<?xml version='1.0' encoding='UTF-8' standalone='no'?>
<doxygen xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="compound.xsd" version="1.11.0" xml:lang="en-US">
  <compounddef id="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy" kind="class" language="Python" prot="public">
    <compoundname>open_spiel::python::rl_agent_policy::RLAgentPolicy</compoundname>
    <basecompoundref refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_joint_r_l_agent_policy" prot="public" virt="non-virtual">open_spiel.python.rl_agent_policy.JointRLAgentPolicy</basecompoundref>
    <sectiondef kind="protected-attrib">
      <memberdef kind="variable" id="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy_1a3688a90cfa6812beac8e9653bda1a0da" prot="protected" static="no" mutable="no">
        <type></type>
        <definition>open_spiel.python.rl_agent_policy.RLAgentPolicy::_player_id</definition>
        <argsstring></argsstring>
        <name>_player_id</name>
        <qualifiedname>open_spiel.python.rl_agent_policy.RLAgentPolicy._player_id</qualifiedname>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="open_spiel/python/rl_agent_policy.py" line="95" column="1" bodyfile="open_spiel/python/rl_agent_policy.py" bodystart="95" bodyend="-1"/>
        <referencedby refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy_1a967b75480ace1fba56768f83cbf6e9aa" compoundref="rl__agent__policy_8py" startline="98" endline="101">open_spiel.python.rl_agent_policy.RLAgentPolicy.action_probabilities</referencedby>
      </memberdef>
    </sectiondef>
    <sectiondef kind="public-func">
      <memberdef kind="function" id="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy_1a083d5ce616242d077b77970d2bd24817" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type></type>
        <definition>open_spiel.python.rl_agent_policy.RLAgentPolicy.__init__</definition>
        <argsstring>(self, game, rl_agent.AbstractAgent agent, int player_id, bool use_observation)</argsstring>
        <name>__init__</name>
        <qualifiedname>open_spiel.python.rl_agent_policy.RLAgentPolicy.__init__</qualifiedname>
        <reimplements refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_joint_r_l_agent_policy_1acdc33df50365949c39488a570276bd11">__init__</reimplements>
        <param>
          <type>self</type>
          <defname>self</defname>
        </param>
        <param>
          <type><ref refid="classopen__spiel_1_1python_1_1policy_1_1_policy_1ae972849a1b0e68c8201c45dd6d27f1bd" kindref="member">game</ref></type>
          <defname>game</defname>
        </param>
        <param>
          <type><ref refid="classopen__spiel_1_1python_1_1rl__agent_1_1_abstract_agent" kindref="compound">rl_agent.AbstractAgent</ref></type>
          <declname>agent</declname>
        </param>
        <param>
          <type>int</type>
          <declname>player_id</declname>
        </param>
        <param>
          <type>bool</type>
          <declname>use_observation</declname>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para><verbatim>Initializes the RL agent policy.

Args:
  game: The game.
  agent: RL agent.
  player_id: ID of the player.
  use_observation: See JointRLAgentPolicy above.
</verbatim> </para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="open_spiel/python/rl_agent_policy.py" line="85" column="1" bodyfile="open_spiel/python/rl_agent_policy.py" bodystart="86" bodyend="97"/>
      </memberdef>
      <memberdef kind="function" id="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy_1a967b75480ace1fba56768f83cbf6e9aa" prot="public" static="no" const="no" explicit="no" inline="no" virt="non-virtual">
        <type></type>
        <definition>open_spiel.python.rl_agent_policy.RLAgentPolicy.action_probabilities</definition>
        <argsstring>(self, state, player_id=None)</argsstring>
        <name>action_probabilities</name>
        <qualifiedname>open_spiel.python.rl_agent_policy.RLAgentPolicy.action_probabilities</qualifiedname>
        <reimplements refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_joint_r_l_agent_policy_1ac5250795c3e475a382804676ee8d945f">action_probabilities</reimplements>
        <param>
          <type>self</type>
          <defname>self</defname>
        </param>
        <param>
          <type>state</type>
          <defname>state</defname>
        </param>
        <param>
          <type>player_id</type>
          <defname>player_id</defname>
          <defval>None</defval>
        </param>
        <briefdescription>
        </briefdescription>
        <detaileddescription>
<para><verbatim>Returns a dictionary {action: prob} for all legal actions.

IMPORTANT: We assume the following properties hold:
- All probabilities are &gt;=0 and sum to 1
- TLDR: Policy implementations should list the (action, prob) for all legal
  actions, but algorithms should not rely on this (yet).
  Details: Before May 2020, only legal actions were present in the mapping,
  but it did not have to be exhaustive: missing actions were considered to
  be associated to a zero probability.
  For example, a deterministic state-poliy was previously {action: 1.0}.
  Given this change of convention is new and hard to enforce, algorithms
  should not rely on the fact that all legal actions should be present.

Args:
  state: A `pyspiel.State` object.
  player_id: Optional, the player id for whom we want an action. Optional
    unless this is a simultaneous state at which multiple players can act.

Returns:
  A `dict` of `{action: probability}` for the specified player in the
  supplied state.
</verbatim> </para>
        </detaileddescription>
        <inbodydescription>
        </inbodydescription>
        <location file="open_spiel/python/rl_agent_policy.py" line="98" column="1" bodyfile="open_spiel/python/rl_agent_policy.py" bodystart="98" bodyend="101"/>
        <references refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy_1a3688a90cfa6812beac8e9653bda1a0da" compoundref="rl__agent__policy_8py" startline="95">open_spiel.python.rl_agent_policy.RLAgentPolicy._player_id</references>
        <references refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy_1a967b75480ace1fba56768f83cbf6e9aa" compoundref="rl__agent__policy_8py" startline="98" endline="101">open_spiel.python.rl_agent_policy.RLAgentPolicy.action_probabilities</references>
        <referencedby refid="classopen__spiel_1_1python_1_1policy_1_1_policy_1a5755c0c1868c78cba8d68773d3d32831" compoundref="policy_8py" startline="145" endline="157">open_spiel.python.policy.Policy.__call__</referencedby>
        <referencedby refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy_1a967b75480ace1fba56768f83cbf6e9aa" compoundref="rl__agent__policy_8py" startline="98" endline="101">open_spiel.python.rl_agent_policy.RLAgentPolicy.action_probabilities</referencedby>
        <referencedby refid="classopen__spiel_1_1python_1_1policy_1_1_policy_1a2761954d5f010b490e108c0bedf4e089" compoundref="policy_8py" startline="158" endline="177">open_spiel.python.policy.Policy.to_tabular</referencedby>
      </memberdef>
    </sectiondef>
    <briefdescription>
    </briefdescription>
    <detaileddescription>
<para><verbatim>A policy for a specific agent trained in an RL environment.</verbatim> </para>
    </detaileddescription>
    <inheritancegraph>
      <node id="1">
        <label>open_spiel.python.rl_agent_policy.RLAgentPolicy</label>
        <link refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy"/>
        <childnode refid="2" relation="public-inheritance">
        </childnode>
      </node>
      <node id="3">
        <label>open_spiel.python.policy.Policy</label>
        <link refid="classopen__spiel_1_1python_1_1policy_1_1_policy"/>
      </node>
      <node id="2">
        <label>open_spiel.python.rl_agent_policy.JointRLAgentPolicy</label>
        <link refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_joint_r_l_agent_policy"/>
        <childnode refid="3" relation="public-inheritance">
        </childnode>
      </node>
    </inheritancegraph>
    <collaborationgraph>
      <node id="1">
        <label>open_spiel.python.rl_agent_policy.RLAgentPolicy</label>
        <link refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy"/>
        <childnode refid="2" relation="public-inheritance">
        </childnode>
      </node>
      <node id="3">
        <label>open_spiel.python.policy.Policy</label>
        <link refid="classopen__spiel_1_1python_1_1policy_1_1_policy"/>
      </node>
      <node id="2">
        <label>open_spiel.python.rl_agent_policy.JointRLAgentPolicy</label>
        <link refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_joint_r_l_agent_policy"/>
        <childnode refid="3" relation="public-inheritance">
        </childnode>
      </node>
    </collaborationgraph>
    <location file="open_spiel/python/rl_agent_policy.py" line="82" column="1" bodyfile="open_spiel/python/rl_agent_policy.py" bodystart="82" bodyend="101"/>
    <listofallmembers>
      <member refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy_1a083d5ce616242d077b77970d2bd24817" prot="public" virt="non-virtual"><scope>open_spiel::python::rl_agent_policy::RLAgentPolicy</scope><name>__init__</name></member>
      <member refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy_1a3688a90cfa6812beac8e9653bda1a0da" prot="protected" virt="non-virtual"><scope>open_spiel::python::rl_agent_policy::RLAgentPolicy</scope><name>_player_id</name></member>
      <member refid="classopen__spiel_1_1python_1_1rl__agent__policy_1_1_r_l_agent_policy_1a967b75480ace1fba56768f83cbf6e9aa" prot="public" virt="non-virtual"><scope>open_spiel::python::rl_agent_policy::RLAgentPolicy</scope><name>action_probabilities</name></member>
    </listofallmembers>
  </compounddef>
</doxygen>

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.11.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>open spiel: open_spiel.python.pytorch.policy_gradient.PolicyGradient Class Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../clipboard.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">open spiel
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.11.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../df/dc9/namespaceopen__spiel.html">open_spiel</a></li><li class="navelem"><a class="el" href="../../d9/d47/namespaceopen__spiel_1_1python.html">python</a></li><li class="navelem"><b>pytorch</b></li><li class="navelem"><a class="el" href="../../d7/deb/namespaceopen__spiel_1_1python_1_1pytorch_1_1policy__gradient.html">policy_gradient</a></li><li class="navelem"><a class="el" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html">PolicyGradient</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pro-methods">Protected Member Functions</a> &#124;
<a href="#pro-attribs">Protected Attributes</a> &#124;
<a href="../../d2/d71/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient-members.html">List of all members</a>  </div>
  <div class="headertitle"><div class="title">open_spiel.python.pytorch.policy_gradient.PolicyGradient Class Reference</div></div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for open_spiel.python.pytorch.policy_gradient.PolicyGradient:</div>
<div class="dyncontent">
<div class="center"><img src="../../dd/ddb/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient__inherit__graph.png" border="0" usemap="#aopen__spiel_8python_8pytorch_8policy__gradient_8_policy_gradient_inherit__map" alt="Inheritance graph"/></div>
<map name="aopen__spiel_8python_8pytorch_8policy__gradient_8_policy_gradient_inherit__map" id="aopen__spiel_8python_8pytorch_8policy__gradient_8_policy_gradient_inherit__map">
<area shape="rect" title=" " alt="" coords="5,267,208,956"/>
<area shape="rect" href="../../d2/dfa/classopen__spiel_1_1python_1_1rl__agent_1_1_abstract_agent.html" title=" " alt="" coords="37,119,176,219"/>
<area shape="poly" title=" " alt="" coords="109,234,109,267,104,267,104,234"/>
<area shape="rect" title=" " alt="" coords="17,5,90,71"/>
<area shape="poly" title=" " alt="" coords="75,83,89,118,84,120,70,85"/>
<area shape="rect" title=" " alt="" coords="114,5,209,71"/>
<area shape="poly" title=" " alt="" coords="145,85,130,120,125,118,140,83"/>
</map>
</div>
<div class="dynheader">
Collaboration diagram for open_spiel.python.pytorch.policy_gradient.PolicyGradient:</div>
<div class="dyncontent">
<div class="center"><img src="../../de/de4/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient__coll__graph.png" border="0" usemap="#aopen__spiel_8python_8pytorch_8policy__gradient_8_policy_gradient_coll__map" alt="Collaboration graph"/></div>
<map name="aopen__spiel_8python_8pytorch_8policy__gradient_8_policy_gradient_coll__map" id="aopen__spiel_8python_8pytorch_8policy__gradient_8_policy_gradient_coll__map">
<area shape="rect" title=" " alt="" coords="5,267,208,956"/>
<area shape="rect" href="../../d2/dfa/classopen__spiel_1_1python_1_1rl__agent_1_1_abstract_agent.html" title=" " alt="" coords="37,119,176,219"/>
<area shape="poly" title=" " alt="" coords="109,234,109,267,104,267,104,234"/>
<area shape="rect" title=" " alt="" coords="17,5,90,71"/>
<area shape="poly" title=" " alt="" coords="75,83,89,118,84,120,70,85"/>
<area shape="rect" title=" " alt="" coords="114,5,209,71"/>
<area shape="poly" title=" " alt="" coords="145,85,130,120,125,118,140,83"/>
</map>
</div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-methods" name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:acff77770d69b724496d0d58fd14ccb43" id="r_acff77770d69b724496d0d58fd14ccb43"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#acff77770d69b724496d0d58fd14ccb43">__init__</a> (self, player_id, info_state_size, num_actions, loss_str=&quot;a2c&quot;, loss_class=None, hidden_layers_sizes=(128,), batch_size=16, critic_learning_rate=0.01, pi_learning_rate=0.001, entropy_cost=0.01, num_critic_before_pi=8, additional_discount_factor=1.0, max_global_gradient_norm=None, optimizer_str=&quot;sgd&quot;)</td></tr>
<tr class="separator:acff77770d69b724496d0d58fd14ccb43"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:accd3df94affd3092ece7c5110a1de359" id="r_accd3df94affd3092ece7c5110a1de359"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#accd3df94affd3092ece7c5110a1de359">minimize_with_clipping</a> (self, model, optimizer, loss)</td></tr>
<tr class="separator:accd3df94affd3092ece7c5110a1de359"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6b7739338748eab5d5000c55d046fe8" id="r_af6b7739338748eab5d5000c55d046fe8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af6b7739338748eab5d5000c55d046fe8">step</a> (self, time_step, is_evaluation=False)</td></tr>
<tr class="separator:af6b7739338748eab5d5000c55d046fe8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af1a6308c6317b2a69c3e54ebf67c5622" id="r_af1a6308c6317b2a69c3e54ebf67c5622"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af1a6308c6317b2a69c3e54ebf67c5622">save</a> (self, checkpoint_dir)</td></tr>
<tr class="separator:af1a6308c6317b2a69c3e54ebf67c5622"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5c98bb68cd5183cb7878933996547f93" id="r_a5c98bb68cd5183cb7878933996547f93"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5c98bb68cd5183cb7878933996547f93">has_checkpoint</a> (self, checkpoint_dir)</td></tr>
<tr class="separator:a5c98bb68cd5183cb7878933996547f93"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab609a7255d397d73b18d4dbec2364f1c" id="r_ab609a7255d397d73b18d4dbec2364f1c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab609a7255d397d73b18d4dbec2364f1c">restore</a> (self, checkpoint_dir)</td></tr>
<tr class="separator:ab609a7255d397d73b18d4dbec2364f1c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af93562285d1d33bc47102f98acb85488" id="r_af93562285d1d33bc47102f98acb85488"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af93562285d1d33bc47102f98acb85488">loss</a> (self)</td></tr>
<tr class="separator:af93562285d1d33bc47102f98acb85488"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5784c14c48765f4a3e50eda0c442426d" id="r_a5784c14c48765f4a3e50eda0c442426d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5784c14c48765f4a3e50eda0c442426d">get_weights</a> (self)</td></tr>
<tr class="separator:a5784c14c48765f4a3e50eda0c442426d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a548181be13c4c79730cb5520a75787ca" id="r_a548181be13c4c79730cb5520a75787ca"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a548181be13c4c79730cb5520a75787ca">copy_with_noise</a> (self, sigma=0.0, copy_weights=True)</td></tr>
<tr class="separator:a548181be13c4c79730cb5520a75787ca"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pub-attribs" name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:af3f98efa3a15dc3f807f10ee8d757171" id="r_af3f98efa3a15dc3f807f10ee8d757171"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af3f98efa3a15dc3f807f10ee8d757171">player_id</a></td></tr>
<tr class="separator:af3f98efa3a15dc3f807f10ee8d757171"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1ea857b4ebb691043d7510d4a15825e5" id="r_a1ea857b4ebb691043d7510d4a15825e5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1ea857b4ebb691043d7510d4a15825e5">policy_logits_network</a></td></tr>
<tr class="separator:a1ea857b4ebb691043d7510d4a15825e5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f6b907fbc00f3a27c4777852bc5c108" id="r_a3f6b907fbc00f3a27c4777852bc5c108"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a3f6b907fbc00f3a27c4777852bc5c108">pg_class</a></td></tr>
<tr class="separator:a3f6b907fbc00f3a27c4777852bc5c108"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-methods" name="pro-methods"></a>
Protected Member Functions</h2></td></tr>
<tr class="memitem:aa7d88aa18275e11c79b98f3abf8bfb6d" id="r_aa7d88aa18275e11c79b98f3abf8bfb6d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa7d88aa18275e11c79b98f3abf8bfb6d">_get_loss_class</a> (self, loss_str)</td></tr>
<tr class="separator:aa7d88aa18275e11c79b98f3abf8bfb6d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5fbe9303efa1660b1b4738078819631d" id="r_a5fbe9303efa1660b1b4738078819631d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5fbe9303efa1660b1b4738078819631d">_act</a> (self, info_state, legal_actions)</td></tr>
<tr class="separator:a5fbe9303efa1660b1b4738078819631d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7f03499d3fe8e965b17197a14b50fd5" id="r_ae7f03499d3fe8e965b17197a14b50fd5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae7f03499d3fe8e965b17197a14b50fd5">_full_checkpoint_name</a> (self, checkpoint_dir, name)</td></tr>
<tr class="separator:ae7f03499d3fe8e965b17197a14b50fd5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a09ea379d1a5880b14cf864511d95e169" id="r_a09ea379d1a5880b14cf864511d95e169"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a09ea379d1a5880b14cf864511d95e169">_latest_checkpoint_filename</a> (self, name)</td></tr>
<tr class="separator:a09ea379d1a5880b14cf864511d95e169"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae72fa55445edd59df6e326a4902eb686" id="r_ae72fa55445edd59df6e326a4902eb686"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae72fa55445edd59df6e326a4902eb686">_add_episode_data_to_dataset</a> (self)</td></tr>
<tr class="separator:ae72fa55445edd59df6e326a4902eb686"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa03ef306d33bfebbdb6c7478a965c26f" id="r_aa03ef306d33bfebbdb6c7478a965c26f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa03ef306d33bfebbdb6c7478a965c26f">_add_transition</a> (self, time_step)</td></tr>
<tr class="separator:aa03ef306d33bfebbdb6c7478a965c26f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6cc5d6bb8de010a9f67e71cc09e3ff5c" id="r_a6cc5d6bb8de010a9f67e71cc09e3ff5c"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a6cc5d6bb8de010a9f67e71cc09e3ff5c">_critic_update</a> (self)</td></tr>
<tr class="separator:a6cc5d6bb8de010a9f67e71cc09e3ff5c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1df0f6d210f6335c45c04572758e5dab" id="r_a1df0f6d210f6335c45c04572758e5dab"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1df0f6d210f6335c45c04572758e5dab">_pi_update</a> (self)</td></tr>
<tr class="separator:a1df0f6d210f6335c45c04572758e5dab"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="pro-attribs" name="pro-attribs"></a>
Protected Attributes</h2></td></tr>
<tr class="memitem:a8008d74c54fdd7a8346c662c18f0513f" id="r_a8008d74c54fdd7a8346c662c18f0513f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8008d74c54fdd7a8346c662c18f0513f">_kwargs</a></td></tr>
<tr class="separator:a8008d74c54fdd7a8346c662c18f0513f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af6fc20a88f31a3f20b4628ee182e3352" id="r_af6fc20a88f31a3f20b4628ee182e3352"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af6fc20a88f31a3f20b4628ee182e3352">_loss_class</a></td></tr>
<tr class="separator:af6fc20a88f31a3f20b4628ee182e3352"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a224bf64bf629d63f4123b67f0f45bc7a" id="r_a224bf64bf629d63f4123b67f0f45bc7a"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a224bf64bf629d63f4123b67f0f45bc7a">_num_actions</a></td></tr>
<tr class="separator:a224bf64bf629d63f4123b67f0f45bc7a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a62bf8321cd431e13713e9970c7ac50c3" id="r_a62bf8321cd431e13713e9970c7ac50c3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a62bf8321cd431e13713e9970c7ac50c3">_layer_sizes</a></td></tr>
<tr class="separator:a62bf8321cd431e13713e9970c7ac50c3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a514747846f0aba63885ceee9e7999ad5" id="r_a514747846f0aba63885ceee9e7999ad5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a514747846f0aba63885ceee9e7999ad5">_batch_size</a></td></tr>
<tr class="separator:a514747846f0aba63885ceee9e7999ad5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0db88eaecdaca8cb92f2a457b28f658e" id="r_a0db88eaecdaca8cb92f2a457b28f658e"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0db88eaecdaca8cb92f2a457b28f658e">_extra_discount</a></td></tr>
<tr class="separator:a0db88eaecdaca8cb92f2a457b28f658e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeb9c290f2c483ad80487aee65d4f9399" id="r_aeb9c290f2c483ad80487aee65d4f9399"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aeb9c290f2c483ad80487aee65d4f9399">_num_critic_before_pi</a></td></tr>
<tr class="separator:aeb9c290f2c483ad80487aee65d4f9399"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abd22d3c69beb48d983fd934193e03aaf" id="r_abd22d3c69beb48d983fd934193e03aaf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#abd22d3c69beb48d983fd934193e03aaf">_max_global_gradient_norm</a></td></tr>
<tr class="separator:abd22d3c69beb48d983fd934193e03aaf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7ad49e1f466991ddab26852eeec613cb" id="r_a7ad49e1f466991ddab26852eeec613cb"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7ad49e1f466991ddab26852eeec613cb">_episode_data</a></td></tr>
<tr class="separator:a7ad49e1f466991ddab26852eeec613cb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f16488b9f0f92e073d7e8e969d8793b" id="r_a4f16488b9f0f92e073d7e8e969d8793b"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4f16488b9f0f92e073d7e8e969d8793b">_dataset</a></td></tr>
<tr class="separator:a4f16488b9f0f92e073d7e8e969d8793b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5d0742495265e2db0c0f8f5853920573" id="r_a5d0742495265e2db0c0f8f5853920573"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5d0742495265e2db0c0f8f5853920573">_prev_time_step</a></td></tr>
<tr class="separator:a5d0742495265e2db0c0f8f5853920573"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5850c75570c66a26bd5a843401f8c655" id="r_a5850c75570c66a26bd5a843401f8c655"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5850c75570c66a26bd5a843401f8c655">_prev_action</a></td></tr>
<tr class="separator:a5850c75570c66a26bd5a843401f8c655"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a129b3a4ac314411afa90406590743a8d" id="r_a129b3a4ac314411afa90406590743a8d"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a129b3a4ac314411afa90406590743a8d">_step_counter</a></td></tr>
<tr class="separator:a129b3a4ac314411afa90406590743a8d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a095ea25772e0dc60db1e0b69ff4d52cc" id="r_a095ea25772e0dc60db1e0b69ff4d52cc"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a095ea25772e0dc60db1e0b69ff4d52cc">_episode_counter</a></td></tr>
<tr class="separator:a095ea25772e0dc60db1e0b69ff4d52cc"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeacb6abaae61dbc27cb957842dae67aa" id="r_aeacb6abaae61dbc27cb957842dae67aa"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aeacb6abaae61dbc27cb957842dae67aa">_num_learn_steps</a></td></tr>
<tr class="separator:aeacb6abaae61dbc27cb957842dae67aa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2279bd25f2714729ebe52265829bcec" id="r_ac2279bd25f2714729ebe52265829bcec"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac2279bd25f2714729ebe52265829bcec">_last_loss_value</a></td></tr>
<tr class="separator:ac2279bd25f2714729ebe52265829bcec"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a769cd71526dec762bc6464d008e782bf" id="r_a769cd71526dec762bc6464d008e782bf"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a769cd71526dec762bc6464d008e782bf">_net_torso</a></td></tr>
<tr class="separator:a769cd71526dec762bc6464d008e782bf"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe5f81efc6a4d006adbc43523aa807b5" id="r_afe5f81efc6a4d006adbc43523aa807b5"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#afe5f81efc6a4d006adbc43523aa807b5">_policy_logits_layer</a></td></tr>
<tr class="separator:afe5f81efc6a4d006adbc43523aa807b5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5a1adfc0f559d59b75f9c30c5991c757" id="r_a5a1adfc0f559d59b75f9c30c5991c757"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5a1adfc0f559d59b75f9c30c5991c757">_savers</a></td></tr>
<tr class="separator:a5a1adfc0f559d59b75f9c30c5991c757"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7802b6a9f19aa8a16739cdb0d9689764" id="r_a7802b6a9f19aa8a16739cdb0d9689764"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7802b6a9f19aa8a16739cdb0d9689764">_critic_optimizer</a></td></tr>
<tr class="separator:a7802b6a9f19aa8a16739cdb0d9689764"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae314355e379c41fab18e0f210e206dbe" id="r_ae314355e379c41fab18e0f210e206dbe"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae314355e379c41fab18e0f210e206dbe">_baseline_layer</a></td></tr>
<tr class="separator:ae314355e379c41fab18e0f210e206dbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae4711f268372a27b01725b41fa9e0075" id="r_ae4711f268372a27b01725b41fa9e0075"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae4711f268372a27b01725b41fa9e0075">_critic_network</a></td></tr>
<tr class="separator:ae4711f268372a27b01725b41fa9e0075"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a178999560faff22b784da9efd675eae2" id="r_a178999560faff22b784da9efd675eae2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a178999560faff22b784da9efd675eae2">_q_values_layer</a></td></tr>
<tr class="separator:a178999560faff22b784da9efd675eae2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af488b26c17dc6464176a853eb8906cc3" id="r_af488b26c17dc6464176a853eb8906cc3"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#af488b26c17dc6464176a853eb8906cc3">_pi_network</a></td></tr>
<tr class="separator:af488b26c17dc6464176a853eb8906cc3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a20560f66e392c7a7a9c91f7552e903f8" id="r_a20560f66e392c7a7a9c91f7552e903f8"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a20560f66e392c7a7a9c91f7552e903f8">_pi_optimizer</a></td></tr>
<tr class="separator:a20560f66e392c7a7a9c91f7552e903f8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1898d1e97950c332e40d31db30b7f7de" id="r_a1898d1e97950c332e40d31db30b7f7de"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1898d1e97950c332e40d31db30b7f7de">_loss_str</a></td></tr>
<tr class="separator:a1898d1e97950c332e40d31db30b7f7de"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1b0ccdfb7cf04ba5dd04306bbd8b3c65" id="r_a1b0ccdfb7cf04ba5dd04306bbd8b3c65"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1b0ccdfb7cf04ba5dd04306bbd8b3c65">_policy_logits</a></td></tr>
<tr class="separator:a1b0ccdfb7cf04ba5dd04306bbd8b3c65"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0176c53410292f41d18248aa42f4b93f" id="r_a0176c53410292f41d18248aa42f4b93f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0176c53410292f41d18248aa42f4b93f">_last_critic_loss_value</a></td></tr>
<tr class="separator:a0176c53410292f41d18248aa42f4b93f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0e58499db2a1f760318def503964d092" id="r_a0e58499db2a1f760318def503964d092"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0e58499db2a1f760318def503964d092">_last_pi_loss_value</a></td></tr>
<tr class="separator:a0e58499db2a1f760318def503964d092"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">RPG Agent implementation in PyTorch.

See open_spiel/python/examples/single_agent_catch.py for an usage example.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00118">118</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
</div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="acff77770d69b724496d0d58fd14ccb43" name="acff77770d69b724496d0d58fd14ccb43"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acff77770d69b724496d0d58fd14ccb43">&#9670;&#160;</a></span>__init__()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__ </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>player_id</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>info_state_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>num_actions</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>loss_str</em></span><span class="paramdefsep"> = </span><span class="paramdefval">&quot;a2c&quot;</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>loss_class</em></span><span class="paramdefsep"> = </span><span class="paramdefval">None</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>hidden_layers_sizes</em></span><span class="paramdefsep"> = </span><span class="paramdefval">(128,)</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>batch_size</em></span><span class="paramdefsep"> = </span><span class="paramdefval">16</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>critic_learning_rate</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0.01</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>pi_learning_rate</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0.001</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>entropy_cost</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0.01</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>num_critic_before_pi</em></span><span class="paramdefsep"> = </span><span class="paramdefval">8</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>additional_discount_factor</em></span><span class="paramdefsep"> = </span><span class="paramdefval">1.0</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>max_global_gradient_norm</em></span><span class="paramdefsep"> = </span><span class="paramdefval">None</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>optimizer_str</em></span><span class="paramdefsep"> = </span><span class="paramdefval">&quot;sgd&quot;</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Initialize the PolicyGradient agent.

Args:
  player_id: int, player identifier. Usually its position in the game.
  info_state_size: int, info_state vector size.
  num_actions: int, number of actions per info state.
  loss_str: string or None. If string, must be one of ["rpg", "qpg", "rm",
    "a2c", "neurd"] and defined in `_get_loss_class`. If None, a loss class
    must be passed through `loss_class`. Defaults to "a2c".
  loss_class: Class or None. If Class, it must define the policy gradient
    loss. If None a loss class in a string format must be passed through
    `loss_str`. Defaults to None.
  hidden_layers_sizes: iterable, defines the neural network layers. Defaults
      to (128,), which produces a NN: [INPUT] -&gt; [128] -&gt; ReLU -&gt; [OUTPUT].
  batch_size: int, batch size to use for Q and Pi learning. Defaults to 128.
  critic_learning_rate: float, learning rate used for Critic (Q or V).
    Defaults to 0.001.
  pi_learning_rate: float, learning rate used for Pi. Defaults to 0.001.
  entropy_cost: float, entropy cost used to multiply the entropy loss. Can
    be set to None to skip entropy computation. Defaults to 0.001.
  num_critic_before_pi: int, number of Critic (Q or V) updates before each
    Pi update. Defaults to 8 (every 8th critic learning step, Pi also
    learns).
  additional_discount_factor: float, additional discount to compute returns.
    Defaults to 1.0, in which case, no extra discount is applied.  None that
    users must provide *only one of* `loss_str` or `loss_class`.
  max_global_gradient_norm: float or None, maximum global norm of a gradient
    to which the gradient is shrunk if its value is larger.
  optimizer_str: String defining which optimizer to use. Supported values
    are {sgd, adam}
</pre> 
<p>Reimplemented from <a class="el" href="../../d2/dfa/classopen__spiel_1_1python_1_1rl__agent_1_1_abstract_agent.html#af17e2a06dc592b1d2bbe3d1ee40467b6">open_spiel.python.rl_agent.AbstractAgent</a>.</p>

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00124">124</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  138</span>               optimizer_str=<span class="stringliteral">&quot;sgd&quot;</span>):</div>
<div class="line"><span class="lineno">  139</span>    <span class="stringliteral">&quot;&quot;&quot;Initialize the PolicyGradient agent.</span></div>
<div class="line"><span class="lineno">  140</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  141</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  142</span><span class="stringliteral">      player_id: int, player identifier. Usually its position in the game.</span></div>
<div class="line"><span class="lineno">  143</span><span class="stringliteral">      info_state_size: int, info_state vector size.</span></div>
<div class="line"><span class="lineno">  144</span><span class="stringliteral">      num_actions: int, number of actions per info state.</span></div>
<div class="line"><span class="lineno">  145</span><span class="stringliteral">      loss_str: string or None. If string, must be one of [&quot;rpg&quot;, &quot;qpg&quot;, &quot;rm&quot;,</span></div>
<div class="line"><span class="lineno">  146</span><span class="stringliteral">        &quot;a2c&quot;, &quot;neurd&quot;] and defined in `_get_loss_class`. If None, a loss class</span></div>
<div class="line"><span class="lineno">  147</span><span class="stringliteral">        must be passed through `loss_class`. Defaults to &quot;a2c&quot;.</span></div>
<div class="line"><span class="lineno">  148</span><span class="stringliteral">      loss_class: Class or None. If Class, it must define the policy gradient</span></div>
<div class="line"><span class="lineno">  149</span><span class="stringliteral">        loss. If None a loss class in a string format must be passed through</span></div>
<div class="line"><span class="lineno">  150</span><span class="stringliteral">        `loss_str`. Defaults to None.</span></div>
<div class="line"><span class="lineno">  151</span><span class="stringliteral">      hidden_layers_sizes: iterable, defines the neural network layers. Defaults</span></div>
<div class="line"><span class="lineno">  152</span><span class="stringliteral">          to (128,), which produces a NN: [INPUT] -&gt; [128] -&gt; ReLU -&gt; [OUTPUT].</span></div>
<div class="line"><span class="lineno">  153</span><span class="stringliteral">      batch_size: int, batch size to use for Q and Pi learning. Defaults to 128.</span></div>
<div class="line"><span class="lineno">  154</span><span class="stringliteral">      critic_learning_rate: float, learning rate used for Critic (Q or V).</span></div>
<div class="line"><span class="lineno">  155</span><span class="stringliteral">        Defaults to 0.001.</span></div>
<div class="line"><span class="lineno">  156</span><span class="stringliteral">      pi_learning_rate: float, learning rate used for Pi. Defaults to 0.001.</span></div>
<div class="line"><span class="lineno">  157</span><span class="stringliteral">      entropy_cost: float, entropy cost used to multiply the entropy loss. Can</span></div>
<div class="line"><span class="lineno">  158</span><span class="stringliteral">        be set to None to skip entropy computation. Defaults to 0.001.</span></div>
<div class="line"><span class="lineno">  159</span><span class="stringliteral">      num_critic_before_pi: int, number of Critic (Q or V) updates before each</span></div>
<div class="line"><span class="lineno">  160</span><span class="stringliteral">        Pi update. Defaults to 8 (every 8th critic learning step, Pi also</span></div>
<div class="line"><span class="lineno">  161</span><span class="stringliteral">        learns).</span></div>
<div class="line"><span class="lineno">  162</span><span class="stringliteral">      additional_discount_factor: float, additional discount to compute returns.</span></div>
<div class="line"><span class="lineno">  163</span><span class="stringliteral">        Defaults to 1.0, in which case, no extra discount is applied.  None that</span></div>
<div class="line"><span class="lineno">  164</span><span class="stringliteral">        users must provide *only one of* `loss_str` or `loss_class`.</span></div>
<div class="line"><span class="lineno">  165</span><span class="stringliteral">      max_global_gradient_norm: float or None, maximum global norm of a gradient</span></div>
<div class="line"><span class="lineno">  166</span><span class="stringliteral">        to which the gradient is shrunk if its value is larger.</span></div>
<div class="line"><span class="lineno">  167</span><span class="stringliteral">      optimizer_str: String defining which optimizer to use. Supported values</span></div>
<div class="line"><span class="lineno">  168</span><span class="stringliteral">        are {sgd, adam}</span></div>
<div class="line"><span class="lineno">  169</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  170</span>    <span class="keyword">assert</span> bool(loss_str) ^ bool(loss_class), <span class="stringliteral">&quot;Please provide only one option.&quot;</span></div>
<div class="line"><span class="lineno">  171</span>    self._kwargs = locals()</div>
<div class="line"><span class="lineno">  172</span>    loss_class = loss_class <span class="keywordflow">if</span> loss_class <span class="keywordflow">else</span> self._get_loss_class(loss_str)</div>
<div class="line"><span class="lineno">  173</span>    self._loss_class = loss_class</div>
<div class="line"><span class="lineno">  174</span> </div>
<div class="line"><span class="lineno">  175</span>    self.player_id = player_id</div>
<div class="line"><span class="lineno">  176</span>    self._num_actions = num_actions</div>
<div class="line"><span class="lineno">  177</span>    self._layer_sizes = hidden_layers_sizes</div>
<div class="line"><span class="lineno">  178</span>    self._batch_size = batch_size</div>
<div class="line"><span class="lineno">  179</span>    self._extra_discount = additional_discount_factor</div>
<div class="line"><span class="lineno">  180</span>    self._num_critic_before_pi = num_critic_before_pi</div>
<div class="line"><span class="lineno">  181</span>    self._max_global_gradient_norm = max_global_gradient_norm</div>
<div class="line"><span class="lineno">  182</span> </div>
<div class="line"><span class="lineno">  183</span>    self._episode_data = []</div>
<div class="line"><span class="lineno">  184</span>    self._dataset = collections.defaultdict(list)</div>
<div class="line"><span class="lineno">  185</span>    self._prev_time_step = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  186</span>    self._prev_action = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  187</span> </div>
<div class="line"><span class="lineno">  188</span>    <span class="comment"># Step counters</span></div>
<div class="line"><span class="lineno">  189</span>    self._step_counter = 0</div>
<div class="line"><span class="lineno">  190</span>    self._episode_counter = 0</div>
<div class="line"><span class="lineno">  191</span>    self._num_learn_steps = 0</div>
<div class="line"><span class="lineno">  192</span> </div>
<div class="line"><span class="lineno">  193</span>    <span class="comment"># Keep track of the last training loss achieved in an update step.</span></div>
<div class="line"><span class="lineno">  194</span>    self._last_loss_value = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  195</span> </div>
<div class="line"><span class="lineno">  196</span>    <span class="comment"># Network</span></div>
<div class="line"><span class="lineno">  197</span>    <span class="comment"># activate final as we plug logit and qvalue heads afterwards.</span></div>
<div class="line"><span class="lineno">  198</span>    self._net_torso = MLPTorso(info_state_size, self._layer_sizes)</div>
<div class="line"><span class="lineno">  199</span>    torso_out_size = self._layer_sizes[-1]</div>
<div class="line"><span class="lineno">  200</span>    self._policy_logits_layer = SonnetLinear(</div>
<div class="line"><span class="lineno">  201</span>        torso_out_size, self._num_actions, activate_relu=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  202</span>    <span class="comment"># Do not remove policy_logits_network. Even if it&#39;s not used directly here,</span></div>
<div class="line"><span class="lineno">  203</span>    <span class="comment"># other code outside this file refers to it.</span></div>
<div class="line"><span class="lineno">  204</span>    self.policy_logits_network = nn.Sequential(self._net_torso,</div>
<div class="line"><span class="lineno">  205</span>                                               self._policy_logits_layer)</div>
<div class="line"><span class="lineno">  206</span> </div>
<div class="line"><span class="lineno">  207</span>    self._savers = []</div>
<div class="line"><span class="lineno">  208</span> </div>
<div class="line"><span class="lineno">  209</span>    <span class="comment"># Add baseline (V) head for A2C (or Q-head for QPG / RPG / RMPG / NeuRD)</span></div>
<div class="line"><span class="lineno">  210</span>    <span class="keywordflow">if</span> optimizer_str == <span class="stringliteral">&quot;adam&quot;</span>:</div>
<div class="line"><span class="lineno">  211</span>      self._critic_optimizer = optim.Adam</div>
<div class="line"><span class="lineno">  212</span>    <span class="keywordflow">elif</span> optimizer_str == <span class="stringliteral">&quot;sgd&quot;</span>:</div>
<div class="line"><span class="lineno">  213</span>      self._critic_optimizer = optim.SGD</div>
<div class="line"><span class="lineno">  214</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  215</span>      <span class="keywordflow">raise</span> ValueError(<span class="stringliteral">&quot;Not implemented, choose from &#39;adam&#39; and &#39;sgd&#39;.&quot;</span>)</div>
<div class="line"><span class="lineno">  216</span> </div>
<div class="line"><span class="lineno">  217</span>    <span class="keywordflow">if</span> loss_class.__name__ == <span class="stringliteral">&quot;BatchA2CLoss&quot;</span>:</div>
<div class="line"><span class="lineno">  218</span>      self._baseline_layer = SonnetLinear(</div>
<div class="line"><span class="lineno">  219</span>          torso_out_size, 1, activate_relu=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  220</span>      self._critic_network = nn.Sequential(self._net_torso,</div>
<div class="line"><span class="lineno">  221</span>                                           self._baseline_layer)</div>
<div class="line"><span class="lineno">  222</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  223</span>      self._q_values_layer = SonnetLinear(</div>
<div class="line"><span class="lineno">  224</span>          torso_out_size, self._num_actions, activate_relu=<span class="keyword">False</span>)</div>
<div class="line"><span class="lineno">  225</span>      self._critic_network = nn.Sequential(self._net_torso,</div>
<div class="line"><span class="lineno">  226</span>                                           self._q_values_layer)</div>
<div class="line"><span class="lineno">  227</span> </div>
<div class="line"><span class="lineno">  228</span>    self._critic_optimizer = self._critic_optimizer(</div>
<div class="line"><span class="lineno">  229</span>        self._critic_network.parameters(), lr=critic_learning_rate)</div>
<div class="line"><span class="lineno">  230</span> </div>
<div class="line"><span class="lineno">  231</span>    <span class="comment"># Pi loss</span></div>
<div class="line"><span class="lineno">  232</span>    self.pg_class = loss_class(entropy_cost=entropy_cost)</div>
<div class="line"><span class="lineno">  233</span>    self._pi_network = nn.Sequential(self._net_torso, self._policy_logits_layer)</div>
<div class="line"><span class="lineno">  234</span>    <span class="keywordflow">if</span> optimizer_str == <span class="stringliteral">&quot;adam&quot;</span>:</div>
<div class="line"><span class="lineno">  235</span>      self._pi_optimizer = optim.Adam(</div>
<div class="line"><span class="lineno">  236</span>          self._pi_network.parameters(), lr=pi_learning_rate)</div>
<div class="line"><span class="lineno">  237</span>    <span class="keywordflow">elif</span> optimizer_str == <span class="stringliteral">&quot;sgd&quot;</span>:</div>
<div class="line"><span class="lineno">  238</span>      self._pi_optimizer = optim.SGD(</div>
<div class="line"><span class="lineno">  239</span>          self._pi_network.parameters(), lr=pi_learning_rate)</div>
<div class="line"><span class="lineno">  240</span> </div>
<div class="line"><span class="lineno">  241</span>    self._loss_str = loss_str</div>
<div class="line"><span class="lineno">  242</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00202">open_spiel.python.algorithms.policy_gradient.PolicyGradient._baseline_layer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00218">open_spiel.python.pytorch.policy_gradient.PolicyGradient._baseline_layer</a>, <a class="el" href="../../d7/dfe/dataset__generator_8py_source.html#l00032">dataset_generator.Dataset._batch_size</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00074">open_spiel.python.algorithms.dqn.DQN._batch_size</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00068">open_spiel.python.algorithms.nfsp.NFSP._batch_size</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00156">open_spiel.python.algorithms.policy_gradient.PolicyGradient._batch_size</a>, <a class="el" href="../../d4/d52/iterated__matrix__game_8py_source.html#l00047">open_spiel.python.environments.iterated_matrix_game.IteratedMatrixGame._batch_size</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00072">open_spiel.python.jax.dqn.DQN._batch_size</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00068">open_spiel.python.jax.nfsp.NFSP._batch_size</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00633">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._batch_size</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00075">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy._batch_size</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00092">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._batch_size</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00145">open_spiel.python.pytorch.dqn.DQN._batch_size</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00178">open_spiel.python.pytorch.policy_gradient.PolicyGradient._batch_size</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00652">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._critic_network</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00220">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_network</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00228">open_spiel.python.algorithms.policy_gradient.PolicyGradient._critic_optimizer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00211">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_optimizer</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00161">open_spiel.python.algorithms.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00249">open_spiel.python.jax.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00184">open_spiel.python.pytorch.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00167">open_spiel.python.algorithms.policy_gradient.PolicyGradient._episode_counter</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00648">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._episode_counter</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00255">open_spiel.python.jax.policy_gradient.PolicyGradient._episode_counter</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00190">open_spiel.python.pytorch.policy_gradient.PolicyGradient._episode_counter</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00160">open_spiel.python.algorithms.policy_gradient.PolicyGradient._episode_data</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00248">open_spiel.python.jax.policy_gradient.PolicyGradient._episode_data</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00183">open_spiel.python.pytorch.policy_gradient.PolicyGradient._episode_data</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00157">open_spiel.python.algorithms.policy_gradient.PolicyGradient._extra_discount</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00245">open_spiel.python.jax.policy_gradient.PolicyGradient._extra_discount</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00179">open_spiel.python.pytorch.policy_gradient.PolicyGradient._extra_discount</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00271">open_spiel.python.algorithms.policy_gradient.PolicyGradient._get_loss_class()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00322">open_spiel.python.jax.policy_gradient.PolicyGradient._get_loss_class()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00243">open_spiel.python.pytorch.policy_gradient.PolicyGradient._get_loss_class()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00066">open_spiel.python.algorithms.dqn.DQN._kwargs</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00148">open_spiel.python.algorithms.policy_gradient.PolicyGradient._kwargs</a>, <a class="el" href="../../d9/d94/abstract__meta__trainer_8py_source.html#l00171">open_spiel.python.algorithms.psro_v2.abstract_meta_trainer.AbstractMetaTrainer._kwargs</a>, <a class="el" href="../../dc/d28/optimization__oracle_8py_source.html#l00064">open_spiel.python.algorithms.psro_v2.optimization_oracle.AbstractOracle._kwargs</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00065">open_spiel.python.jax.dqn.DQN._kwargs</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00240">open_spiel.python.jax.policy_gradient.PolicyGradient._kwargs</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00138">open_spiel.python.pytorch.dqn.DQN._kwargs</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00171">open_spiel.python.pytorch.policy_gradient.PolicyGradient._kwargs</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00095">open_spiel.python.algorithms.dqn.DQN._last_loss_value</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00171">open_spiel.python.algorithms.policy_gradient.PolicyGradient._last_loss_value</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00054">open_spiel.python.algorithms.tabular_qlearner.QLearner._last_loss_value</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00084">open_spiel.python.algorithms.wolf_phc.WoLFPHC._last_loss_value</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00094">open_spiel.python.jax.dqn.DQN._last_loss_value</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00259">open_spiel.python.jax.policy_gradient.PolicyGradient._last_loss_value</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00082">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy._last_loss_value</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00118">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._last_loss_value</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00166">open_spiel.python.pytorch.dqn.DQN._last_loss_value</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00194">open_spiel.python.pytorch.policy_gradient.PolicyGradient._last_loss_value</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00073">open_spiel.python.algorithms.dqn.DQN._layer_sizes</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00067">open_spiel.python.algorithms.nfsp.NFSP._layer_sizes</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00155">open_spiel.python.algorithms.policy_gradient.PolicyGradient._layer_sizes</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00071">open_spiel.python.jax.dqn.DQN._layer_sizes</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00067">open_spiel.python.jax.nfsp.NFSP._layer_sizes</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00144">open_spiel.python.pytorch.dqn.DQN._layer_sizes</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00177">open_spiel.python.pytorch.policy_gradient.PolicyGradient._layer_sizes</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00150">open_spiel.python.algorithms.policy_gradient.PolicyGradient._loss_class</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00173">open_spiel.python.pytorch.policy_gradient.PolicyGradient._loss_class</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00268">open_spiel.python.algorithms.policy_gradient.PolicyGradient._loss_str</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00261">open_spiel.python.jax.policy_gradient.PolicyGradient._loss_str</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00241">open_spiel.python.pytorch.policy_gradient.PolicyGradient._loss_str</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00181">open_spiel.python.pytorch.policy_gradient.PolicyGradient._max_global_gradient_norm</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00183">open_spiel.python.algorithms.policy_gradient.PolicyGradient._net_torso</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00198">open_spiel.python.pytorch.policy_gradient.PolicyGradient._net_torso</a>, <a class="el" href="../../dd/dc3/boltzmann__tabular__qlearner_8py_source.html#l00073">open_spiel.python.algorithms.boltzmann_tabular_qlearner.BoltzmannQLearner._num_actions</a>, <a class="el" href="../../d3/dc4/algorithms_2deep__cfr_8py_source.html#l00170">open_spiel.python.algorithms.deep_cfr.DeepCFRSolver._num_actions</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00213">open_spiel.python.algorithms.deep_cfr_tf2.AdvantageNetwork._num_actions</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00333">open_spiel.python.algorithms.deep_cfr_tf2.DeepCFRSolver._num_actions</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00148">open_spiel.python.algorithms.deep_cfr_tf2.PolicyNetwork._num_actions</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00070">open_spiel.python.algorithms.dqn.DQN._num_actions</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00137">open_spiel.python.algorithms.eva.EVAAgent._num_actions</a>, <a class="el" href="../../d9/d7e/mcts__agent_8py_source.html#l00033">open_spiel.python.algorithms.mcts_agent.MCTSAgent._num_actions</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00066">open_spiel.python.algorithms.nfsp.NFSP._num_actions</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00154">open_spiel.python.algorithms.policy_gradient.PolicyGradient._num_actions</a>, <a class="el" href="../../d3/df2/random__agent_8py_source.html#l00027">open_spiel.python.algorithms.random_agent.RandomAgent._num_actions</a>, <a class="el" href="../../d8/d79/tabular__multiagent__qlearner_8py_source.html#l00190">open_spiel.python.algorithms.tabular_multiagent_qlearner.MultiagentQLearner._num_actions</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00046">open_spiel.python.algorithms.tabular_qlearner.QLearner._num_actions</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00072">open_spiel.python.algorithms.wolf_phc.WoLFPHC._num_actions</a>, <a class="el" href="../../d6/d15/bluechip__bridge_8py_source.html#l00214">open_spiel.python.bots.bluechip_bridge.BlueChipBridgeBot._num_actions</a>, <a class="el" href="../../dc/d9b/catch_8py_source.html#l00043">open_spiel.python.environments.catch.Environment._num_actions</a>, <a class="el" href="../../d0/dd5/rl__response_8py_source.html#l00137">open_spiel.python.examples.rl_response.FirstActionAgent._num_actions</a>, <a class="el" href="../../da/db6/roshambo__population__example_8py_source.html#l00058">open_spiel.python.examples.roshambo_population_example.BotAgent._num_actions</a>, <a class="el" href="../../df/d6c/chat__game__base_8py_source.html#l01060">open_spiel.python.games.chat_games.chat_game_base.BaseChatGame._num_actions</a>, <a class="el" href="../../df/d6c/chat__game__base_8py_source.html#l00121">open_spiel.python.games.chat_games.chat_game_base.ChatGameState._num_actions</a>, <a class="el" href="../../d0/d69/jax_2deep__cfr_8py_source.html#l00176">open_spiel.python.jax.deep_cfr.DeepCFRSolver._num_actions</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00068">open_spiel.python.jax.dqn.DQN._num_actions</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00066">open_spiel.python.jax.nfsp.NFSP._num_actions</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00632">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._num_actions</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00037">open_spiel.python.jax.policy_gradient.NetA2C._num_actions</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00054">open_spiel.python.jax.policy_gradient.NetPG._num_actions</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00244">open_spiel.python.jax.policy_gradient.PolicyGradient._num_actions</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00074">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy._num_actions</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00090">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._num_actions</a>, <a class="el" href="../../dd/d6d/normal__form__game_8py_source.html#l00146">open_spiel.python.mfg.games.normal_form_game.MFGNormalFormState._num_actions</a>, <a class="el" href="../../d7/d95/pytorch_2deep__cfr_8py_source.html#l00259">open_spiel.python.pytorch.deep_cfr.DeepCFRSolver._num_actions</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00141">open_spiel.python.pytorch.dqn.DQN._num_actions</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00129">open_spiel.python.pytorch.eva.EVAAgent._num_actions</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00176">open_spiel.python.pytorch.policy_gradient.PolicyGradient._num_actions</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00158">open_spiel.python.algorithms.policy_gradient.PolicyGradient._num_critic_before_pi</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00246">open_spiel.python.jax.policy_gradient.PolicyGradient._num_critic_before_pi</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00180">open_spiel.python.pytorch.policy_gradient.PolicyGradient._num_critic_before_pi</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00168">open_spiel.python.algorithms.policy_gradient.PolicyGradient._num_learn_steps</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00649">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._num_learn_steps</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00256">open_spiel.python.jax.policy_gradient.PolicyGradient._num_learn_steps</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00191">open_spiel.python.pytorch.policy_gradient.PolicyGradient._num_learn_steps</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00651">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._pi_network</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00233">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_network</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00260">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_optimizer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00235">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_optimizer</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00195">open_spiel.python.algorithms.policy_gradient.PolicyGradient._policy_logits</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00267">open_spiel.python.pytorch.policy_gradient.PolicyGradient._policy_logits</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00186">open_spiel.python.algorithms.policy_gradient.PolicyGradient._policy_logits_layer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00200">open_spiel.python.pytorch.policy_gradient.PolicyGradient._policy_logits_layer</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00089">open_spiel.python.algorithms.dqn.DQN._prev_action</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00075">open_spiel.python.algorithms.nfsp.NFSP._prev_action</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00163">open_spiel.python.algorithms.policy_gradient.PolicyGradient._prev_action</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00141">open_spiel.python.algorithms.tabular_qlearner.QLearner._prev_action</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00226">open_spiel.python.algorithms.wolf_phc.WoLFPHC._prev_action</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00088">open_spiel.python.jax.dqn.DQN._prev_action</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00075">open_spiel.python.jax.nfsp.NFSP._prev_action</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00639">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._prev_action</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00251">open_spiel.python.jax.policy_gradient.PolicyGradient._prev_action</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00107">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._prev_action</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00160">open_spiel.python.pytorch.dqn.DQN._prev_action</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00186">open_spiel.python.pytorch.policy_gradient.PolicyGradient._prev_action</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00162">open_spiel.python.algorithms.policy_gradient.PolicyGradient._prev_time_step</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00638">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._prev_time_step</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00250">open_spiel.python.jax.policy_gradient.PolicyGradient._prev_time_step</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00109">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._prev_time_step</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00185">open_spiel.python.pytorch.policy_gradient.PolicyGradient._prev_time_step</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00206">open_spiel.python.algorithms.policy_gradient.PolicyGradient._q_values_layer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00223">open_spiel.python.pytorch.policy_gradient.PolicyGradient._q_values_layer</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00147">open_spiel.python.algorithms.dqn.DQN._savers</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00115">open_spiel.python.algorithms.nfsp.NFSP._savers</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00198">open_spiel.python.algorithms.policy_gradient.PolicyGradient._savers</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00114">open_spiel.python.jax.nfsp.NFSP._savers</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00207">open_spiel.python.pytorch.policy_gradient.PolicyGradient._savers</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00092">open_spiel.python.algorithms.dqn.DQN._step_counter</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00078">open_spiel.python.algorithms.nfsp.NFSP._step_counter</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00166">open_spiel.python.algorithms.policy_gradient.PolicyGradient._step_counter</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00091">open_spiel.python.jax.dqn.DQN._step_counter</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00078">open_spiel.python.jax.nfsp.NFSP._step_counter</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00647">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._step_counter</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00254">open_spiel.python.jax.policy_gradient.PolicyGradient._step_counter</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00115">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._step_counter</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00163">open_spiel.python.pytorch.dqn.DQN._step_counter</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00189">open_spiel.python.pytorch.policy_gradient.PolicyGradient._step_counter</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00232">open_spiel.python.pytorch.policy_gradient.PolicyGradient.pg_class</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00068">open_spiel.python.algorithms.dqn.DQN.player_id</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00135">open_spiel.python.algorithms.eva.EVAAgent.player_id</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00064">open_spiel.python.algorithms.nfsp.NFSP.player_id</a>, <a class="el" href="../../d6/d97/noisy__policy_8py_source.html#l00055">open_spiel.python.algorithms.noisy_policy.NoisyPolicy.player_id</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00152">open_spiel.python.algorithms.policy_gradient.PolicyGradient.player_id</a>, <a class="el" href="../../d5/d27/rnad_8py_source.html#l00670">open_spiel.python.algorithms.rnad.rnad.EnvStep.player_id</a>, <a class="el" href="../../d6/d15/bluechip__bridge_8py_source.html#l00222">open_spiel.python.bots.bluechip_bridge.BlueChipBridgeBot.player_id()</a>, <a class="el" href="../../d1/d9b/bluechip__bridge__uncontested__bidding_8py_source.html#l00208">open_spiel.python.bots.bluechip_bridge_uncontested_bidding.BlueChipBridgeBot.player_id()</a>, <a class="el" href="../../dc/d9c/bots_2policy_8py_source.html#l00043">open_spiel.python.bots.policy.PolicyBot.player_id()</a>, <a class="el" href="../../d6/d4c/uniform__random_8py_source.html#l00039">open_spiel.python.bots.uniform_random.UniformRandomBot.player_id()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00067">open_spiel.python.jax.dqn.DQN.player_id</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00065">open_spiel.python.jax.nfsp.NFSP.player_id</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00631">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.player_id</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00243">open_spiel.python.jax.policy_gradient.PolicyGradient.player_id</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00089">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.player_id</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00140">open_spiel.python.pytorch.dqn.DQN.player_id</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00127">open_spiel.python.pytorch.eva.EVAAgent.player_id</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00175">open_spiel.python.pytorch.policy_gradient.PolicyGradient.player_id</a>, <a class="el" href="../../de/d51/ppo_8py_source.html#l00198">open_spiel.python.pytorch.ppo.PPO.player_id</a>, <a class="el" href="../../d3/d26/dqn_8h_source.html#l00050">open_spiel::algorithms::torch_dqn::DQNSettings.player_id</a>, <a class="el" href="../../d9/d49/base_type_8h_source.html#l00032">open_spiel::baseT::P_UnitId.player_id</a>, <a class="el" href="../../d7/d2a/data_2paper__data_2routing__game__experiments_2utils_8py_source.html#l01009">utils.PurePolicyResponse.player_id</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00193">open_spiel.python.algorithms.policy_gradient.PolicyGradient.policy_logits_network</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00204">open_spiel.python.pytorch.policy_gradient.PolicyGradient.policy_logits_network</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_acff77770d69b724496d0d58fd14ccb43_cgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_acff77770d69b724496d0d58fd14ccb43_cgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_acff77770d69b724496d0d58fd14ccb43_cgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_acff77770d69b724496d0d58fd14ccb43_cgraph">
<area shape="rect" title=" " alt="" coords="5,245,218,286"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#ab0fcf96d53131b6a058a1fd851b43a68" title=" " alt="" coords="275,5,503,61"/>
<area shape="poly" title=" " alt="" coords="121,243,143,206,175,160,216,112,264,71,271,67,274,71,267,75,220,116,180,163,148,209,126,246"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#a3fce8652c5c58932e223922fc8799a3a" title=" " alt="" coords="296,85,482,141"/>
<area shape="poly" title=" " alt="" coords="134,242,191,197,264,151,281,143,283,148,267,156,195,201,138,246"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#aa7d88aa18275e11c79b98f3abf8bfb6d" title=" " alt="" coords="283,165,494,221"/>
<area shape="poly" title=" " alt="" coords="192,242,268,222,269,227,193,247"/>
<area shape="rect" href="../../d2/d62/classopen__spiel_1_1python_1_1bots_1_1bluechip__bridge_1_1_blue_chip_bridge_bot.html#acaaa9d432ff433c3672a24c8a7bc0a23" title=" " alt="" coords="272,245,506,286"/>
<area shape="poly" title=" " alt="" coords="218,262,257,262,257,268,218,268"/>
<area shape="rect" href="../../da/d4a/classopen__spiel_1_1python_1_1bots_1_1bluechip__bridge__uncontested__bidding_1_1_blue_chip_bridge_bot.html#a6b74e3d54f11b8147bd0806a1641e2b1" title=" " alt="" coords="266,309,512,365"/>
<area shape="poly" title=" " alt="" coords="193,284,265,302,264,307,192,289"/>
<area shape="rect" href="../../d1/d07/classopen__spiel_1_1python_1_1bots_1_1policy_1_1_policy_bot.html#ae1967e66d77d550419acdce692703543" title=" " alt="" coords="291,389,486,430"/>
<area shape="poly" title=" " alt="" coords="137,284,194,330,229,354,267,375,280,381,278,385,264,380,226,359,191,334,134,288"/>
<area shape="rect" href="../../d5/dc0/classopen__spiel_1_1python_1_1bots_1_1uniform__random_1_1_uniform_random_bot.html#ac93a0f081d67fda75f84f09b1e6e2b0b" title=" " alt="" coords="266,454,512,495"/>
<area shape="poly" title=" " alt="" coords="127,285,150,319,182,360,221,403,267,439,278,445,275,450,264,443,218,407,177,364,145,322,123,288"/>
</map>
</div>

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a5fbe9303efa1660b1b4738078819631d" name="a5fbe9303efa1660b1b4738078819631d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5fbe9303efa1660b1b4738078819631d">&#9670;&#160;</a></span>_act()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._act </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>info_state</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>legal_actions</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00263">263</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  263</span>  <span class="keyword">def </span>_act(self, info_state, legal_actions):</div>
<div class="line"><span class="lineno">  264</span>    <span class="comment"># Make a singleton batch for NN compatibility: [1, info_state_size]</span></div>
<div class="line"><span class="lineno">  265</span>    info_state = torch.Tensor(np.reshape(info_state, [1, -1]))</div>
<div class="line"><span class="lineno">  266</span>    torso_out = self._net_torso(info_state)</div>
<div class="line"><span class="lineno">  267</span>    self._policy_logits = self._policy_logits_layer(torso_out)</div>
<div class="line"><span class="lineno">  268</span>    policy_probs = F.softmax(self._policy_logits, dim=1).detach()</div>
<div class="line"><span class="lineno">  269</span> </div>
<div class="line"><span class="lineno">  270</span>    <span class="comment"># Remove illegal actions, re-normalize probs</span></div>
<div class="line"><span class="lineno">  271</span>    probs = np.zeros(self._num_actions)</div>
<div class="line"><span class="lineno">  272</span>    probs[legal_actions] = policy_probs[0][legal_actions]</div>
<div class="line"><span class="lineno">  273</span>    <span class="keywordflow">if</span> sum(probs) != 0:</div>
<div class="line"><span class="lineno">  274</span>      probs /= sum(probs)</div>
<div class="line"><span class="lineno">  275</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  276</span>      probs[legal_actions] = 1 / len(legal_actions)</div>
<div class="line"><span class="lineno">  277</span>    action = np.random.choice(len(probs), p=probs)</div>
<div class="line"><span class="lineno">  278</span>    <span class="keywordflow">return</span> action, probs</div>
<div class="line"><span class="lineno">  279</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00176">open_spiel.python.algorithms.nfsp.NFSP.step()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00184">open_spiel.python.jax.nfsp.NFSP.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00165">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a5fbe9303efa1660b1b4738078819631d_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a5fbe9303efa1660b1b4738078819631d_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a5fbe9303efa1660b1b4738078819631d_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a5fbe9303efa1660b1b4738078819631d_icgraph">
<area shape="rect" title=" " alt="" coords="1207,240,1418,280"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#ab179556d75b56778b2069bc9582177a5" title=" " alt="" coords="929,5,1114,61"/>
<area shape="poly" title=" " alt="" coords="1290,227,1267,191,1236,150,1200,110,1157,75,1113,54,1116,50,1160,71,1203,106,1241,147,1271,188,1294,225"/>
<area shape="rect" href="../../dd/d94/classopen__spiel_1_1python_1_1algorithms_1_1nfsp_1_1_n_f_s_p.html#aaa1e08b658aadea19d0ed6b09dad4de9" title=" " alt="" coords="910,329,1133,370"/>
<area shape="poly" title=" " alt="" coords="1230,288,1091,331,1090,326,1228,283"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a2cdd98bcd5917fa6d824f463e8c56f03" title=" " alt="" coords="907,394,1136,435"/>
<area shape="poly" title=" " alt="" coords="1282,293,1228,340,1195,364,1160,384,1129,396,1127,391,1158,379,1192,359,1224,336,1278,289"/>
<area shape="rect" href="../../da/dba/classopen__spiel_1_1python_1_1jax_1_1nfsp_1_1_n_f_s_p.html#a3839ae629edb089b840c98d176b7af92" title=" " alt="" coords="931,484,1112,524"/>
<area shape="poly" title=" " alt="" coords="1293,295,1239,371,1202,412,1160,449,1127,469,1091,485,1089,480,1124,465,1157,444,1198,408,1235,367,1289,292"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#a03aec30cd5c3aa917c53b196b8bf740b" title=" " alt="" coords="925,85,1118,126"/>
<area shape="poly" title=" " alt="" coords="1278,230,1224,184,1192,161,1158,141,1117,125,1119,121,1160,136,1195,156,1228,180,1282,226"/>
<area shape="rect" href="../../d7/d46/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1average__network__fictitious__play_1_1_average_policy.html#a279f2f41d18b26f151bd7a72579c2be0" title=" " alt="" coords="884,174,1159,215"/>
<area shape="poly" title=" " alt="" coords="1203,238,1115,218,1116,213,1205,233"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#af6b7739338748eab5d5000c55d046fe8" title=" " alt="" coords="916,240,1127,280"/>
<area shape="poly" title=" " alt="" coords="1191,262,1128,262,1128,257,1191,257"/>
<area shape="poly" title=" " alt="" coords="1069,316,1052,310,1021,307,993,309,976,314,970,320,973,327,967,329,965,319,974,310,993,304,1022,302,1053,305,1071,311"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#a14d11483beff07f087b51f3a2dd71135" title=" " alt="" coords="606,469,792,525"/>
<area shape="poly" title=" " alt="" coords="897,377,886,385,870,402,863,421,855,440,838,459,817,472,793,482,791,477,814,468,835,455,850,437,858,419,865,399,883,380,895,373"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#adb88039a6a02b4d0090a0abc5c3c5424" title=" " alt="" coords="606,93,792,134"/>
<area shape="poly" title=" " alt="" coords="925,324,902,311,882,294,869,274,862,255,859,218,856,182,849,165,835,148,814,134,791,125,793,120,817,130,838,145,853,163,861,181,864,218,867,254,873,272,886,290,905,307,927,320"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a7a91195b9b42b8536e06098e836b02e4" title=" " alt="" coords="573,158,824,199"/>
<area shape="poly" title=" " alt="" coords="932,325,906,311,882,294,866,273,859,252,851,232,835,214,814,202,817,197,838,210,856,229,864,250,871,270,886,290,909,306,935,320"/>
<area shape="rect" href="../../d2/dfd/classnash__evolutionary__search_1_1_nash_c_m_a_e_s.html#a42b13c1091631c52988a6391fe34038a" title=" " alt="" coords="610,224,787,264"/>
<area shape="poly" title=" " alt="" coords="957,325,836,280,787,266,788,261,837,275,959,320"/>
<area shape="rect" href="../../d5/dd9/classnash__random__search_1_1_nash_random_search.html#a9b9967669c24ceba55dc8ce00565a71a" title=" " alt="" coords="584,289,813,330"/>
<area shape="poly" title=" " alt="" coords="894,336,814,326,814,321,895,331"/>
<area shape="rect" href="../../d1/d50/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1bandit__regret_1_1_polynomial_weight_algorithm.html#a3b7ceacfd8a03895a691242d227c1ddd" title=" " alt="" coords="561,354,836,395"/>
<area shape="poly" title=" " alt="" coords="895,362,837,366,836,361,894,356"/>
<area shape="rect" href="../../d5/d11/classregret__minimizer_1_1_regret_minimizer.html#aa371edb5793c6a6cfbf51dc8597905dc" title=" " alt="" coords="566,419,831,445"/>
<area shape="poly" title=" " alt="" coords="910,377,885,385,862,397,837,409,793,421,792,416,835,404,859,392,883,380,908,372"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a44f0c375b5ef20bb1267524788ab16da" title=" " alt="" coords="281,158,513,199"/>
<area shape="poly" title=" " alt="" coords="557,181,514,181,514,176,557,176"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#ad1331eddb66a419f7336bc267b47d75e" title=" " alt="" coords="5,125,233,166"/>
<area shape="poly" title=" " alt="" coords="265,165,233,161,233,156,265,160"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#a14e053b461dc025b01a41453bc278c7d" title=" " alt="" coords="5,190,233,231"/>
<area shape="poly" title=" " alt="" coords="265,196,233,200,233,195,265,191"/>
<area shape="poly" title=" " alt="" coords="919,442,885,450,793,475,792,469,884,445,918,437"/>
<area shape="poly" title=" " alt="" coords="893,392,882,383,862,353,853,323,854,293,858,263,862,234,862,205,854,177,834,148,815,133,791,123,793,118,817,129,838,145,859,174,867,204,867,234,863,264,859,294,859,323,867,351,886,379,896,388"/>
<area shape="poly" title=" " alt="" coords="892,391,882,383,866,362,858,340,858,297,857,254,850,234,834,214,818,202,822,197,838,210,855,231,862,253,863,296,864,339,871,359,886,379,896,387"/>
<area shape="poly" title=" " alt="" coords="892,390,883,383,870,370,863,357,858,330,852,303,846,291,835,279,812,265,786,255,788,250,814,260,838,275,850,288,857,302,863,329,868,355,875,367,886,379,895,386"/>
<area shape="poly" title=" " alt="" coords="900,391,883,384,868,374,858,364,849,354,835,345,805,333,807,328,838,340,852,350,862,360,872,370,886,379,902,386"/>
<area shape="poly" title=" " alt="" coords="891,401,836,394,837,389,892,396"/>
<area shape="poly" title=" " alt="" coords="892,424,832,427,832,422,892,419"/>
<area shape="poly" title=" " alt="" coords="916,504,792,502,792,496,916,499"/>
<area shape="poly" title=" " alt="" coords="919,478,899,465,882,448,860,408,852,369,854,331,861,293,867,257,868,221,859,185,834,148,815,133,791,123,793,118,818,128,838,145,864,182,873,220,872,257,866,294,859,331,857,369,865,406,886,445,903,461,922,474"/>
<area shape="poly" title=" " alt="" coords="921,479,900,465,882,448,863,417,856,386,856,356,860,327,864,298,863,270,854,242,834,214,819,201,823,197,838,210,859,239,868,269,869,298,865,327,862,356,861,386,868,415,886,445,903,461,924,474"/>
<area shape="poly" title=" " alt="" coords="923,479,901,465,882,448,867,426,860,403,859,360,858,319,850,299,834,279,812,263,786,253,788,248,815,259,838,275,855,296,863,318,865,360,866,403,872,423,886,445,904,461,926,474"/>
<area shape="poly" title=" " alt="" coords="928,479,904,466,882,448,871,435,864,421,859,394,853,368,846,356,835,345,812,330,815,326,838,340,850,353,858,366,864,393,869,419,876,432,886,445,907,461,931,474"/>
<area shape="poly" title=" " alt="" coords="945,480,883,449,859,428,849,418,835,409,809,398,811,393,838,404,853,414,863,424,886,444,947,475"/>
<area shape="poly" title=" " alt="" coords="927,482,836,460,777,448,778,443,837,455,928,476"/>
<area shape="poly" title=" " alt="" coords="1069,470,1052,464,1021,462,993,464,976,469,970,475,973,482,967,484,965,473,974,464,993,459,1022,457,1053,459,1071,465"/>
<area shape="poly" title=" " alt="" coords="913,121,886,140,871,160,861,179,852,218,854,257,862,297,870,336,873,377,864,418,854,438,838,459,818,476,793,488,791,483,815,472,834,455,849,436,859,416,867,377,865,337,857,298,849,258,847,218,856,177,867,157,882,137,909,117"/>
<area shape="poly" title=" " alt="" coords="910,111,792,114,792,108,910,105"/>
<area shape="poly" title=" " alt="" coords="915,132,792,160,791,155,913,127"/>
<area shape="poly" title=" " alt="" coords="912,126,886,141,870,157,863,176,855,194,838,213,814,226,788,235,787,230,812,221,835,208,850,192,858,173,866,155,883,136,910,122"/>
<area shape="poly" title=" " alt="" coords="913,123,886,140,873,156,866,173,863,207,860,243,852,261,838,278,815,293,812,289,835,274,848,258,855,242,858,207,861,172,868,154,883,137,910,119"/>
<area shape="poly" title=" " alt="" coords="912,122,886,140,869,165,861,189,860,214,863,240,866,265,865,291,857,317,838,343,822,356,819,352,834,339,852,315,860,291,860,266,858,240,855,214,856,188,864,162,882,137,909,118"/>
<area shape="poly" title=" " alt="" coords="912,122,886,140,864,173,857,206,858,239,864,273,870,307,871,341,862,375,838,408,823,420,819,416,834,405,857,373,866,341,865,308,859,274,853,240,851,205,860,171,882,137,909,117"/>
<area shape="poly" title=" " alt="" coords="889,227,886,230,867,257,859,285,859,313,862,342,866,371,866,400,858,430,838,459,818,476,794,487,791,482,815,471,834,455,853,427,861,399,861,371,857,342,853,313,854,284,862,255,882,226,886,223"/>
<area shape="poly" title=" " alt="" coords="926,172,836,149,786,137,787,132,837,144,927,167"/>
<area shape="poly" title=" " alt="" coords="869,190,825,187,825,182,869,184"/>
<area shape="poly" title=" " alt="" coords="869,220,788,233,787,228,869,215"/>
<area shape="poly" title=" " alt="" coords="899,224,886,230,871,241,862,253,853,266,838,278,810,291,808,286,835,274,849,262,858,250,868,238,883,226,896,219"/>
<area shape="poly" title=" " alt="" coords="892,225,886,230,874,243,868,256,863,285,858,314,851,329,838,343,820,356,817,351,835,339,846,326,853,313,858,284,863,255,870,240,883,226,889,221"/>
<area shape="poly" title=" " alt="" coords="890,226,886,230,870,251,863,273,862,295,864,318,865,341,864,364,856,386,838,408,821,421,818,416,834,405,851,384,858,363,860,341,858,318,857,295,858,272,866,248,882,226,886,222"/>
<area shape="poly" title=" " alt="" coords="1069,161,1052,155,1021,153,993,155,976,160,970,165,973,173,967,174,965,164,974,155,993,149,1022,148,1053,150,1071,156"/>
<area shape="poly" title=" " alt="" coords="903,282,886,295,871,314,864,334,863,375,861,417,854,438,838,459,817,475,793,486,791,481,815,470,834,455,849,436,856,416,857,375,859,333,866,312,882,291,900,278"/>
<area shape="poly" title=" " alt="" coords="900,239,883,229,865,208,858,187,851,167,835,149,814,137,791,128,793,123,817,132,838,144,856,165,863,186,870,206,886,224,903,235"/>
<area shape="poly" title=" " alt="" coords="916,238,884,229,836,214,788,202,790,197,837,209,885,224,917,233"/>
<area shape="poly" title=" " alt="" coords="900,256,787,251,788,246,900,251"/>
<area shape="poly" title=" " alt="" coords="901,281,814,294,814,289,900,276"/>
<area shape="poly" title=" " alt="" coords="902,287,886,295,871,307,862,319,853,331,838,343,810,356,808,351,835,339,849,328,858,316,868,303,883,291,900,282"/>
<area shape="poly" title=" " alt="" coords="904,283,886,295,874,308,868,322,863,351,859,380,851,395,838,409,819,421,816,416,835,404,847,392,853,378,858,350,863,320,870,305,883,291,901,279"/>
</map>
</div>

</div>
</div>
<a id="ae72fa55445edd59df6e326a4902eb686" name="ae72fa55445edd59df6e326a4902eb686"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae72fa55445edd59df6e326a4902eb686">&#9670;&#160;</a></span>_add_episode_data_to_dataset()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_episode_data_to_dataset </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Add episode data to the buffer.</pre> 
<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00362">362</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  362</span>  <span class="keyword">def </span>_add_episode_data_to_dataset(self):</div>
<div class="line"><span class="lineno">  363</span>    <span class="stringliteral">&quot;&quot;&quot;Add episode data to the buffer.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  364</span>    info_states = [data.info_state <span class="keywordflow">for</span> data <span class="keywordflow">in</span> self._episode_data]</div>
<div class="line"><span class="lineno">  365</span>    rewards = [data.reward <span class="keywordflow">for</span> data <span class="keywordflow">in</span> self._episode_data]</div>
<div class="line"><span class="lineno">  366</span>    discount = [data.discount <span class="keywordflow">for</span> data <span class="keywordflow">in</span> self._episode_data]</div>
<div class="line"><span class="lineno">  367</span>    actions = [data.action <span class="keywordflow">for</span> data <span class="keywordflow">in</span> self._episode_data]</div>
<div class="line"><span class="lineno">  368</span> </div>
<div class="line"><span class="lineno">  369</span>    <span class="comment"># Calculate returns</span></div>
<div class="line"><span class="lineno">  370</span>    returns = np.array(rewards)</div>
<div class="line"><span class="lineno">  371</span>    <span class="keywordflow">for</span> idx <span class="keywordflow">in</span> reversed(range(len(rewards[:-1]))):</div>
<div class="line"><span class="lineno">  372</span>      returns[idx] = (</div>
<div class="line"><span class="lineno">  373</span>          rewards[idx] +</div>
<div class="line"><span class="lineno">  374</span>          discount[idx] * returns[idx + 1] * self._extra_discount)</div>
<div class="line"><span class="lineno">  375</span> </div>
<div class="line"><span class="lineno">  376</span>    <span class="comment"># Add flattened data points to dataset</span></div>
<div class="line"><span class="lineno">  377</span>    self._dataset[<span class="stringliteral">&quot;actions&quot;</span>].extend(actions)</div>
<div class="line"><span class="lineno">  378</span>    self._dataset[<span class="stringliteral">&quot;returns&quot;</span>].extend(returns)</div>
<div class="line"><span class="lineno">  379</span>    self._dataset[<span class="stringliteral">&quot;info_states&quot;</span>].extend(info_states)</div>
<div class="line"><span class="lineno">  380</span>    self._episode_data = []</div>
<div class="line"><span class="lineno">  381</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00161">open_spiel.python.algorithms.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00249">open_spiel.python.jax.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00184">open_spiel.python.pytorch.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00160">open_spiel.python.algorithms.policy_gradient.PolicyGradient._episode_data</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00248">open_spiel.python.jax.policy_gradient.PolicyGradient._episode_data</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00183">open_spiel.python.pytorch.policy_gradient.PolicyGradient._episode_data</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00157">open_spiel.python.algorithms.policy_gradient.PolicyGradient._extra_discount</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00245">open_spiel.python.jax.policy_gradient.PolicyGradient._extra_discount</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00179">open_spiel.python.pytorch.policy_gradient.PolicyGradient._extra_discount</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_ae72fa55445edd59df6e326a4902eb686_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_ae72fa55445edd59df6e326a4902eb686_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_ae72fa55445edd59df6e326a4902eb686_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_ae72fa55445edd59df6e326a4902eb686_icgraph">
<area shape="rect" title=" " alt="" coords="1161,195,1372,251"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a2cdd98bcd5917fa6d824f463e8c56f03" title=" " alt="" coords="884,169,1113,210"/>
<area shape="poly" title=" " alt="" coords="1145,211,1113,207,1113,201,1146,205"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#af6b7739338748eab5d5000c55d046fe8" title=" " alt="" coords="893,235,1104,275"/>
<area shape="poly" title=" " alt="" coords="1145,240,1105,245,1104,240,1145,235"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#a14d11483beff07f087b51f3a2dd71135" title=" " alt="" coords="606,382,792,438"/>
<area shape="poly" title=" " alt="" coords="890,221,886,225,872,242,866,260,863,297,860,334,853,353,838,372,817,387,794,398,791,393,814,383,834,368,848,350,855,333,858,296,860,259,868,240,882,221,887,217"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#adb88039a6a02b4d0090a0abc5c3c5424" title=" " alt="" coords="606,5,792,46"/>
<area shape="poly" title=" " alt="" coords="966,160,908,109,873,83,835,61,791,45,793,40,837,57,876,79,911,105,969,156"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a7a91195b9b42b8536e06098e836b02e4" title=" " alt="" coords="573,71,824,111"/>
<area shape="poly" title=" " alt="" coords="936,165,835,127,793,115,794,109,837,122,938,160"/>
<area shape="rect" href="../../d2/dfd/classnash__evolutionary__search_1_1_nash_c_m_a_e_s.html#a42b13c1091631c52988a6391fe34038a" title=" " alt="" coords="610,136,787,177"/>
<area shape="poly" title=" " alt="" coords="869,178,787,169,788,163,869,173"/>
<area shape="rect" href="../../d5/dd9/classnash__random__search_1_1_nash_random_search.html#a9b9967669c24ceba55dc8ce00565a71a" title=" " alt="" coords="584,201,813,242"/>
<area shape="poly" title=" " alt="" coords="869,206,814,212,814,207,868,201"/>
<area shape="rect" href="../../d1/d50/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1bandit__regret_1_1_polynomial_weight_algorithm.html#a3b7ceacfd8a03895a691242d227c1ddd" title=" " alt="" coords="561,267,836,307"/>
<area shape="poly" title=" " alt="" coords="903,218,886,225,862,241,837,256,803,269,801,264,835,251,859,236,883,221,901,213"/>
<area shape="rect" href="../../d5/d11/classregret__minimizer_1_1_regret_minimizer.html#aa371edb5793c6a6cfbf51dc8597905dc" title=" " alt="" coords="566,332,831,357"/>
<area shape="poly" title=" " alt="" coords="892,220,886,225,875,236,869,248,864,272,857,297,850,310,838,321,817,333,815,329,835,317,846,306,852,295,858,271,864,246,871,233,883,221,889,216"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a44f0c375b5ef20bb1267524788ab16da" title=" " alt="" coords="281,71,513,111"/>
<area shape="poly" title=" " alt="" coords="557,94,514,94,514,88,557,88"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#ad1331eddb66a419f7336bc267b47d75e" title=" " alt="" coords="5,37,233,78"/>
<area shape="poly" title=" " alt="" coords="265,78,233,74,233,69,265,73"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#a14e053b461dc025b01a41453bc278c7d" title=" " alt="" coords="5,103,233,143"/>
<area shape="poly" title=" " alt="" coords="265,109,233,113,233,107,265,104"/>
<area shape="poly" title=" " alt="" coords="964,287,907,331,838,372,793,390,791,385,835,367,904,326,961,283"/>
<area shape="poly" title=" " alt="" coords="886,227,882,223,867,203,859,182,858,140,857,99,850,80,834,61,815,47,791,37,794,32,817,42,838,57,854,77,862,98,863,140,865,181,872,200,886,220,890,223"/>
<area shape="poly" title=" " alt="" coords="889,229,883,224,871,211,864,199,858,173,852,149,846,138,835,126,815,114,818,109,838,122,850,134,857,147,863,172,869,197,875,208,886,220,892,224"/>
<area shape="poly" title=" " alt="" coords="900,231,883,224,859,208,835,192,786,175,788,170,838,187,862,203,886,219,902,226"/>
<area shape="poly" title=" " alt="" coords="877,244,814,237,814,232,878,239"/>
<area shape="poly" title=" " alt="" coords="878,271,837,275,836,270,877,265"/>
<area shape="poly" title=" " alt="" coords="938,284,837,322,787,333,786,328,836,316,937,279"/>
</map>
</div>

</div>
</div>
<a id="aa03ef306d33bfebbdb6c7478a965c26f" name="aa03ef306d33bfebbdb6c7478a965c26f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa03ef306d33bfebbdb6c7478a965c26f">&#9670;&#160;</a></span>_add_transition()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_transition </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>time_step</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Adds intra-episode transition to the `_episode_data` buffer.

Adds the transition from `self._prev_time_step` to `time_step`.

Args:
  time_step: an instance of rl_environment.TimeStep.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00382">382</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  382</span>  <span class="keyword">def </span>_add_transition(self, time_step):</div>
<div class="line"><span class="lineno">  383</span>    <span class="stringliteral">&quot;&quot;&quot;Adds intra-episode transition to the `_episode_data` buffer.</span></div>
<div class="line"><span class="lineno">  384</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  385</span><span class="stringliteral">    Adds the transition from `self._prev_time_step` to `time_step`.</span></div>
<div class="line"><span class="lineno">  386</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  387</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  388</span><span class="stringliteral">      time_step: an instance of rl_environment.TimeStep.</span></div>
<div class="line"><span class="lineno">  389</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  390</span>    <span class="keyword">assert</span> self._prev_time_step <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  391</span>    legal_actions = (</div>
<div class="line"><span class="lineno">  392</span>        self._prev_time_step.observations[<span class="stringliteral">&quot;legal_actions&quot;</span>][self.player_id])</div>
<div class="line"><span class="lineno">  393</span>    legal_actions_mask = np.zeros(self._num_actions)</div>
<div class="line"><span class="lineno">  394</span>    legal_actions_mask[legal_actions] = 1.0</div>
<div class="line"><span class="lineno">  395</span>    transition = Transition(</div>
<div class="line"><span class="lineno">  396</span>        info_state=(</div>
<div class="line"><span class="lineno">  397</span>            self._prev_time_step.observations[<span class="stringliteral">&quot;info_state&quot;</span>][self.player_id][:]),</div>
<div class="line"><span class="lineno">  398</span>        action=self._prev_action,</div>
<div class="line"><span class="lineno">  399</span>        reward=time_step.rewards[self.player_id],</div>
<div class="line"><span class="lineno">  400</span>        discount=time_step.discounts[self.player_id],</div>
<div class="line"><span class="lineno">  401</span>        legal_actions_mask=legal_actions_mask)</div>
<div class="line"><span class="lineno">  402</span> </div>
<div class="line"><span class="lineno">  403</span>    self._episode_data.append(transition)</div>
<div class="line"><span class="lineno">  404</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00160">open_spiel.python.algorithms.policy_gradient.PolicyGradient._episode_data</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00248">open_spiel.python.jax.policy_gradient.PolicyGradient._episode_data</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00183">open_spiel.python.pytorch.policy_gradient.PolicyGradient._episode_data</a>, <a class="el" href="../../dd/dc3/boltzmann__tabular__qlearner_8py_source.html#l00073">open_spiel.python.algorithms.boltzmann_tabular_qlearner.BoltzmannQLearner._num_actions</a>, <a class="el" href="../../d3/dc4/algorithms_2deep__cfr_8py_source.html#l00170">open_spiel.python.algorithms.deep_cfr.DeepCFRSolver._num_actions</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00213">open_spiel.python.algorithms.deep_cfr_tf2.AdvantageNetwork._num_actions</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00333">open_spiel.python.algorithms.deep_cfr_tf2.DeepCFRSolver._num_actions</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00148">open_spiel.python.algorithms.deep_cfr_tf2.PolicyNetwork._num_actions</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00070">open_spiel.python.algorithms.dqn.DQN._num_actions</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00137">open_spiel.python.algorithms.eva.EVAAgent._num_actions</a>, <a class="el" href="../../d9/d7e/mcts__agent_8py_source.html#l00033">open_spiel.python.algorithms.mcts_agent.MCTSAgent._num_actions</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00066">open_spiel.python.algorithms.nfsp.NFSP._num_actions</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00154">open_spiel.python.algorithms.policy_gradient.PolicyGradient._num_actions</a>, <a class="el" href="../../d3/df2/random__agent_8py_source.html#l00027">open_spiel.python.algorithms.random_agent.RandomAgent._num_actions</a>, <a class="el" href="../../d8/d79/tabular__multiagent__qlearner_8py_source.html#l00190">open_spiel.python.algorithms.tabular_multiagent_qlearner.MultiagentQLearner._num_actions</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00046">open_spiel.python.algorithms.tabular_qlearner.QLearner._num_actions</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00072">open_spiel.python.algorithms.wolf_phc.WoLFPHC._num_actions</a>, <a class="el" href="../../d6/d15/bluechip__bridge_8py_source.html#l00214">open_spiel.python.bots.bluechip_bridge.BlueChipBridgeBot._num_actions</a>, <a class="el" href="../../dc/d9b/catch_8py_source.html#l00043">open_spiel.python.environments.catch.Environment._num_actions</a>, <a class="el" href="../../d0/dd5/rl__response_8py_source.html#l00137">open_spiel.python.examples.rl_response.FirstActionAgent._num_actions</a>, <a class="el" href="../../da/db6/roshambo__population__example_8py_source.html#l00058">open_spiel.python.examples.roshambo_population_example.BotAgent._num_actions</a>, <a class="el" href="../../df/d6c/chat__game__base_8py_source.html#l01060">open_spiel.python.games.chat_games.chat_game_base.BaseChatGame._num_actions</a>, <a class="el" href="../../df/d6c/chat__game__base_8py_source.html#l00121">open_spiel.python.games.chat_games.chat_game_base.ChatGameState._num_actions</a>, <a class="el" href="../../d0/d69/jax_2deep__cfr_8py_source.html#l00176">open_spiel.python.jax.deep_cfr.DeepCFRSolver._num_actions</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00068">open_spiel.python.jax.dqn.DQN._num_actions</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00066">open_spiel.python.jax.nfsp.NFSP._num_actions</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00632">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._num_actions</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00037">open_spiel.python.jax.policy_gradient.NetA2C._num_actions</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00054">open_spiel.python.jax.policy_gradient.NetPG._num_actions</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00244">open_spiel.python.jax.policy_gradient.PolicyGradient._num_actions</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00074">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy._num_actions</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00090">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._num_actions</a>, <a class="el" href="../../dd/d6d/normal__form__game_8py_source.html#l00146">open_spiel.python.mfg.games.normal_form_game.MFGNormalFormState._num_actions</a>, <a class="el" href="../../d7/d95/pytorch_2deep__cfr_8py_source.html#l00259">open_spiel.python.pytorch.deep_cfr.DeepCFRSolver._num_actions</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00141">open_spiel.python.pytorch.dqn.DQN._num_actions</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00129">open_spiel.python.pytorch.eva.EVAAgent._num_actions</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00176">open_spiel.python.pytorch.policy_gradient.PolicyGradient._num_actions</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00089">open_spiel.python.algorithms.dqn.DQN._prev_action</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00075">open_spiel.python.algorithms.nfsp.NFSP._prev_action</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00163">open_spiel.python.algorithms.policy_gradient.PolicyGradient._prev_action</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00141">open_spiel.python.algorithms.tabular_qlearner.QLearner._prev_action</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00226">open_spiel.python.algorithms.wolf_phc.WoLFPHC._prev_action</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00088">open_spiel.python.jax.dqn.DQN._prev_action</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00075">open_spiel.python.jax.nfsp.NFSP._prev_action</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00639">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._prev_action</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00251">open_spiel.python.jax.policy_gradient.PolicyGradient._prev_action</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00107">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._prev_action</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00160">open_spiel.python.pytorch.dqn.DQN._prev_action</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00186">open_spiel.python.pytorch.policy_gradient.PolicyGradient._prev_action</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00162">open_spiel.python.algorithms.policy_gradient.PolicyGradient._prev_time_step</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00638">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._prev_time_step</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00250">open_spiel.python.jax.policy_gradient.PolicyGradient._prev_time_step</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00109">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._prev_time_step</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00185">open_spiel.python.pytorch.policy_gradient.PolicyGradient._prev_time_step</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00068">open_spiel.python.algorithms.dqn.DQN.player_id</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00135">open_spiel.python.algorithms.eva.EVAAgent.player_id</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00064">open_spiel.python.algorithms.nfsp.NFSP.player_id</a>, <a class="el" href="../../d6/d97/noisy__policy_8py_source.html#l00055">open_spiel.python.algorithms.noisy_policy.NoisyPolicy.player_id</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00152">open_spiel.python.algorithms.policy_gradient.PolicyGradient.player_id</a>, <a class="el" href="../../d5/d27/rnad_8py_source.html#l00670">open_spiel.python.algorithms.rnad.rnad.EnvStep.player_id</a>, <a class="el" href="../../d6/d15/bluechip__bridge_8py_source.html#l00222">open_spiel.python.bots.bluechip_bridge.BlueChipBridgeBot.player_id()</a>, <a class="el" href="../../d1/d9b/bluechip__bridge__uncontested__bidding_8py_source.html#l00208">open_spiel.python.bots.bluechip_bridge_uncontested_bidding.BlueChipBridgeBot.player_id()</a>, <a class="el" href="../../dc/d9c/bots_2policy_8py_source.html#l00043">open_spiel.python.bots.policy.PolicyBot.player_id()</a>, <a class="el" href="../../d6/d4c/uniform__random_8py_source.html#l00039">open_spiel.python.bots.uniform_random.UniformRandomBot.player_id()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00067">open_spiel.python.jax.dqn.DQN.player_id</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00065">open_spiel.python.jax.nfsp.NFSP.player_id</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00631">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.player_id</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00243">open_spiel.python.jax.policy_gradient.PolicyGradient.player_id</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00089">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.player_id</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00140">open_spiel.python.pytorch.dqn.DQN.player_id</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00127">open_spiel.python.pytorch.eva.EVAAgent.player_id</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00175">open_spiel.python.pytorch.policy_gradient.PolicyGradient.player_id</a>, <a class="el" href="../../de/d51/ppo_8py_source.html#l00198">open_spiel.python.pytorch.ppo.PPO.player_id</a>, <a class="el" href="../../d3/d26/dqn_8h_source.html#l00050">open_spiel::algorithms::torch_dqn::DQNSettings.player_id</a>, <a class="el" href="../../d9/d49/base_type_8h_source.html#l00032">open_spiel::baseT::P_UnitId.player_id</a>, and <a class="el" href="../../d7/d2a/data_2paper__data_2routing__game__experiments_2utils_8py_source.html#l01009">utils.PurePolicyResponse.player_id</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00176">open_spiel.python.algorithms.nfsp.NFSP.step()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00184">open_spiel.python.jax.nfsp.NFSP.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00165">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa03ef306d33bfebbdb6c7478a965c26f_cgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa03ef306d33bfebbdb6c7478a965c26f_cgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa03ef306d33bfebbdb6c7478a965c26f_cgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa03ef306d33bfebbdb6c7478a965c26f_cgraph">
<area shape="rect" title=" " alt="" coords="5,106,217,162"/>
<area shape="rect" href="../../d2/d62/classopen__spiel_1_1python_1_1bots_1_1bluechip__bridge_1_1_blue_chip_bridge_bot.html#acaaa9d432ff433c3672a24c8a7bc0a23" title=" " alt="" coords="271,5,504,46"/>
<area shape="poly" title=" " alt="" coords="161,103,210,78,264,55,283,49,285,54,266,60,213,83,164,108"/>
<area shape="rect" href="../../da/d4a/classopen__spiel_1_1python_1_1bots_1_1bluechip__bridge__uncontested__bidding_1_1_blue_chip_bridge_bot.html#a6b74e3d54f11b8147bd0806a1641e2b1" title=" " alt="" coords="265,70,511,126"/>
<area shape="poly" title=" " alt="" coords="217,117,249,113,249,118,218,123"/>
<area shape="rect" href="../../d1/d07/classopen__spiel_1_1python_1_1bots_1_1policy_1_1_policy_bot.html#ae1967e66d77d550419acdce692703543" title=" " alt="" coords="290,149,486,190"/>
<area shape="poly" title=" " alt="" coords="218,145,275,152,274,158,217,150"/>
<area shape="rect" href="../../d5/dc0/classopen__spiel_1_1python_1_1bots_1_1uniform__random_1_1_uniform_random_bot.html#ac93a0f081d67fda75f84f09b1e6e2b0b" title=" " alt="" coords="265,215,511,255"/>
<area shape="poly" title=" " alt="" coords="171,160,266,199,290,207,288,212,264,204,169,165"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa03ef306d33bfebbdb6c7478a965c26f_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa03ef306d33bfebbdb6c7478a965c26f_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa03ef306d33bfebbdb6c7478a965c26f_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa03ef306d33bfebbdb6c7478a965c26f_icgraph">
<area shape="rect" title=" " alt="" coords="1207,210,1418,266"/>
<area shape="rect" href="../../dd/d94/classopen__spiel_1_1python_1_1algorithms_1_1nfsp_1_1_n_f_s_p.html#aaa1e08b658aadea19d0ed6b09dad4de9" title=" " alt="" coords="910,29,1133,70"/>
<area shape="poly" title=" " alt="" coords="1280,200,1227,140,1194,110,1157,85,1131,73,1133,68,1160,81,1197,106,1231,136,1284,196"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a2cdd98bcd5917fa6d824f463e8c56f03" title=" " alt="" coords="907,95,1136,135"/>
<area shape="poly" title=" " alt="" coords="1256,203,1209,175,1158,151,1122,138,1123,133,1160,146,1211,171,1259,199"/>
<area shape="rect" href="../../da/dba/classopen__spiel_1_1python_1_1jax_1_1nfsp_1_1_n_f_s_p.html#a3839ae629edb089b840c98d176b7af92" title=" " alt="" coords="931,184,1112,225"/>
<area shape="poly" title=" " alt="" coords="1191,226,1112,217,1112,212,1191,221"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#a03aec30cd5c3aa917c53b196b8bf740b" title=" " alt="" coords="925,249,1118,290"/>
<area shape="poly" title=" " alt="" coords="1191,254,1118,262,1118,256,1191,248"/>
<area shape="rect" href="../../d7/d46/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1average__network__fictitious__play_1_1_average_policy.html#a279f2f41d18b26f151bd7a72579c2be0" title=" " alt="" coords="884,339,1159,379"/>
<area shape="poly" title=" " alt="" coords="1231,274,1073,341,1071,336,1228,270"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#af6b7739338748eab5d5000c55d046fe8" title=" " alt="" coords="916,404,1127,445"/>
<area shape="poly" title=" " alt="" coords="1284,280,1230,339,1197,368,1160,393,1129,407,1127,402,1157,389,1194,364,1227,335,1280,276"/>
<area shape="poly" title=" " alt="" coords="1069,16,1052,10,1021,8,993,10,976,15,970,21,973,28,967,29,965,19,974,10,993,5,1022,3,1053,5,1071,11"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#a14d11483beff07f087b51f3a2dd71135" title=" " alt="" coords="606,400,792,456"/>
<area shape="poly" title=" " alt="" coords="898,74,886,85,872,103,862,122,853,159,855,197,862,234,869,273,872,312,863,351,853,370,838,390,818,407,793,419,791,414,815,403,834,386,849,368,858,349,866,311,864,273,857,235,850,197,848,159,857,120,867,101,882,81,895,70"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#adb88039a6a02b4d0090a0abc5c3c5424" title=" " alt="" coords="606,24,792,65"/>
<area shape="poly" title=" " alt="" coords="894,50,792,49,792,43,895,45"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a7a91195b9b42b8536e06098e836b02e4" title=" " alt="" coords="573,89,824,130"/>
<area shape="poly" title=" " alt="" coords="895,76,812,91,811,86,894,71"/>
<area shape="rect" href="../../d2/dfd/classnash__evolutionary__search_1_1_nash_c_m_a_e_s.html#a42b13c1091631c52988a6391fe34038a" title=" " alt="" coords="610,155,787,195"/>
<area shape="poly" title=" " alt="" coords="897,79,886,85,871,99,863,114,854,129,838,144,814,156,788,165,787,160,812,151,835,139,850,126,858,111,867,96,883,81,894,74"/>
<area shape="rect" href="../../d5/dd9/classnash__random__search_1_1_nash_random_search.html#a9b9967669c24ceba55dc8ce00565a71a" title=" " alt="" coords="584,220,813,261"/>
<area shape="poly" title=" " alt="" coords="898,76,886,85,874,99,867,114,863,145,859,177,852,194,838,209,815,224,812,220,835,205,847,191,854,176,858,145,862,113,869,96,883,81,895,72"/>
<area shape="rect" href="../../d1/d50/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1bandit__regret_1_1_polynomial_weight_algorithm.html#a3b7ceacfd8a03895a691242d227c1ddd" title=" " alt="" coords="561,285,836,326"/>
<area shape="poly" title=" " alt="" coords="898,75,886,85,869,107,862,130,861,154,863,177,865,202,864,226,856,250,838,274,822,287,819,283,834,270,851,248,859,225,860,202,858,178,856,154,857,129,865,105,882,81,894,71"/>
<area shape="rect" href="../../d5/d11/classregret__minimizer_1_1_regret_minimizer.html#aa371edb5793c6a6cfbf51dc8597905dc" title=" " alt="" coords="566,350,831,376"/>
<area shape="poly" title=" " alt="" coords="898,75,886,85,865,116,858,147,858,179,864,211,869,243,870,276,861,308,838,340,822,352,819,348,834,336,856,306,864,275,864,244,859,212,853,179,852,146,860,114,882,81,895,70"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a44f0c375b5ef20bb1267524788ab16da" title=" " alt="" coords="281,89,513,130"/>
<area shape="poly" title=" " alt="" coords="557,112,514,112,514,107,557,107"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#ad1331eddb66a419f7336bc267b47d75e" title=" " alt="" coords="5,56,233,97"/>
<area shape="poly" title=" " alt="" coords="265,96,233,93,233,87,265,91"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#a14e053b461dc025b01a41453bc278c7d" title=" " alt="" coords="5,121,233,162"/>
<area shape="poly" title=" " alt="" coords="265,128,233,131,233,126,265,122"/>
<area shape="poly" title=" " alt="" coords="896,142,886,150,866,179,858,208,858,237,862,267,867,298,867,328,859,359,838,390,817,407,793,419,791,414,815,403,834,387,854,357,862,328,861,298,857,268,853,238,853,207,861,177,882,147,892,138"/>
<area shape="poly" title=" " alt="" coords="910,93,792,67,793,62,911,88"/>
<area shape="poly" title=" " alt="" coords="892,116,825,114,825,109,892,110"/>
<area shape="poly" title=" " alt="" coords="894,141,788,161,787,156,893,136"/>
<area shape="poly" title=" " alt="" coords="896,145,886,150,871,164,863,179,854,194,838,209,813,222,811,217,835,205,850,191,858,176,867,161,883,146,894,140"/>
<area shape="poly" title=" " alt="" coords="895,143,886,150,874,165,867,179,863,211,859,243,852,259,838,274,820,287,817,283,835,270,847,256,854,241,858,210,862,178,869,162,883,146,892,139"/>
<area shape="poly" title=" " alt="" coords="896,142,886,150,870,173,862,196,861,219,864,243,866,268,865,292,856,316,838,340,821,352,818,348,834,336,852,314,859,291,860,268,858,244,856,220,857,195,865,170,882,147,892,138"/>
<area shape="poly" title=" " alt="" coords="918,220,886,240,872,257,865,275,863,313,860,351,853,371,838,390,817,406,794,417,791,412,815,401,834,386,848,368,855,350,857,312,860,274,867,255,883,236,915,215"/>
<area shape="poly" title=" " alt="" coords="935,180,908,166,883,149,867,131,859,113,851,96,835,80,791,60,793,55,838,75,855,93,863,110,871,128,886,145,911,162,937,175"/>
<area shape="poly" title=" " alt="" coords="946,181,836,146,789,133,791,128,837,140,948,176"/>
<area shape="poly" title=" " alt="" coords="916,197,787,186,787,180,916,192"/>
<area shape="poly" title=" " alt="" coords="916,219,814,230,814,225,915,213"/>
<area shape="poly" title=" " alt="" coords="917,228,886,240,862,257,838,275,805,287,803,282,835,270,859,253,883,235,915,223"/>
<area shape="poly" title=" " alt="" coords="918,222,886,240,875,251,869,263,863,289,857,315,850,328,838,340,818,352,815,347,835,336,846,324,852,313,858,288,864,261,871,248,883,236,915,217"/>
<area shape="poly" title=" " alt="" coords="1069,171,1052,165,1021,163,993,165,976,169,970,175,973,183,967,184,965,174,974,165,993,159,1022,157,1053,160,1071,166"/>
<area shape="poly" title=" " alt="" coords="912,290,886,305,869,325,863,346,856,369,838,390,817,404,793,414,791,409,814,399,835,386,851,366,858,345,865,322,883,301,909,286"/>
<area shape="poly" title=" " alt="" coords="909,256,883,238,867,218,859,198,858,157,856,117,849,98,834,80,815,65,791,56,793,51,817,61,838,76,854,96,861,116,863,157,864,197,871,216,886,234,912,252"/>
<area shape="poly" title=" " alt="" coords="909,254,883,238,871,227,864,215,858,190,852,167,845,156,835,145,815,133,818,128,838,141,850,152,857,165,863,189,869,213,875,224,886,234,912,250"/>
<area shape="poly" title=" " alt="" coords="910,248,883,239,859,225,835,211,787,195,788,190,837,206,862,220,885,234,912,243"/>
<area shape="poly" title=" " alt="" coords="910,262,813,253,814,248,910,257"/>
<area shape="poly" title=" " alt="" coords="910,285,837,293,837,288,909,279"/>
<area shape="poly" title=" " alt="" coords="911,295,886,305,862,323,852,332,837,340,801,352,800,347,835,335,849,327,859,319,883,301,909,290"/>
<area shape="poly" title=" " alt="" coords="909,386,793,411,792,406,908,381"/>
<area shape="poly" title=" " alt="" coords="921,334,900,321,882,303,864,274,857,244,857,215,860,187,863,160,862,133,854,106,834,80,815,65,791,55,793,50,817,60,838,76,858,104,867,132,868,160,865,188,862,216,862,244,869,271,886,300,904,316,924,329"/>
<area shape="poly" title=" " alt="" coords="924,334,902,321,882,303,868,282,861,261,859,221,857,182,849,163,834,145,818,132,821,128,838,141,854,161,862,181,865,221,866,260,873,280,886,300,905,316,927,330"/>
<area shape="poly" title=" " alt="" coords="930,335,905,321,882,304,865,279,859,255,852,232,835,210,812,197,786,187,788,182,814,192,838,206,857,229,864,253,870,277,886,300,908,316,933,330"/>
<area shape="poly" title=" " alt="" coords="951,335,883,304,859,289,835,276,799,264,801,259,837,271,862,285,886,299,954,330"/>
<area shape="poly" title=" " alt="" coords="879,338,825,329,826,324,880,333"/>
<area shape="poly" title=" " alt="" coords="869,364,832,364,832,359,869,358"/>
<area shape="poly" title=" " alt="" coords="1069,326,1052,320,1021,317,993,319,976,324,970,330,973,337,967,339,965,329,974,319,993,314,1022,312,1053,314,1071,321"/>
<area shape="poly" title=" " alt="" coords="900,428,792,430,792,425,900,423"/>
<area shape="poly" title=" " alt="" coords="901,408,882,393,867,373,856,353,847,313,850,273,858,234,866,195,868,156,859,118,849,99,834,80,815,64,791,54,793,49,818,59,838,76,854,96,864,116,873,156,871,195,863,235,855,274,853,313,861,351,871,370,886,389,904,404"/>
<area shape="poly" title=" " alt="" coords="901,407,882,393,861,361,852,330,853,298,858,267,862,236,863,205,855,175,834,145,820,133,823,128,838,141,860,173,868,204,868,236,863,267,858,298,858,329,866,359,886,389,904,403"/>
<area shape="poly" title=" " alt="" coords="900,406,882,393,865,370,857,346,856,323,858,299,859,276,858,254,851,232,834,210,812,194,787,184,788,179,815,190,838,206,855,229,863,253,865,276,863,300,861,323,863,345,870,367,886,389,903,402"/>
<area shape="poly" title=" " alt="" coords="900,405,883,393,870,378,862,363,858,333,853,303,847,289,835,276,812,261,815,257,838,272,851,286,858,302,863,332,867,362,874,375,886,389,904,401"/>
<area shape="poly" title=" " alt="" coords="900,402,883,393,867,380,858,366,850,352,835,340,813,329,815,324,838,335,854,349,863,363,871,376,886,389,903,397"/>
<area shape="poly" title=" " alt="" coords="900,403,836,391,773,379,774,374,837,386,901,398"/>
</map>
</div>

</div>
</div>
<a id="a6cc5d6bb8de010a9f67e71cc09e3ff5c" name="a6cc5d6bb8de010a9f67e71cc09e3ff5c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6cc5d6bb8de010a9f67e71cc09e3ff5c">&#9670;&#160;</a></span>_critic_update()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_update </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute the Critic loss on sampled transitions &amp; perform a critic update.

Returns:
  The average Critic loss obtained on this batch.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00405">405</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  405</span>  <span class="keyword">def </span>_critic_update(self):</div>
<div class="line"><span class="lineno">  406</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the Critic loss on sampled transitions &amp; perform a critic update.</span></div>
<div class="line"><span class="lineno">  407</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  408</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><span class="lineno">  409</span><span class="stringliteral">      The average Critic loss obtained on this batch.</span></div>
<div class="line"><span class="lineno">  410</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  411</span>    <span class="comment"># TODO(author3): illegal action handling.</span></div>
<div class="line"><span class="lineno">  412</span>    info_state = torch.Tensor(self._dataset[<span class="stringliteral">&quot;info_states&quot;</span>])</div>
<div class="line"><span class="lineno">  413</span>    action = torch.LongTensor(self._dataset[<span class="stringliteral">&quot;actions&quot;</span>])</div>
<div class="line"><span class="lineno">  414</span>    return_ = torch.Tensor(self._dataset[<span class="stringliteral">&quot;returns&quot;</span>])</div>
<div class="line"><span class="lineno">  415</span>    torso_out = self._net_torso(info_state)</div>
<div class="line"><span class="lineno">  416</span> </div>
<div class="line"><span class="lineno">  417</span>    <span class="comment"># Critic loss</span></div>
<div class="line"><span class="lineno">  418</span>    <span class="comment"># Baseline loss in case of A2C</span></div>
<div class="line"><span class="lineno">  419</span>    <span class="keywordflow">if</span> self._loss_class.__name__ == <span class="stringliteral">&quot;BatchA2CLoss&quot;</span>:</div>
<div class="line"><span class="lineno">  420</span>      baseline = torch.squeeze(self._baseline_layer(torso_out), dim=1)</div>
<div class="line"><span class="lineno">  421</span>      critic_loss = torch.mean(F.mse_loss(baseline, return_))</div>
<div class="line"><span class="lineno">  422</span>      self.minimize_with_clipping(self._baseline_layer, self._critic_optimizer,</div>
<div class="line"><span class="lineno">  423</span>                                  critic_loss)</div>
<div class="line"><span class="lineno">  424</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  425</span>      <span class="comment"># Q-loss otherwise.</span></div>
<div class="line"><span class="lineno">  426</span>      q_values = self._q_values_layer(torso_out)</div>
<div class="line"><span class="lineno">  427</span>      action_indices = torch.stack(</div>
<div class="line"><span class="lineno">  428</span>          [torch.arange(q_values.shape[0], dtype=torch.long), action], dim=0)</div>
<div class="line"><span class="lineno">  429</span>      value_predictions = q_values[list(action_indices)]</div>
<div class="line"><span class="lineno">  430</span>      critic_loss = torch.mean(F.mse_loss(value_predictions, return_))</div>
<div class="line"><span class="lineno">  431</span>      self.minimize_with_clipping(self._q_values_layer, self._critic_optimizer,</div>
<div class="line"><span class="lineno">  432</span>                                  critic_loss)</div>
<div class="line"><span class="lineno">  433</span>    self._last_critic_loss_value = critic_loss</div>
<div class="line"><span class="lineno">  434</span>    <span class="keywordflow">return</span> critic_loss</div>
<div class="line"><span class="lineno">  435</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00202">open_spiel.python.algorithms.policy_gradient.PolicyGradient._baseline_layer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00218">open_spiel.python.pytorch.policy_gradient.PolicyGradient._baseline_layer</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00228">open_spiel.python.algorithms.policy_gradient.PolicyGradient._critic_optimizer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00211">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_optimizer</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00161">open_spiel.python.algorithms.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00249">open_spiel.python.jax.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00184">open_spiel.python.pytorch.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00382">open_spiel.python.algorithms.policy_gradient.PolicyGradient._last_critic_loss_value</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00396">open_spiel.python.jax.policy_gradient.PolicyGradient._last_critic_loss_value</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00360">open_spiel.python.pytorch.policy_gradient.PolicyGradient._last_critic_loss_value</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00150">open_spiel.python.algorithms.policy_gradient.PolicyGradient._loss_class</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00173">open_spiel.python.pytorch.policy_gradient.PolicyGradient._loss_class</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00183">open_spiel.python.algorithms.policy_gradient.PolicyGradient._net_torso</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00198">open_spiel.python.pytorch.policy_gradient.PolicyGradient._net_torso</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00206">open_spiel.python.algorithms.policy_gradient.PolicyGradient._q_values_layer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00223">open_spiel.python.pytorch.policy_gradient.PolicyGradient._q_values_layer</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00255">open_spiel.python.pytorch.policy_gradient.PolicyGradient.minimize_with_clipping()</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a6cc5d6bb8de010a9f67e71cc09e3ff5c_cgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a6cc5d6bb8de010a9f67e71cc09e3ff5c_cgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a6cc5d6bb8de010a9f67e71cc09e3ff5c_cgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a6cc5d6bb8de010a9f67e71cc09e3ff5c_cgraph">
<area shape="rect" title=" " alt="" coords="5,13,254,54"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#accd3df94affd3092ece7c5110a1de359" title=" " alt="" coords="302,5,521,61"/>
<area shape="poly" title=" " alt="" coords="254,30,286,30,286,36,254,36"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a6cc5d6bb8de010a9f67e71cc09e3ff5c_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a6cc5d6bb8de010a9f67e71cc09e3ff5c_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a6cc5d6bb8de010a9f67e71cc09e3ff5c_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a6cc5d6bb8de010a9f67e71cc09e3ff5c_icgraph">
<area shape="rect" title=" " alt="" coords="1161,201,1409,242"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a2cdd98bcd5917fa6d824f463e8c56f03" title=" " alt="" coords="884,136,1113,177"/>
<area shape="poly" title=" " alt="" coords="1177,200,1090,180,1091,175,1178,195"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#a03aec30cd5c3aa917c53b196b8bf740b" title=" " alt="" coords="902,201,1095,242"/>
<area shape="poly" title=" " alt="" coords="1145,224,1095,224,1095,219,1145,219"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#af6b7739338748eab5d5000c55d046fe8" title=" " alt="" coords="893,267,1104,307"/>
<area shape="poly" title=" " alt="" coords="1178,249,1091,269,1090,263,1177,243"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#a14d11483beff07f087b51f3a2dd71135" title=" " alt="" coords="606,382,792,438"/>
<area shape="poly" title=" " alt="" coords="890,188,886,191,870,213,863,235,863,280,863,325,855,349,838,372,817,388,793,399,791,394,815,383,834,368,850,346,857,324,858,280,858,234,866,211,882,188,886,184"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#adb88039a6a02b4d0090a0abc5c3c5424" title=" " alt="" coords="606,5,792,46"/>
<area shape="poly" title=" " alt="" coords="955,129,899,94,835,61,791,47,793,42,837,57,902,89,958,125"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a7a91195b9b42b8536e06098e836b02e4" title=" " alt="" coords="573,71,824,111"/>
<area shape="poly" title=" " alt="" coords="887,135,795,115,796,109,888,130"/>
<area shape="rect" href="../../d2/dfd/classnash__evolutionary__search_1_1_nash_c_m_a_e_s.html#a42b13c1091631c52988a6391fe34038a" title=" " alt="" coords="610,136,787,177"/>
<area shape="poly" title=" " alt="" coords="869,159,787,159,787,154,869,154"/>
<area shape="rect" href="../../d5/dd9/classnash__random__search_1_1_nash_random_search.html#a9b9967669c24ceba55dc8ce00565a71a" title=" " alt="" coords="584,201,813,242"/>
<area shape="poly" title=" " alt="" coords="888,183,796,203,795,198,887,178"/>
<area shape="rect" href="../../d1/d50/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1bandit__regret_1_1_polynomial_weight_algorithm.html#a3b7ceacfd8a03895a691242d227c1ddd" title=" " alt="" coords="561,267,836,307"/>
<area shape="poly" title=" " alt="" coords="894,186,886,192,871,207,863,223,854,240,838,256,814,268,812,264,835,252,850,237,858,221,867,204,883,188,892,182"/>
<area shape="rect" href="../../d5/d11/classregret__minimizer_1_1_regret_minimizer.html#aa371edb5793c6a6cfbf51dc8597905dc" title=" " alt="" coords="566,332,831,357"/>
<area shape="poly" title=" " alt="" coords="891,187,886,192,874,207,867,223,864,256,860,289,852,305,838,321,820,333,817,329,835,317,848,302,855,287,858,255,862,221,869,204,882,188,888,183"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a44f0c375b5ef20bb1267524788ab16da" title=" " alt="" coords="281,71,513,111"/>
<area shape="poly" title=" " alt="" coords="557,94,514,94,514,88,557,88"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#ad1331eddb66a419f7336bc267b47d75e" title=" " alt="" coords="5,37,233,78"/>
<area shape="poly" title=" " alt="" coords="265,78,233,74,233,69,265,73"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#a14e053b461dc025b01a41453bc278c7d" title=" " alt="" coords="5,103,233,143"/>
<area shape="poly" title=" " alt="" coords="265,109,233,113,233,107,265,104"/>
<area shape="poly" title=" " alt="" coords="891,253,886,257,874,270,868,284,863,313,858,342,851,357,838,372,817,387,793,397,791,392,814,382,835,368,846,354,853,341,858,312,863,282,870,268,882,253,888,249"/>
<area shape="poly" title=" " alt="" coords="888,195,882,190,869,174,862,157,858,124,854,91,847,76,835,61,814,47,791,38,793,33,817,43,838,57,852,73,859,90,863,123,867,156,874,171,886,186,891,191"/>
<area shape="poly" title=" " alt="" coords="892,196,883,190,867,174,858,157,850,141,835,126,812,114,814,110,838,122,854,138,863,155,871,171,886,186,894,192"/>
<area shape="poly" title=" " alt="" coords="886,200,787,178,788,173,888,195"/>
<area shape="poly" title=" " alt="" coords="887,224,814,224,814,219,887,219"/>
<area shape="poly" title=" " alt="" coords="888,248,796,269,795,263,887,243"/>
<area shape="poly" title=" " alt="" coords="894,252,886,257,871,272,863,289,855,306,838,321,813,333,810,328,835,317,850,302,858,286,867,269,883,253,892,247"/>
<area shape="poly" title=" " alt="" coords="950,317,896,345,837,372,793,388,792,383,835,367,894,341,947,313"/>
<area shape="poly" title=" " alt="" coords="886,259,882,255,865,231,857,205,856,180,858,156,860,131,859,107,852,84,834,61,815,46,791,36,793,31,817,42,838,57,856,82,864,106,866,131,864,156,861,180,862,204,870,228,886,252,890,255"/>
<area shape="poly" title=" " alt="" coords="888,260,882,256,869,239,862,222,858,189,854,157,847,141,835,126,817,114,820,110,838,122,852,138,859,155,863,188,867,221,874,236,886,252,891,256"/>
<area shape="poly" title=" " alt="" coords="892,261,883,256,867,239,858,223,850,207,835,192,812,180,786,171,788,166,814,175,838,188,854,203,863,220,871,236,886,252,894,257"/>
<area shape="poly" title=" " alt="" coords="887,265,795,245,796,240,888,260"/>
<area shape="poly" title=" " alt="" coords="877,290,837,290,837,284,877,284"/>
<area shape="poly" title=" " alt="" coords="879,313,837,322,774,334,773,328,836,316,878,308"/>
</map>
</div>

</div>
</div>
<a id="ae7f03499d3fe8e965b17197a14b50fd5" name="ae7f03499d3fe8e965b17197a14b50fd5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae7f03499d3fe8e965b17197a14b50fd5">&#9670;&#160;</a></span>_full_checkpoint_name()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._full_checkpoint_name </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>checkpoint_dir</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>name</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00329">329</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  329</span>  <span class="keyword">def </span>_full_checkpoint_name(self, checkpoint_dir, name):</div>
<div class="line"><span class="lineno">  330</span>    checkpoint_filename = <span class="stringliteral">&quot;_&quot;</span>.join(</div>
<div class="line"><span class="lineno">  331</span>        [self._loss_str, name, <span class="stringliteral">&quot;pid&quot;</span> + str(self.player_id)])</div>
<div class="line"><span class="lineno">  332</span>    <span class="keywordflow">return</span> os.path.join(checkpoint_dir, checkpoint_filename)</div>
<div class="line"><span class="lineno">  333</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00371">open_spiel.python.algorithms.dqn.DQN.restore()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00304">open_spiel.python.algorithms.nfsp.NFSP.restore()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00346">open_spiel.python.algorithms.dqn.DQN.save()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00279">open_spiel.python.algorithms.nfsp.NFSP.save()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00295">open_spiel.python.jax.nfsp.NFSP.save()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_ae7f03499d3fe8e965b17197a14b50fd5_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_ae7f03499d3fe8e965b17197a14b50fd5_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_ae7f03499d3fe8e965b17197a14b50fd5_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_ae7f03499d3fe8e965b17197a14b50fd5_icgraph">
<area shape="rect" title=" " alt="" coords="1161,194,1372,250"/>
<area shape="rect" href="../../d2/d7c/classopen__spiel_1_1python_1_1algorithms_1_1dqn_1_1_d_q_n.html#aa6a6f2b71d722c4ff30a636783917756" title=" " alt="" coords="889,5,1108,46"/>
<area shape="poly" title=" " alt="" coords="1235,183,1182,120,1148,88,1111,61,1086,49,1089,44,1114,57,1152,84,1186,116,1239,179"/>
<area shape="rect" href="../../dd/d94/classopen__spiel_1_1python_1_1algorithms_1_1nfsp_1_1_n_f_s_p.html#a99c2af5d80f500fda58c9376e9f8178f" title=" " alt="" coords="887,71,1110,111"/>
<area shape="poly" title=" " alt="" coords="1214,187,1165,155,1112,127,1080,114,1082,109,1114,122,1168,151,1217,182"/>
<area shape="rect" href="../../d2/d7c/classopen__spiel_1_1python_1_1algorithms_1_1dqn_1_1_d_q_n.html#a1b847585cb662ad989d1dd46015f3172" title=" " alt="" coords="889,136,1108,177"/>
<area shape="poly" title=" " alt="" coords="1145,195,1084,180,1085,175,1146,190"/>
<area shape="rect" href="../../dd/d94/classopen__spiel_1_1python_1_1algorithms_1_1nfsp_1_1_n_f_s_p.html#ab08271c06d92b3f28a2b3f4dc066a928" title=" " alt="" coords="887,201,1110,242"/>
<area shape="poly" title=" " alt="" coords="1145,224,1110,224,1110,219,1145,219"/>
<area shape="rect" href="../../da/dba/classopen__spiel_1_1python_1_1jax_1_1nfsp_1_1_n_f_s_p.html#a897a1e253cf59558b5f1655dbc1a7617" title=" " alt="" coords="908,267,1089,307"/>
<area shape="poly" title=" " alt="" coords="1146,254,1085,269,1084,263,1145,249"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a2cdd98bcd5917fa6d824f463e8c56f03" title=" " alt="" coords="884,397,1113,438"/>
<area shape="poly" title=" " alt="" coords="1239,264,1186,327,1152,359,1114,387,1089,399,1086,395,1111,382,1148,355,1182,324,1235,261"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#af6b7739338748eab5d5000c55d046fe8" title=" " alt="" coords="893,332,1104,373"/>
<area shape="poly" title=" " alt="" coords="1217,261,1168,292,1114,321,1082,334,1080,329,1112,317,1165,288,1214,256"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#a14d11483beff07f087b51f3a2dd71135" title=" " alt="" coords="606,544,792,600"/>
<area shape="poly" title=" " alt="" coords="964,450,907,493,838,535,793,552,791,547,835,530,904,489,961,446"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#adb88039a6a02b4d0090a0abc5c3c5424" title=" " alt="" coords="606,168,792,209"/>
<area shape="poly" title=" " alt="" coords="886,390,882,386,867,365,859,344,858,303,857,262,850,243,834,224,815,209,791,200,794,195,817,205,838,220,854,240,862,261,863,302,865,343,872,363,886,383,890,386"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a7a91195b9b42b8536e06098e836b02e4" title=" " alt="" coords="573,233,824,274"/>
<area shape="poly" title=" " alt="" coords="889,391,883,386,871,374,864,361,858,336,852,312,846,300,835,289,815,277,818,272,838,285,850,297,857,310,863,335,869,359,875,371,886,382,892,387"/>
<area shape="rect" href="../../d2/dfd/classnash__evolutionary__search_1_1_nash_c_m_a_e_s.html#a42b13c1091631c52988a6391fe34038a" title=" " alt="" coords="610,299,787,339"/>
<area shape="poly" title=" " alt="" coords="900,394,883,387,859,370,835,355,786,338,788,333,838,350,862,366,886,382,902,389"/>
<area shape="rect" href="../../d5/dd9/classnash__random__search_1_1_nash_random_search.html#a9b9967669c24ceba55dc8ce00565a71a" title=" " alt="" coords="584,364,813,405"/>
<area shape="poly" title=" " alt="" coords="868,406,814,400,814,394,869,401"/>
<area shape="rect" href="../../d1/d50/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1bandit__regret_1_1_polynomial_weight_algorithm.html#a3b7ceacfd8a03895a691242d227c1ddd" title=" " alt="" coords="561,429,836,470"/>
<area shape="poly" title=" " alt="" coords="869,434,837,438,837,432,869,429"/>
<area shape="rect" href="../../d5/d11/classregret__minimizer_1_1_regret_minimizer.html#aa371edb5793c6a6cfbf51dc8597905dc" title=" " alt="" coords="566,494,831,520"/>
<area shape="poly" title=" " alt="" coords="938,447,837,484,787,496,786,491,836,479,937,442"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a44f0c375b5ef20bb1267524788ab16da" title=" " alt="" coords="281,233,513,274"/>
<area shape="poly" title=" " alt="" coords="557,256,514,256,514,251,557,251"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#ad1331eddb66a419f7336bc267b47d75e" title=" " alt="" coords="5,200,233,241"/>
<area shape="poly" title=" " alt="" coords="265,240,233,237,233,231,265,235"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#a14e053b461dc025b01a41453bc278c7d" title=" " alt="" coords="5,265,233,306"/>
<area shape="poly" title=" " alt="" coords="265,272,233,275,233,270,265,266"/>
<area shape="poly" title=" " alt="" coords="890,384,886,387,872,405,866,423,863,459,860,497,853,516,838,534,817,550,794,561,791,556,814,545,834,530,848,513,855,495,858,459,860,421,868,402,882,384,887,380"/>
<area shape="poly" title=" " alt="" coords="889,326,883,321,871,309,864,296,858,271,852,246,846,235,835,224,814,211,791,202,793,197,817,206,838,220,850,232,857,244,863,269,869,294,875,306,886,317,892,322"/>
<area shape="poly" title=" " alt="" coords="900,329,883,321,859,305,835,289,802,277,803,272,838,285,862,301,886,317,902,324"/>
<area shape="poly" title=" " alt="" coords="877,342,787,331,787,326,878,336"/>
<area shape="poly" title=" " alt="" coords="878,368,814,375,814,369,877,363"/>
<area shape="poly" title=" " alt="" coords="903,381,886,388,862,403,837,419,803,431,801,426,835,414,859,399,883,383,901,376"/>
<area shape="poly" title=" " alt="" coords="892,383,886,388,875,399,869,411,864,435,857,460,850,472,838,484,817,496,815,491,835,480,846,469,852,458,858,434,864,409,871,396,883,384,889,379"/>
</map>
</div>

</div>
</div>
<a id="aa7d88aa18275e11c79b98f3abf8bfb6d" name="aa7d88aa18275e11c79b98f3abf8bfb6d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa7d88aa18275e11c79b98f3abf8bfb6d">&#9670;&#160;</a></span>_get_loss_class()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._get_loss_class </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>loss_str</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00243">243</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  243</span>  <span class="keyword">def </span>_get_loss_class(self, loss_str):</div>
<div class="line"><span class="lineno">  244</span>    <span class="keywordflow">if</span> loss_str == <span class="stringliteral">&quot;rpg&quot;</span>:</div>
<div class="line"><span class="lineno">  245</span>      <span class="keywordflow">return</span> rl_losses.BatchRPGLoss</div>
<div class="line"><span class="lineno">  246</span>    <span class="keywordflow">elif</span> loss_str == <span class="stringliteral">&quot;qpg&quot;</span>:</div>
<div class="line"><span class="lineno">  247</span>      <span class="keywordflow">return</span> rl_losses.BatchQPGLoss</div>
<div class="line"><span class="lineno">  248</span>    <span class="keywordflow">elif</span> loss_str == <span class="stringliteral">&quot;rm&quot;</span>:</div>
<div class="line"><span class="lineno">  249</span>      <span class="keywordflow">return</span> rl_losses.BatchRMLoss</div>
<div class="line"><span class="lineno">  250</span>    <span class="keywordflow">elif</span> loss_str == <span class="stringliteral">&quot;a2c&quot;</span>:</div>
<div class="line"><span class="lineno">  251</span>      <span class="keywordflow">return</span> rl_losses.BatchA2CLoss</div>
<div class="line"><span class="lineno">  252</span>    <span class="keywordflow">elif</span> loss_str == <span class="stringliteral">&quot;neurd&quot;</span>:</div>
<div class="line"><span class="lineno">  253</span>      <span class="keywordflow">return</span> rl_losses.BatchNeuRDLoss</div>
<div class="line"><span class="lineno">  254</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa7d88aa18275e11c79b98f3abf8bfb6d_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa7d88aa18275e11c79b98f3abf8bfb6d_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa7d88aa18275e11c79b98f3abf8bfb6d_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_aa7d88aa18275e11c79b98f3abf8bfb6d_icgraph">
<area shape="rect" title=" " alt="" coords="282,70,493,126"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#ac912c890844bd86a84a085a531f1d488" title=" " alt="" coords="5,5,234,46"/>
<area shape="poly" title=" " alt="" coords="266,68,197,49,199,44,267,63"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#ab179556d75b56778b2069bc9582177a5" title=" " alt="" coords="27,70,212,126"/>
<area shape="poly" title=" " alt="" coords="266,100,212,100,212,95,266,95"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#acff77770d69b724496d0d58fd14ccb43" title=" " alt="" coords="13,149,226,190"/>
<area shape="poly" title=" " alt="" coords="267,133,199,151,197,146,266,127"/>
</map>
</div>

</div>
</div>
<a id="a09ea379d1a5880b14cf864511d95e169" name="a09ea379d1a5880b14cf864511d95e169"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a09ea379d1a5880b14cf864511d95e169">&#9670;&#160;</a></span>_latest_checkpoint_filename()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._latest_checkpoint_filename </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>name</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00334">334</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  334</span>  <span class="keyword">def </span>_latest_checkpoint_filename(self, name):</div>
<div class="line"><span class="lineno">  335</span>    checkpoint_filename = <span class="stringliteral">&quot;_&quot;</span>.join(</div>
<div class="line"><span class="lineno">  336</span>        [self._loss_str, name, <span class="stringliteral">&quot;pid&quot;</span> + str(self.player_id)])</div>
<div class="line"><span class="lineno">  337</span>    <span class="keywordflow">return</span> checkpoint_filename + <span class="stringliteral">&quot;_latest&quot;</span></div>
<div class="line"><span class="lineno">  338</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00346">open_spiel.python.algorithms.dqn.DQN.save()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00279">open_spiel.python.algorithms.nfsp.NFSP.save()</a>, and <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a09ea379d1a5880b14cf864511d95e169_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a09ea379d1a5880b14cf864511d95e169_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a09ea379d1a5880b14cf864511d95e169_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a09ea379d1a5880b14cf864511d95e169_icgraph">
<area shape="rect" title=" " alt="" coords="1161,143,1372,198"/>
<area shape="rect" href="../../d2/d7c/classopen__spiel_1_1python_1_1algorithms_1_1dqn_1_1_d_q_n.html#a1b847585cb662ad989d1dd46015f3172" title=" " alt="" coords="889,85,1108,126"/>
<area shape="poly" title=" " alt="" coords="1145,144,1084,129,1085,123,1146,138"/>
<area shape="rect" href="../../dd/d94/classopen__spiel_1_1python_1_1algorithms_1_1nfsp_1_1_n_f_s_p.html#ab08271c06d92b3f28a2b3f4dc066a928" title=" " alt="" coords="887,150,1110,191"/>
<area shape="poly" title=" " alt="" coords="1145,173,1110,173,1110,168,1145,168"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a2cdd98bcd5917fa6d824f463e8c56f03" title=" " alt="" coords="884,216,1113,256"/>
<area shape="poly" title=" " alt="" coords="1146,203,1085,218,1084,212,1145,197"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#a14d11483beff07f087b51f3a2dd71135" title=" " alt="" coords="606,5,792,61"/>
<area shape="poly" title=" " alt="" coords="888,209,882,204,869,188,862,171,858,138,854,106,847,90,835,75,814,61,791,50,793,45,817,56,838,71,852,88,859,104,863,138,867,170,874,185,886,201,891,205"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#adb88039a6a02b4d0090a0abc5c3c5424" title=" " alt="" coords="606,85,792,126"/>
<area shape="poly" title=" " alt="" coords="892,210,883,205,867,188,858,171,850,155,835,141,791,121,793,116,838,136,854,152,863,169,871,185,886,200,894,206"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a7a91195b9b42b8536e06098e836b02e4" title=" " alt="" coords="573,150,824,191"/>
<area shape="poly" title=" " alt="" coords="887,214,795,194,796,189,888,209"/>
<area shape="rect" href="../../d2/dfd/classnash__evolutionary__search_1_1_nash_c_m_a_e_s.html#a42b13c1091631c52988a6391fe34038a" title=" " alt="" coords="610,216,787,256"/>
<area shape="poly" title=" " alt="" coords="869,238,787,238,787,233,869,233"/>
<area shape="rect" href="../../d5/dd9/classnash__random__search_1_1_nash_random_search.html#a9b9967669c24ceba55dc8ce00565a71a" title=" " alt="" coords="584,281,813,322"/>
<area shape="poly" title=" " alt="" coords="888,263,796,283,795,278,887,257"/>
<area shape="rect" href="../../d1/d50/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1bandit__regret_1_1_polynomial_weight_algorithm.html#a3b7ceacfd8a03895a691242d227c1ddd" title=" " alt="" coords="561,346,836,387"/>
<area shape="poly" title=" " alt="" coords="958,268,902,303,837,336,802,348,800,343,835,331,899,298,955,263"/>
<area shape="rect" href="../../d5/d11/classregret__minimizer_1_1_regret_minimizer.html#aa371edb5793c6a6cfbf51dc8597905dc" title=" " alt="" coords="566,411,831,437"/>
<area shape="poly" title=" " alt="" coords="976,271,919,338,880,373,838,401,808,413,806,408,835,396,877,368,915,334,972,267"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a44f0c375b5ef20bb1267524788ab16da" title=" " alt="" coords="281,150,513,191"/>
<area shape="poly" title=" " alt="" coords="557,173,514,173,514,168,557,168"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#ad1331eddb66a419f7336bc267b47d75e" title=" " alt="" coords="5,117,233,158"/>
<area shape="poly" title=" " alt="" coords="265,157,233,153,233,148,265,152"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#a14e053b461dc025b01a41453bc278c7d" title=" " alt="" coords="5,182,233,223"/>
<area shape="poly" title=" " alt="" coords="265,188,233,192,233,187,265,183"/>
</map>
</div>

</div>
</div>
<a id="a1df0f6d210f6335c45c04572758e5dab" name="a1df0f6d210f6335c45c04572758e5dab"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1df0f6d210f6335c45c04572758e5dab">&#9670;&#160;</a></span>_pi_update()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<pre class="fragment">Compute the Pi loss on sampled transitions and perform a Pi update.

Returns:
  The average Pi loss obtained on this batch.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">436</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  436</span>  <span class="keyword">def </span>_pi_update(self):</div>
<div class="line"><span class="lineno">  437</span>    <span class="stringliteral">&quot;&quot;&quot;Compute the Pi loss on sampled transitions and perform a Pi update.</span></div>
<div class="line"><span class="lineno">  438</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  439</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><span class="lineno">  440</span><span class="stringliteral">      The average Pi loss obtained on this batch.</span></div>
<div class="line"><span class="lineno">  441</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  442</span>    <span class="comment"># TODO(author3): illegal action handling.</span></div>
<div class="line"><span class="lineno">  443</span>    info_state = torch.Tensor(self._dataset[<span class="stringliteral">&quot;info_states&quot;</span>])</div>
<div class="line"><span class="lineno">  444</span>    action = torch.LongTensor(self._dataset[<span class="stringliteral">&quot;actions&quot;</span>])</div>
<div class="line"><span class="lineno">  445</span>    return_ = torch.Tensor(self._dataset[<span class="stringliteral">&quot;returns&quot;</span>])</div>
<div class="line"><span class="lineno">  446</span>    torso_out = self._net_torso(info_state)</div>
<div class="line"><span class="lineno">  447</span>    self._policy_logits = self._policy_logits_layer(torso_out)</div>
<div class="line"><span class="lineno">  448</span> </div>
<div class="line"><span class="lineno">  449</span>    <span class="keywordflow">if</span> self._loss_class.__name__ == <span class="stringliteral">&quot;BatchA2CLoss&quot;</span>:</div>
<div class="line"><span class="lineno">  450</span>      baseline = torch.squeeze(self._baseline_layer(torso_out), dim=1)</div>
<div class="line"><span class="lineno">  451</span>      pi_loss = self.pg_class.loss(</div>
<div class="line"><span class="lineno">  452</span>          policy_logits=self._policy_logits,</div>
<div class="line"><span class="lineno">  453</span>          baseline=baseline,</div>
<div class="line"><span class="lineno">  454</span>          actions=action,</div>
<div class="line"><span class="lineno">  455</span>          returns=return_)</div>
<div class="line"><span class="lineno">  456</span>      self.minimize_with_clipping(self._policy_logits_layer, self._pi_optimizer,</div>
<div class="line"><span class="lineno">  457</span>                                  pi_loss)</div>
<div class="line"><span class="lineno">  458</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  459</span>      q_values = self._q_values_layer(torso_out)</div>
<div class="line"><span class="lineno">  460</span>      pi_loss = self.pg_class.loss(</div>
<div class="line"><span class="lineno">  461</span>          policy_logits=self._policy_logits, action_values=q_values)</div>
<div class="line"><span class="lineno">  462</span>      self.minimize_with_clipping(self._policy_logits_layer, self._pi_optimizer,</div>
<div class="line"><span class="lineno">  463</span>                                  pi_loss)</div>
<div class="line"><span class="lineno">  464</span>    self._last_pi_loss_value = pi_loss</div>
<div class="line"><span class="lineno">  465</span>    <span class="keywordflow">return</span> pi_loss</div>
<div class="line"><span class="lineno">  466</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00202">open_spiel.python.algorithms.policy_gradient.PolicyGradient._baseline_layer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00218">open_spiel.python.pytorch.policy_gradient.PolicyGradient._baseline_layer</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00161">open_spiel.python.algorithms.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00249">open_spiel.python.jax.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00184">open_spiel.python.pytorch.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00382">open_spiel.python.algorithms.policy_gradient.PolicyGradient._last_pi_loss_value</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00396">open_spiel.python.jax.policy_gradient.PolicyGradient._last_pi_loss_value</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00360">open_spiel.python.pytorch.policy_gradient.PolicyGradient._last_pi_loss_value</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00150">open_spiel.python.algorithms.policy_gradient.PolicyGradient._loss_class</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00173">open_spiel.python.pytorch.policy_gradient.PolicyGradient._loss_class</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00183">open_spiel.python.algorithms.policy_gradient.PolicyGradient._net_torso</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00198">open_spiel.python.pytorch.policy_gradient.PolicyGradient._net_torso</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00260">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_optimizer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00235">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_optimizer</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00195">open_spiel.python.algorithms.policy_gradient.PolicyGradient._policy_logits</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00267">open_spiel.python.pytorch.policy_gradient.PolicyGradient._policy_logits</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00186">open_spiel.python.algorithms.policy_gradient.PolicyGradient._policy_logits_layer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00200">open_spiel.python.pytorch.policy_gradient.PolicyGradient._policy_logits_layer</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00206">open_spiel.python.algorithms.policy_gradient.PolicyGradient._q_values_layer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00223">open_spiel.python.pytorch.policy_gradient.PolicyGradient._q_values_layer</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00255">open_spiel.python.pytorch.policy_gradient.PolicyGradient.minimize_with_clipping()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00232">open_spiel.python.pytorch.policy_gradient.PolicyGradient.pg_class</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a1df0f6d210f6335c45c04572758e5dab_cgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a1df0f6d210f6335c45c04572758e5dab_cgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a1df0f6d210f6335c45c04572758e5dab_cgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a1df0f6d210f6335c45c04572758e5dab_cgraph">
<area shape="rect" title=" " alt="" coords="5,13,236,54"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#accd3df94affd3092ece7c5110a1de359" title=" " alt="" coords="284,5,503,61"/>
<area shape="poly" title=" " alt="" coords="236,30,268,30,268,36,236,36"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a1df0f6d210f6335c45c04572758e5dab_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a1df0f6d210f6335c45c04572758e5dab_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a1df0f6d210f6335c45c04572758e5dab_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_a1df0f6d210f6335c45c04572758e5dab_icgraph">
<area shape="rect" title=" " alt="" coords="1161,201,1391,242"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a2cdd98bcd5917fa6d824f463e8c56f03" title=" " alt="" coords="884,136,1113,177"/>
<area shape="poly" title=" " alt="" coords="1171,200,1087,180,1088,175,1172,195"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#a03aec30cd5c3aa917c53b196b8bf740b" title=" " alt="" coords="902,201,1095,242"/>
<area shape="poly" title=" " alt="" coords="1145,224,1095,224,1095,219,1145,219"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#af6b7739338748eab5d5000c55d046fe8" title=" " alt="" coords="893,267,1104,307"/>
<area shape="poly" title=" " alt="" coords="1172,249,1088,269,1087,263,1171,244"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#a14d11483beff07f087b51f3a2dd71135" title=" " alt="" coords="606,382,792,438"/>
<area shape="poly" title=" " alt="" coords="890,188,886,191,870,213,863,235,863,280,863,325,855,349,838,372,817,388,793,399,791,394,815,383,834,368,850,346,857,324,858,280,858,234,866,211,882,188,886,184"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#adb88039a6a02b4d0090a0abc5c3c5424" title=" " alt="" coords="606,5,792,46"/>
<area shape="poly" title=" " alt="" coords="955,129,899,94,835,61,791,47,793,42,837,57,902,89,958,125"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a7a91195b9b42b8536e06098e836b02e4" title=" " alt="" coords="573,71,824,111"/>
<area shape="poly" title=" " alt="" coords="887,135,795,115,796,109,888,130"/>
<area shape="rect" href="../../d2/dfd/classnash__evolutionary__search_1_1_nash_c_m_a_e_s.html#a42b13c1091631c52988a6391fe34038a" title=" " alt="" coords="610,136,787,177"/>
<area shape="poly" title=" " alt="" coords="869,159,787,159,787,154,869,154"/>
<area shape="rect" href="../../d5/dd9/classnash__random__search_1_1_nash_random_search.html#a9b9967669c24ceba55dc8ce00565a71a" title=" " alt="" coords="584,201,813,242"/>
<area shape="poly" title=" " alt="" coords="888,183,796,203,795,198,887,178"/>
<area shape="rect" href="../../d1/d50/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1bandit__regret_1_1_polynomial_weight_algorithm.html#a3b7ceacfd8a03895a691242d227c1ddd" title=" " alt="" coords="561,267,836,307"/>
<area shape="poly" title=" " alt="" coords="894,186,886,192,871,207,863,223,854,240,838,256,814,268,812,264,835,252,850,237,858,221,867,204,883,188,892,182"/>
<area shape="rect" href="../../d5/d11/classregret__minimizer_1_1_regret_minimizer.html#aa371edb5793c6a6cfbf51dc8597905dc" title=" " alt="" coords="566,332,831,357"/>
<area shape="poly" title=" " alt="" coords="891,187,886,192,874,207,867,223,864,256,860,289,852,305,838,321,820,333,817,329,835,317,848,302,855,287,858,255,862,221,869,204,882,188,888,183"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a44f0c375b5ef20bb1267524788ab16da" title=" " alt="" coords="281,71,513,111"/>
<area shape="poly" title=" " alt="" coords="557,94,514,94,514,88,557,88"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#ad1331eddb66a419f7336bc267b47d75e" title=" " alt="" coords="5,37,233,78"/>
<area shape="poly" title=" " alt="" coords="265,78,233,74,233,69,265,73"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#a14e053b461dc025b01a41453bc278c7d" title=" " alt="" coords="5,103,233,143"/>
<area shape="poly" title=" " alt="" coords="265,109,233,113,233,107,265,104"/>
<area shape="poly" title=" " alt="" coords="891,253,886,257,874,270,868,284,863,313,858,342,851,357,838,372,817,387,793,397,791,392,814,382,835,368,846,354,853,341,858,312,863,282,870,268,882,253,888,249"/>
<area shape="poly" title=" " alt="" coords="888,195,882,190,869,174,862,157,858,124,854,91,847,76,835,61,814,47,791,38,793,33,817,43,838,57,852,73,859,90,863,123,867,156,874,171,886,186,891,191"/>
<area shape="poly" title=" " alt="" coords="892,196,883,190,867,174,858,157,850,141,835,126,812,114,814,110,838,122,854,138,863,155,871,171,886,186,894,192"/>
<area shape="poly" title=" " alt="" coords="886,200,787,178,788,173,888,195"/>
<area shape="poly" title=" " alt="" coords="887,224,814,224,814,219,887,219"/>
<area shape="poly" title=" " alt="" coords="888,248,796,269,795,263,887,243"/>
<area shape="poly" title=" " alt="" coords="894,252,886,257,871,272,863,289,855,306,838,321,813,333,810,328,835,317,850,302,858,286,867,269,883,253,892,247"/>
<area shape="poly" title=" " alt="" coords="950,317,896,345,837,372,793,388,792,383,835,367,894,341,947,313"/>
<area shape="poly" title=" " alt="" coords="886,259,882,255,865,231,857,205,856,180,858,156,860,131,859,107,852,84,834,61,815,46,791,36,793,31,817,42,838,57,856,82,864,106,866,131,864,156,861,180,862,204,870,228,886,252,890,255"/>
<area shape="poly" title=" " alt="" coords="888,260,882,256,869,239,862,222,858,189,854,157,847,141,835,126,817,114,820,110,838,122,852,138,859,155,863,188,867,221,874,236,886,252,891,256"/>
<area shape="poly" title=" " alt="" coords="892,261,883,256,867,239,858,223,850,207,835,192,812,180,786,171,788,166,814,175,838,188,854,203,863,220,871,236,886,252,894,257"/>
<area shape="poly" title=" " alt="" coords="887,265,795,245,796,240,888,260"/>
<area shape="poly" title=" " alt="" coords="877,290,837,290,837,284,877,284"/>
<area shape="poly" title=" " alt="" coords="879,313,837,322,774,334,773,328,836,316,878,308"/>
</map>
</div>

</div>
</div>
<a id="a548181be13c4c79730cb5520a75787ca" name="a548181be13c4c79730cb5520a75787ca"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a548181be13c4c79730cb5520a75787ca">&#9670;&#160;</a></span>copy_with_noise()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.copy_with_noise </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>sigma</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0.0</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>copy_weights</em></span><span class="paramdefsep"> = </span><span class="paramdefval">True</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Copies the object and perturbates its network's weights with noise.

Args:
  sigma: gaussian dropout variance term : Multiplicative noise following
    (1+sigma*epsilon), epsilon standard gaussian variable, multiplies each
    model weight. sigma=0 means no perturbation.
  copy_weights: Boolean determining whether to copy model weights (True) or
    just model hyperparameters.

Returns:
  Perturbated copy of the model.
</pre> 
<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00476">476</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  476</span>  <span class="keyword">def </span>copy_with_noise(self, sigma=0.0, copy_weights=True):</div>
<div class="line"><span class="lineno">  477</span>    <span class="stringliteral">&quot;&quot;&quot;Copies the object and perturbates its network&#39;s weights with noise.</span></div>
<div class="line"><span class="lineno">  478</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  479</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  480</span><span class="stringliteral">      sigma: gaussian dropout variance term : Multiplicative noise following</span></div>
<div class="line"><span class="lineno">  481</span><span class="stringliteral">        (1+sigma*epsilon), epsilon standard gaussian variable, multiplies each</span></div>
<div class="line"><span class="lineno">  482</span><span class="stringliteral">        model weight. sigma=0 means no perturbation.</span></div>
<div class="line"><span class="lineno">  483</span><span class="stringliteral">      copy_weights: Boolean determining whether to copy model weights (True) or</span></div>
<div class="line"><span class="lineno">  484</span><span class="stringliteral">        just model hyperparameters.</span></div>
<div class="line"><span class="lineno">  485</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  486</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><span class="lineno">  487</span><span class="stringliteral">      Perturbated copy of the model.</span></div>
<div class="line"><span class="lineno">  488</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  489</span>    _ = self._kwargs.pop(<span class="stringliteral">&quot;self&quot;</span>, <span class="keywordtype">None</span>)</div>
<div class="line"><span class="lineno">  490</span>    copied_object = PolicyGradient(**self._kwargs)</div>
<div class="line"><span class="lineno">  491</span> </div>
<div class="line"><span class="lineno">  492</span>    net_torso = getattr(copied_object, <span class="stringliteral">&quot;_net_torso&quot;</span>)</div>
<div class="line"><span class="lineno">  493</span>    policy_logits_layer = getattr(copied_object, <span class="stringliteral">&quot;_policy_logits_layer&quot;</span>)</div>
<div class="line"><span class="lineno">  494</span>    <span class="keywordflow">if</span> hasattr(copied_object, <span class="stringliteral">&quot;_q_values_layer&quot;</span>):</div>
<div class="line"><span class="lineno">  495</span>      q_values_layer = getattr(copied_object, <span class="stringliteral">&quot;_q_values_layer&quot;</span>)</div>
<div class="line"><span class="lineno">  496</span>    <span class="keywordflow">if</span> hasattr(copied_object, <span class="stringliteral">&quot;_baseline_layer&quot;</span>):</div>
<div class="line"><span class="lineno">  497</span>      baseline_layer = getattr(copied_object, <span class="stringliteral">&quot;_baseline_layer&quot;</span>)</div>
<div class="line"><span class="lineno">  498</span> </div>
<div class="line"><span class="lineno">  499</span>    <span class="keywordflow">if</span> copy_weights:</div>
<div class="line"><span class="lineno">  500</span>      <span class="keyword">with</span> torch.no_grad():</div>
<div class="line"><span class="lineno">  501</span>        <span class="keywordflow">for</span> layer <span class="keywordflow">in</span> net_torso.model:</div>
<div class="line"><span class="lineno">  502</span>          layer.weight *= (1 + sigma * torch.randn(layer.weight.shape))</div>
<div class="line"><span class="lineno">  503</span> </div>
<div class="line"><span class="lineno">  504</span>        policy_logits_layer.weight *= (</div>
<div class="line"><span class="lineno">  505</span>            1 + sigma * torch.randn(policy_logits_layer.weight.shape))</div>
<div class="line"><span class="lineno">  506</span> </div>
<div class="line"><span class="lineno">  507</span>        <span class="keywordflow">if</span> hasattr(copied_object, <span class="stringliteral">&quot;_q_values_layer&quot;</span>):</div>
<div class="line"><span class="lineno">  508</span>          q_values_layer.weight *= (</div>
<div class="line"><span class="lineno">  509</span>              1 + sigma * torch.randn(q_values_layer.weight.shape))</div>
<div class="line"><span class="lineno">  510</span> </div>
<div class="line"><span class="lineno">  511</span>        <span class="keywordflow">if</span> hasattr(copied_object, <span class="stringliteral">&quot;_baseline_layer&quot;</span>):</div>
<div class="line"><span class="lineno">  512</span>          baseline_layer.weight *= (</div>
<div class="line"><span class="lineno">  513</span>              1 + sigma * torch.randn(baseline_layer.weight.shape))</div>
<div class="line"><span class="lineno">  514</span> </div>
<div class="line"><span class="lineno">  515</span>    <span class="keywordflow">return</span> copied_object</div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00066">open_spiel.python.algorithms.dqn.DQN._kwargs</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00148">open_spiel.python.algorithms.policy_gradient.PolicyGradient._kwargs</a>, <a class="el" href="../../d9/d94/abstract__meta__trainer_8py_source.html#l00171">open_spiel.python.algorithms.psro_v2.abstract_meta_trainer.AbstractMetaTrainer._kwargs</a>, <a class="el" href="../../dc/d28/optimization__oracle_8py_source.html#l00064">open_spiel.python.algorithms.psro_v2.optimization_oracle.AbstractOracle._kwargs</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00065">open_spiel.python.jax.dqn.DQN._kwargs</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00240">open_spiel.python.jax.policy_gradient.PolicyGradient._kwargs</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00138">open_spiel.python.pytorch.dqn.DQN._kwargs</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00171">open_spiel.python.pytorch.policy_gradient.PolicyGradient._kwargs</a>.</p>

</div>
</div>
<a id="a5784c14c48765f4a3e50eda0c442426d" name="a5784c14c48765f4a3e50eda0c442426d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5784c14c48765f4a3e50eda0c442426d">&#9670;&#160;</a></span>get_weights()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.get_weights </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00467">467</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  467</span>  <span class="keyword">def </span>get_weights(self):</div>
<div class="line"><span class="lineno">  468</span>    variables = [m.weight <span class="keywordflow">for</span> m <span class="keywordflow">in</span> self._net_torso.model]</div>
<div class="line"><span class="lineno">  469</span>    variables.append(self._policy_logits_layer.weight)</div>
<div class="line"><span class="lineno">  470</span>    <span class="keywordflow">if</span> self._loss_class.__name__ == <span class="stringliteral">&quot;BatchA2CLoss&quot;</span>:</div>
<div class="line"><span class="lineno">  471</span>      variables.append(self._baseline_layer.weight)</div>
<div class="line"><span class="lineno">  472</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  473</span>      variables.append(self._q_values_layer.weight)</div>
<div class="line"><span class="lineno">  474</span>    <span class="keywordflow">return</span> variables</div>
<div class="line"><span class="lineno">  475</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a5c98bb68cd5183cb7878933996547f93" name="a5c98bb68cd5183cb7878933996547f93"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5c98bb68cd5183cb7878933996547f93">&#9670;&#160;</a></span>has_checkpoint()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.has_checkpoint </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>checkpoint_dir</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00345">345</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  345</span>  <span class="keyword">def </span>has_checkpoint(self, checkpoint_dir):</div>
<div class="line"><span class="lineno">  346</span>    <span class="keywordflow">for</span> name, _ <span class="keywordflow">in</span> self._savers:</div>
<div class="line"><span class="lineno">  347</span>      path = self._full_checkpoint_name(checkpoint_dir, name)</div>
<div class="line"><span class="lineno">  348</span>      <span class="keywordflow">if</span> os.path.exists(path):</div>
<div class="line"><span class="lineno">  349</span>        <span class="keywordflow">return</span> <span class="keyword">True</span></div>
<div class="line"><span class="lineno">  350</span>    <span class="keywordflow">return</span> <span class="keyword">False</span></div>
<div class="line"><span class="lineno">  351</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af93562285d1d33bc47102f98acb85488" name="af93562285d1d33bc47102f98acb85488"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af93562285d1d33bc47102f98acb85488">&#9670;&#160;</a></span>loss()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.loss </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00359">359</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  359</span>  <span class="keyword">def </span>loss(self):</div>
<div class="line"><span class="lineno">  360</span>    <span class="keywordflow">return</span> (self._last_critic_loss_value, self._last_pi_loss_value)</div>
<div class="line"><span class="lineno">  361</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="../../d5/d27/rnad_8py_source.html#l00734">open_spiel.python.algorithms.rnad.rnad.RNaDSolver.init()</a>, <a class="el" href="../../da/d73/least__core__lagrangian_8py_source.html#l00209">open_spiel.python.coalitional_games.least_core_lagrangian.CoreOptimization.solve()</a>, <a class="el" href="../../da/d73/least__core__lagrangian_8py_source.html#l00353">open_spiel.python.coalitional_games.least_core_lagrangian.CoreOptimizationLogits.solve()</a>, <a class="el" href="../../da/d73/least__core__lagrangian_8py_source.html#l00183">open_spiel.python.coalitional_games.least_core_lagrangian.CoreOptimization.update_step()</a>, and <a class="el" href="../../da/d73/least__core__lagrangian_8py_source.html#l00331">open_spiel.python.coalitional_games.least_core_lagrangian.CoreOptimizationLogits.update_step()</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af93562285d1d33bc47102f98acb85488_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af93562285d1d33bc47102f98acb85488_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af93562285d1d33bc47102f98acb85488_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af93562285d1d33bc47102f98acb85488_icgraph">
<area shape="rect" title=" " alt="" coords="881,152,1093,193"/>
<area shape="rect" href="../../db/d54/classopen__spiel_1_1python_1_1algorithms_1_1rnad_1_1rnad_1_1_r_na_d_solver.html#a7f7a4d71f42bf84d07b88fbbe407dbc6" title=" " alt="" coords="581,29,833,70"/>
<area shape="poly" title=" " alt="" coords="939,146,888,118,832,91,784,73,786,68,834,86,891,113,941,142"/>
<area shape="rect" href="../../dd/d32/classopen__spiel_1_1python_1_1coalitional__games_1_1least__core__lagrangian_1_1_core_optimization.html#ae37f19ad122ba867775ad7352025160c" title=" " alt="" coords="292,271,522,327"/>
<area shape="poly" title=" " alt="" coords="960,206,905,254,871,277,834,295,755,315,673,324,593,324,522,319,522,314,593,319,672,319,754,310,832,290,869,273,902,250,956,202"/>
<area shape="rect" href="../../d1/d6d/classopen__spiel_1_1python_1_1coalitional__games_1_1least__core__lagrangian_1_1_core_optimization_logits.html#a9b38cecb395e03fad78c0b3f38fa12ff" title=" " alt="" coords="292,111,522,167"/>
<area shape="poly" title=" " alt="" coords="906,150,833,135,752,128,671,126,522,131,522,126,670,120,753,123,834,130,907,145"/>
<area shape="rect" href="../../dd/d32/classopen__spiel_1_1python_1_1coalitional__games_1_1least__core__lagrangian_1_1_core_optimization.html#aceeec793d205c5c2f5fe361fa2c74438" title=" " alt="" coords="592,144,822,200"/>
<area shape="poly" title=" " alt="" coords="866,175,822,175,822,170,866,170"/>
<area shape="rect" href="../../d1/d6d/classopen__spiel_1_1python_1_1coalitional__games_1_1least__core__lagrangian_1_1_core_optimization_logits.html#a2c1e0223f13faf1cfa737b185238427d" title=" " alt="" coords="592,224,822,280"/>
<area shape="poly" title=" " alt="" coords="900,200,808,226,806,221,898,195"/>
<area shape="poly" title=" " alt="" coords="753,16,736,10,707,8,680,10,664,15,658,21,660,28,655,29,652,19,661,10,679,5,707,3,737,5,755,11"/>
<area shape="rect" href="../../db/d54/classopen__spiel_1_1python_1_1algorithms_1_1rnad_1_1rnad_1_1_r_na_d_solver.html#ab952b8e7473cf001be5f9448c8617855" title=" " alt="" coords="281,29,533,70"/>
<area shape="poly" title=" " alt="" coords="565,52,533,52,533,47,565,47"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#ad1331eddb66a419f7336bc267b47d75e" title=" " alt="" coords="5,232,233,273"/>
<area shape="poly" title=" " alt="" coords="276,281,233,273,234,268,277,275"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#a14e053b461dc025b01a41453bc278c7d" title=" " alt="" coords="5,167,233,207"/>
<area shape="poly" title=" " alt="" coords="290,267,279,261,255,242,231,223,203,210,205,205,234,218,258,237,282,257,293,262"/>
<area shape="poly" title=" " alt="" coords="293,176,282,181,268,191,259,201,249,211,234,221,206,234,204,229,231,217,245,207,255,197,265,187,279,177,290,171"/>
<area shape="poly" title=" " alt="" coords="277,163,234,171,233,165,276,158"/>
<area shape="poly" title=" " alt="" coords="592,209,582,215,568,226,559,237,550,249,534,261,511,273,509,268,532,257,546,246,555,234,564,222,580,210,589,205"/>
<area shape="poly" title=" " alt="" coords="577,161,522,154,522,149,577,155"/>
<area shape="rect" href="../../dd/dd7/classopen__spiel_1_1python_1_1coalitional__games_1_1least__core__lagrangian_1_1_core_lagrangian.html#ac2a4c1b79e56b76bb15f0a3dae6c4b09" title=" " alt="" coords="292,191,522,247"/>
<area shape="poly" title=" " alt="" coords="578,195,522,204,521,199,577,190"/>
<area shape="poly" title=" " alt="" coords="277,237,233,242,233,236,276,231"/>
<area shape="poly" title=" " alt="" coords="276,207,233,202,233,197,277,202"/>
<area shape="poly" title=" " alt="" coords="578,275,522,284,521,279,577,270"/>
<area shape="poly" title=" " alt="" coords="593,221,580,215,555,198,532,181,505,170,507,165,534,177,559,193,582,210,595,216"/>
<area shape="poly" title=" " alt="" coords="577,241,522,234,522,229,577,235"/>
</map>
</div>

</div>
</div>
<a id="accd3df94affd3092ece7c5110a1de359" name="accd3df94affd3092ece7c5110a1de359"></a>
<h2 class="memtitle"><span class="permalink"><a href="#accd3df94affd3092ece7c5110a1de359">&#9670;&#160;</a></span>minimize_with_clipping()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.minimize_with_clipping </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>model</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>optimizer</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>loss</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00255">255</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  255</span>  <span class="keyword">def </span>minimize_with_clipping(self, model, optimizer, loss):</div>
<div class="line"><span class="lineno">  256</span>    optimizer.zero_grad()</div>
<div class="line"><span class="lineno">  257</span>    loss.backward()</div>
<div class="line"><span class="lineno">  258</span>    <span class="keywordflow">if</span> self._max_global_gradient_norm <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span>:</div>
<div class="line"><span class="lineno">  259</span>      nn.utils.clip_grad_norm_(model.parameters(),</div>
<div class="line"><span class="lineno">  260</span>                               self._max_global_gradient_norm)</div>
<div class="line"><span class="lineno">  261</span>    optimizer.step()</div>
<div class="line"><span class="lineno">  262</span> </div>
</div><!-- fragment -->
<p class="reference">Referenced by <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00405">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_update()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>.</p>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_accd3df94affd3092ece7c5110a1de359_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_accd3df94affd3092ece7c5110a1de359_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_accd3df94affd3092ece7c5110a1de359_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_accd3df94affd3092ece7c5110a1de359_icgraph">
<area shape="rect" title=" " alt="" coords="1457,195,1676,251"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#a6cc5d6bb8de010a9f67e71cc09e3ff5c" title=" " alt="" coords="1161,169,1409,210"/>
<area shape="poly" title=" " alt="" coords="1441,211,1409,207,1410,202,1442,206"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#a1df0f6d210f6335c45c04572758e5dab" title=" " alt="" coords="1170,235,1400,275"/>
<area shape="poly" title=" " alt="" coords="1442,240,1401,245,1400,239,1441,235"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a2cdd98bcd5917fa6d824f463e8c56f03" title=" " alt="" coords="884,136,1113,177"/>
<area shape="poly" title=" " alt="" coords="1145,176,1113,172,1113,167,1145,171"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#a03aec30cd5c3aa917c53b196b8bf740b" title=" " alt="" coords="902,201,1095,242"/>
<area shape="poly" title=" " alt="" coords="1146,208,1095,214,1095,208,1145,203"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#af6b7739338748eab5d5000c55d046fe8" title=" " alt="" coords="893,267,1104,307"/>
<area shape="poly" title=" " alt="" coords="1181,218,1162,225,1138,240,1114,256,1082,269,1080,264,1111,251,1135,236,1159,221,1179,213"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#a14d11483beff07f087b51f3a2dd71135" title=" " alt="" coords="606,382,792,438"/>
<area shape="poly" title=" " alt="" coords="890,188,886,191,870,213,863,235,863,280,863,325,855,349,838,372,817,388,793,399,791,394,815,383,834,368,850,346,857,324,858,280,858,234,866,211,882,188,886,184"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#adb88039a6a02b4d0090a0abc5c3c5424" title=" " alt="" coords="606,5,792,46"/>
<area shape="poly" title=" " alt="" coords="955,129,899,94,835,61,791,47,793,42,837,57,902,89,958,125"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a7a91195b9b42b8536e06098e836b02e4" title=" " alt="" coords="573,71,824,111"/>
<area shape="poly" title=" " alt="" coords="887,135,795,115,796,109,888,130"/>
<area shape="rect" href="../../d2/dfd/classnash__evolutionary__search_1_1_nash_c_m_a_e_s.html#a42b13c1091631c52988a6391fe34038a" title=" " alt="" coords="610,136,787,177"/>
<area shape="poly" title=" " alt="" coords="869,159,787,159,787,154,869,154"/>
<area shape="rect" href="../../d5/dd9/classnash__random__search_1_1_nash_random_search.html#a9b9967669c24ceba55dc8ce00565a71a" title=" " alt="" coords="584,201,813,242"/>
<area shape="poly" title=" " alt="" coords="888,183,796,203,795,198,887,178"/>
<area shape="rect" href="../../d1/d50/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1bandit__regret_1_1_polynomial_weight_algorithm.html#a3b7ceacfd8a03895a691242d227c1ddd" title=" " alt="" coords="561,267,836,307"/>
<area shape="poly" title=" " alt="" coords="894,186,886,192,871,207,863,223,854,240,838,256,814,268,812,264,835,252,850,237,858,221,867,204,883,188,892,182"/>
<area shape="rect" href="../../d5/d11/classregret__minimizer_1_1_regret_minimizer.html#aa371edb5793c6a6cfbf51dc8597905dc" title=" " alt="" coords="566,332,831,357"/>
<area shape="poly" title=" " alt="" coords="891,187,886,192,874,207,867,223,864,256,860,289,852,305,838,321,820,333,817,329,835,317,848,302,855,287,858,255,862,221,869,204,882,188,888,183"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a44f0c375b5ef20bb1267524788ab16da" title=" " alt="" coords="281,71,513,111"/>
<area shape="poly" title=" " alt="" coords="557,94,514,94,514,88,557,88"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#ad1331eddb66a419f7336bc267b47d75e" title=" " alt="" coords="5,37,233,78"/>
<area shape="poly" title=" " alt="" coords="265,78,233,74,233,69,265,73"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#a14e053b461dc025b01a41453bc278c7d" title=" " alt="" coords="5,103,233,143"/>
<area shape="poly" title=" " alt="" coords="265,109,233,113,233,107,265,104"/>
<area shape="poly" title=" " alt="" coords="891,253,886,257,874,270,868,284,863,313,858,342,851,357,838,372,817,387,793,397,791,392,814,382,835,368,846,354,853,341,858,312,863,282,870,268,882,253,888,249"/>
<area shape="poly" title=" " alt="" coords="888,195,882,190,869,174,862,157,858,124,854,91,847,76,835,61,814,47,791,38,793,33,817,43,838,57,852,73,859,90,863,123,867,156,874,171,886,186,891,191"/>
<area shape="poly" title=" " alt="" coords="892,196,883,190,867,174,858,157,850,141,835,126,812,114,814,110,838,122,854,138,863,155,871,171,886,186,894,192"/>
<area shape="poly" title=" " alt="" coords="886,200,787,178,788,173,888,195"/>
<area shape="poly" title=" " alt="" coords="887,224,814,224,814,219,887,219"/>
<area shape="poly" title=" " alt="" coords="888,248,796,269,795,263,887,243"/>
<area shape="poly" title=" " alt="" coords="894,252,886,257,871,272,863,289,855,306,838,321,813,333,810,328,835,317,850,302,858,286,867,269,883,253,892,247"/>
<area shape="poly" title=" " alt="" coords="950,317,896,345,837,372,793,388,792,383,835,367,894,341,947,313"/>
<area shape="poly" title=" " alt="" coords="886,259,882,255,865,231,857,205,856,180,858,156,860,131,859,107,852,84,834,61,815,46,791,36,793,31,817,42,838,57,856,82,864,106,866,131,864,156,861,180,862,204,870,228,886,252,890,255"/>
<area shape="poly" title=" " alt="" coords="888,260,882,256,869,239,862,222,858,189,854,157,847,141,835,126,817,114,820,110,838,122,852,138,859,155,863,188,867,221,874,236,886,252,891,256"/>
<area shape="poly" title=" " alt="" coords="892,261,883,256,867,239,858,223,850,207,835,192,812,180,786,171,788,166,814,175,838,188,854,203,863,220,871,236,886,252,894,257"/>
<area shape="poly" title=" " alt="" coords="887,265,795,245,796,240,888,260"/>
<area shape="poly" title=" " alt="" coords="877,290,837,290,837,284,877,284"/>
<area shape="poly" title=" " alt="" coords="879,313,837,322,774,334,773,328,836,316,878,308"/>
<area shape="poly" title=" " alt="" coords="1178,231,1159,224,1135,208,1111,192,1081,180,1083,175,1114,187,1138,204,1162,219,1180,227"/>
<area shape="poly" title=" " alt="" coords="1154,242,1095,236,1095,230,1155,237"/>
<area shape="poly" title=" " alt="" coords="1154,272,1105,278,1104,273,1154,267"/>
</map>
</div>

</div>
</div>
<a id="ab609a7255d397d73b18d4dbec2364f1c" name="ab609a7255d397d73b18d4dbec2364f1c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab609a7255d397d73b18d4dbec2364f1c">&#9670;&#160;</a></span>restore()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.restore </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>checkpoint_dir</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00352">352</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  352</span>  <span class="keyword">def </span>restore(self, checkpoint_dir):</div>
<div class="line"><span class="lineno">  353</span>    <span class="keywordflow">for</span> name, model <span class="keywordflow">in</span> self._savers:</div>
<div class="line"><span class="lineno">  354</span>      full_checkpoint_dir = self._full_checkpoint_name(checkpoint_dir, name)</div>
<div class="line"><span class="lineno">  355</span>      logging.info(<span class="stringliteral">&quot;Restoring checkpoint: %s&quot;</span>, full_checkpoint_dir)</div>
<div class="line"><span class="lineno">  356</span>      model.load_state_dict(torch.load(full_checkpoint_dir))</div>
<div class="line"><span class="lineno">  357</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af1a6308c6317b2a69c3e54ebf67c5622" name="af1a6308c6317b2a69c3e54ebf67c5622"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af1a6308c6317b2a69c3e54ebf67c5622">&#9670;&#160;</a></span>save()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.save </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>checkpoint_dir</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00339">339</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  339</span>  <span class="keyword">def </span>save(self, checkpoint_dir):</div>
<div class="line"><span class="lineno">  340</span>    <span class="keywordflow">for</span> name, model <span class="keywordflow">in</span> self._savers:</div>
<div class="line"><span class="lineno">  341</span>      path = self._full_checkpoint_name(checkpoint_dir, name)</div>
<div class="line"><span class="lineno">  342</span>      torch.save(model.state_dict(), path)</div>
<div class="line"><span class="lineno">  343</span>      logging.info(<span class="stringliteral">&quot;Saved to path: %s&quot;</span>, path)</div>
<div class="line"><span class="lineno">  344</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="af6b7739338748eab5d5000c55d046fe8" name="af6b7739338748eab5d5000c55d046fe8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af6b7739338748eab5d5000c55d046fe8">&#9670;&#160;</a></span>step()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>self</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>time_step</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>is_evaluation</em></span><span class="paramdefsep"> = </span><span class="paramdefval">False</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Returns the action to be taken and updates the network if needed.

Args:
  time_step: an instance of rl_environment.TimeStep.
  is_evaluation: bool, whether this is a training or evaluation call.

Returns:
  A `rl_agent.StepOutput` containing the action probs and chosen action.
</pre> 
<p>Reimplemented from <a class="el" href="../../d2/dfa/classopen__spiel_1_1python_1_1rl__agent_1_1_abstract_agent.html#ab97b9d892ae3a1232f3adce55203efea">open_spiel.python.rl_agent.AbstractAgent</a>.</p>

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">280</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  280</span>  <span class="keyword">def </span>step(self, time_step, is_evaluation=False):</div>
<div class="line"><span class="lineno">  281</span>    <span class="stringliteral">&quot;&quot;&quot;Returns the action to be taken and updates the network if needed.</span></div>
<div class="line"><span class="lineno">  282</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  283</span><span class="stringliteral">    Args:</span></div>
<div class="line"><span class="lineno">  284</span><span class="stringliteral">      time_step: an instance of rl_environment.TimeStep.</span></div>
<div class="line"><span class="lineno">  285</span><span class="stringliteral">      is_evaluation: bool, whether this is a training or evaluation call.</span></div>
<div class="line"><span class="lineno">  286</span><span class="stringliteral"></span> </div>
<div class="line"><span class="lineno">  287</span><span class="stringliteral">    Returns:</span></div>
<div class="line"><span class="lineno">  288</span><span class="stringliteral">      A `rl_agent.StepOutput` containing the action probs and chosen action.</span></div>
<div class="line"><span class="lineno">  289</span><span class="stringliteral">    &quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  290</span>    <span class="comment"># Act step: don&#39;t act at terminal info states or if its not our turn.</span></div>
<div class="line"><span class="lineno">  291</span>    <span class="keywordflow">if</span> (<span class="keywordflow">not</span> time_step.last()) <span class="keywordflow">and</span> (</div>
<div class="line"><span class="lineno">  292</span>        time_step.is_simultaneous_move() <span class="keywordflow">or</span></div>
<div class="line"><span class="lineno">  293</span>        self.player_id == time_step.current_player()):</div>
<div class="line"><span class="lineno">  294</span>      info_state = time_step.observations[<span class="stringliteral">&quot;info_state&quot;</span>][self.player_id]</div>
<div class="line"><span class="lineno">  295</span>      legal_actions = time_step.observations[<span class="stringliteral">&quot;legal_actions&quot;</span>][self.player_id]</div>
<div class="line"><span class="lineno">  296</span>      action, probs = self._act(info_state, legal_actions)</div>
<div class="line"><span class="lineno">  297</span>    <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  298</span>      action = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  299</span>      probs = []</div>
<div class="line"><span class="lineno">  300</span> </div>
<div class="line"><span class="lineno">  301</span>    <span class="keywordflow">if</span> <span class="keywordflow">not</span> is_evaluation:</div>
<div class="line"><span class="lineno">  302</span>      self._step_counter += 1</div>
<div class="line"><span class="lineno">  303</span> </div>
<div class="line"><span class="lineno">  304</span>      <span class="comment"># Add data points to current episode buffer.</span></div>
<div class="line"><span class="lineno">  305</span>      <span class="keywordflow">if</span> self._prev_time_step:</div>
<div class="line"><span class="lineno">  306</span>        self._add_transition(time_step)</div>
<div class="line"><span class="lineno">  307</span> </div>
<div class="line"><span class="lineno">  308</span>      <span class="comment"># Episode done, add to dataset and maybe learn.</span></div>
<div class="line"><span class="lineno">  309</span>      <span class="keywordflow">if</span> time_step.last():</div>
<div class="line"><span class="lineno">  310</span>        self._add_episode_data_to_dataset()</div>
<div class="line"><span class="lineno">  311</span>        self._episode_counter += 1</div>
<div class="line"><span class="lineno">  312</span> </div>
<div class="line"><span class="lineno">  313</span>        <span class="keywordflow">if</span> len(self._dataset[<span class="stringliteral">&quot;returns&quot;</span>]) &gt;= self._batch_size:</div>
<div class="line"><span class="lineno">  314</span>          self._critic_update()</div>
<div class="line"><span class="lineno">  315</span>          self._num_learn_steps += 1</div>
<div class="line"><span class="lineno">  316</span>          <span class="keywordflow">if</span> self._num_learn_steps % self._num_critic_before_pi == 0:</div>
<div class="line"><span class="lineno">  317</span>            self._pi_update()</div>
<div class="line"><span class="lineno">  318</span>          self._dataset = collections.defaultdict(list)</div>
<div class="line"><span class="lineno">  319</span> </div>
<div class="line"><span class="lineno">  320</span>        self._prev_time_step = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  321</span>        self._prev_action = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  322</span>        <span class="keywordflow">return</span></div>
<div class="line"><span class="lineno">  323</span>      <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  324</span>        self._prev_time_step = time_step</div>
<div class="line"><span class="lineno">  325</span>        self._prev_action = action</div>
<div class="line"><span class="lineno">  326</span> </div>
<div class="line"><span class="lineno">  327</span>    <span class="keywordflow">return</span> rl_agent.StepOutput(action=action, probs=probs)</div>
<div class="line"><span class="lineno">  328</span> </div>
</div><!-- fragment -->
<p class="reference">References <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00154">open_spiel.python.algorithms.nfsp.NFSP._act()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00281">open_spiel.python.algorithms.policy_gradient.PolicyGradient._act()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00161">open_spiel.python.jax.nfsp.NFSP._act()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00278">open_spiel.python.jax.policy_gradient.PolicyGradient._act</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00145">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy._act()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00263">open_spiel.python.pytorch.policy_gradient.PolicyGradient._act()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00384">open_spiel.python.algorithms.policy_gradient.PolicyGradient._add_episode_data_to_dataset()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00362">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_episode_data_to_dataset()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00226">open_spiel.python.algorithms.nfsp.NFSP._add_transition()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00404">open_spiel.python.algorithms.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00233">open_spiel.python.jax.nfsp.NFSP._add_transition()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00398">open_spiel.python.jax.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00197">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy._add_transition()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00382">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../d7/dfe/dataset__generator_8py_source.html#l00032">dataset_generator.Dataset._batch_size</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00074">open_spiel.python.algorithms.dqn.DQN._batch_size</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00068">open_spiel.python.algorithms.nfsp.NFSP._batch_size</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00156">open_spiel.python.algorithms.policy_gradient.PolicyGradient._batch_size</a>, <a class="el" href="../../d4/d52/iterated__matrix__game_8py_source.html#l00047">open_spiel.python.environments.iterated_matrix_game.IteratedMatrixGame._batch_size</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00072">open_spiel.python.jax.dqn.DQN._batch_size</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00068">open_spiel.python.jax.nfsp.NFSP._batch_size</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00633">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._batch_size</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00075">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy._batch_size</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00092">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._batch_size</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00145">open_spiel.python.pytorch.dqn.DQN._batch_size</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00178">open_spiel.python.pytorch.policy_gradient.PolicyGradient._batch_size</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00427">open_spiel.python.algorithms.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00422">open_spiel.python.jax.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00405">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00161">open_spiel.python.algorithms.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00249">open_spiel.python.jax.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00184">open_spiel.python.pytorch.policy_gradient.PolicyGradient._dataset</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00167">open_spiel.python.algorithms.policy_gradient.PolicyGradient._episode_counter</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00648">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._episode_counter</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00255">open_spiel.python.jax.policy_gradient.PolicyGradient._episode_counter</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00190">open_spiel.python.pytorch.policy_gradient.PolicyGradient._episode_counter</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00338">open_spiel.python.algorithms.dqn.DQN._full_checkpoint_name()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00271">open_spiel.python.algorithms.nfsp.NFSP._full_checkpoint_name()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00347">open_spiel.python.algorithms.policy_gradient.PolicyGradient._full_checkpoint_name()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00287">open_spiel.python.jax.nfsp.NFSP._full_checkpoint_name()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00329">open_spiel.python.pytorch.policy_gradient.PolicyGradient._full_checkpoint_name()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00382">open_spiel.python.algorithms.policy_gradient.PolicyGradient._last_critic_loss_value</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00396">open_spiel.python.jax.policy_gradient.PolicyGradient._last_critic_loss_value</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00360">open_spiel.python.pytorch.policy_gradient.PolicyGradient._last_critic_loss_value</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00382">open_spiel.python.algorithms.policy_gradient.PolicyGradient._last_pi_loss_value</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00396">open_spiel.python.jax.policy_gradient.PolicyGradient._last_pi_loss_value</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00360">open_spiel.python.pytorch.policy_gradient.PolicyGradient._last_pi_loss_value</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00268">open_spiel.python.algorithms.policy_gradient.PolicyGradient._loss_str</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00261">open_spiel.python.jax.policy_gradient.PolicyGradient._loss_str</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00241">open_spiel.python.pytorch.policy_gradient.PolicyGradient._loss_str</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00158">open_spiel.python.algorithms.policy_gradient.PolicyGradient._num_critic_before_pi</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00246">open_spiel.python.jax.policy_gradient.PolicyGradient._num_critic_before_pi</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00180">open_spiel.python.pytorch.policy_gradient.PolicyGradient._num_critic_before_pi</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00168">open_spiel.python.algorithms.policy_gradient.PolicyGradient._num_learn_steps</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00649">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._num_learn_steps</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00256">open_spiel.python.jax.policy_gradient.PolicyGradient._num_learn_steps</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00191">open_spiel.python.pytorch.policy_gradient.PolicyGradient._num_learn_steps</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00444">open_spiel.python.jax.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00089">open_spiel.python.algorithms.dqn.DQN._prev_action</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00075">open_spiel.python.algorithms.nfsp.NFSP._prev_action</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00163">open_spiel.python.algorithms.policy_gradient.PolicyGradient._prev_action</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00141">open_spiel.python.algorithms.tabular_qlearner.QLearner._prev_action</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00226">open_spiel.python.algorithms.wolf_phc.WoLFPHC._prev_action</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00088">open_spiel.python.jax.dqn.DQN._prev_action</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00075">open_spiel.python.jax.nfsp.NFSP._prev_action</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00639">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._prev_action</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00251">open_spiel.python.jax.policy_gradient.PolicyGradient._prev_action</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00107">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._prev_action</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00160">open_spiel.python.pytorch.dqn.DQN._prev_action</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00186">open_spiel.python.pytorch.policy_gradient.PolicyGradient._prev_action</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00162">open_spiel.python.algorithms.policy_gradient.PolicyGradient._prev_time_step</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00638">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._prev_time_step</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00250">open_spiel.python.jax.policy_gradient.PolicyGradient._prev_time_step</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00109">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._prev_time_step</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00185">open_spiel.python.pytorch.policy_gradient.PolicyGradient._prev_time_step</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00147">open_spiel.python.algorithms.dqn.DQN._savers</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00115">open_spiel.python.algorithms.nfsp.NFSP._savers</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00198">open_spiel.python.algorithms.policy_gradient.PolicyGradient._savers</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00114">open_spiel.python.jax.nfsp.NFSP._savers</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00207">open_spiel.python.pytorch.policy_gradient.PolicyGradient._savers</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00092">open_spiel.python.algorithms.dqn.DQN._step_counter</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00078">open_spiel.python.algorithms.nfsp.NFSP._step_counter</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00166">open_spiel.python.algorithms.policy_gradient.PolicyGradient._step_counter</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00091">open_spiel.python.jax.dqn.DQN._step_counter</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00078">open_spiel.python.jax.nfsp.NFSP._step_counter</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00647">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._step_counter</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00254">open_spiel.python.jax.policy_gradient.PolicyGradient._step_counter</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00115">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._step_counter</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00163">open_spiel.python.pytorch.dqn.DQN._step_counter</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00189">open_spiel.python.pytorch.policy_gradient.PolicyGradient._step_counter</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00068">open_spiel.python.algorithms.dqn.DQN.player_id</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00135">open_spiel.python.algorithms.eva.EVAAgent.player_id</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00064">open_spiel.python.algorithms.nfsp.NFSP.player_id</a>, <a class="el" href="../../d6/d97/noisy__policy_8py_source.html#l00055">open_spiel.python.algorithms.noisy_policy.NoisyPolicy.player_id</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00152">open_spiel.python.algorithms.policy_gradient.PolicyGradient.player_id</a>, <a class="el" href="../../d5/d27/rnad_8py_source.html#l00670">open_spiel.python.algorithms.rnad.rnad.EnvStep.player_id</a>, <a class="el" href="../../d6/d15/bluechip__bridge_8py_source.html#l00222">open_spiel.python.bots.bluechip_bridge.BlueChipBridgeBot.player_id()</a>, <a class="el" href="../../d1/d9b/bluechip__bridge__uncontested__bidding_8py_source.html#l00208">open_spiel.python.bots.bluechip_bridge_uncontested_bidding.BlueChipBridgeBot.player_id()</a>, <a class="el" href="../../dc/d9c/bots_2policy_8py_source.html#l00043">open_spiel.python.bots.policy.PolicyBot.player_id()</a>, <a class="el" href="../../d6/d4c/uniform__random_8py_source.html#l00039">open_spiel.python.bots.uniform_random.UniformRandomBot.player_id()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00067">open_spiel.python.jax.dqn.DQN.player_id</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00065">open_spiel.python.jax.nfsp.NFSP.player_id</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00631">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.player_id</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00243">open_spiel.python.jax.policy_gradient.PolicyGradient.player_id</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00089">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.player_id</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00140">open_spiel.python.pytorch.dqn.DQN.player_id</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00127">open_spiel.python.pytorch.eva.EVAAgent.player_id</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00175">open_spiel.python.pytorch.policy_gradient.PolicyGradient.player_id</a>, <a class="el" href="../../de/d51/ppo_8py_source.html#l00198">open_spiel.python.pytorch.ppo.PPO.player_id</a>, <a class="el" href="../../d3/d26/dqn_8h_source.html#l00050">open_spiel::algorithms::torch_dqn::DQNSettings.player_id</a>, <a class="el" href="../../d9/d49/base_type_8h_source.html#l00032">open_spiel::baseT::P_UnitId.player_id</a>, and <a class="el" href="../../d7/d2a/data_2paper__data_2routing__game__experiments_2utils_8py_source.html#l01009">utils.PurePolicyResponse.player_id</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../da/d71/jax__cfr_8py_source.html#l00359">open_spiel.python.jax.cfr.jax_cfr.JaxCFR.evaluate_and_update_policy()</a>, <a class="el" href="../../da/d71/jax__cfr_8py_source.html#l00350">open_spiel.python.jax.cfr.jax_cfr.JaxCFR.multiple_steps()</a>, <a class="el" href="../../d6/d11/double__oracle_8py_source.html#l00126">open_spiel.python.algorithms.double_oracle.DoubleOracleSolver.solve_yield()</a>, <a class="el" href="../../d4/d2e/nash__evolutionary__search_8py_source.html#l00094">nash_evolutionary_search.NashCMAES.step_for()</a>, <a class="el" href="../../df/dd1/nash__random__search_8py_source.html#l00100">nash_random_search.NashRandomSearch.step_for()</a>, <a class="el" href="../../d2/d0e/bandit__regret_8py_source.html#l00363">open_spiel.python.mfg.algorithms.bandit_regret.PolynomialWeightAlgorithm.step_for()</a>, and <a class="el" href="../../dd/ddd/regret__minimizer_8py_source.html#l00107">regret_minimizer.RegretMinimizer.step_for()</a>.</p>
<div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af6b7739338748eab5d5000c55d046fe8_cgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af6b7739338748eab5d5000c55d046fe8_cgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af6b7739338748eab5d5000c55d046fe8_cgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af6b7739338748eab5d5000c55d046fe8_cgraph">
<area shape="rect" title=" " alt="" coords="5,921,217,962"/>
<area shape="rect" href="../../dd/d94/classopen__spiel_1_1python_1_1algorithms_1_1nfsp_1_1_n_f_s_p.html#a4a6d0e9231fd4a7bb4f3c94d39f7efa9" title=" " alt="" coords="290,5,514,46"/>
<area shape="poly" title=" " alt="" coords="110,921,118,754,128,630,142,494,161,357,187,231,203,176,221,128,241,88,263,57,275,46,278,50,267,61,245,90,226,130,208,178,193,233,167,358,147,494,133,630,124,754,116,921"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a4aa82f423b8ea8364ba5de3c5d4c48c3" title=" " alt="" coords="288,71,516,111"/>
<area shape="poly" title=" " alt="" coords="111,921,121,764,146,524,166,398,191,282,223,187,242,150,263,123,273,114,276,117,267,126,247,153,228,189,196,284,171,399,151,525,126,765,116,921"/>
<area shape="rect" href="../../da/dba/classopen__spiel_1_1python_1_1jax_1_1nfsp_1_1_n_f_s_p.html#ada196f521b92856b75890ae45028e8b5" title=" " alt="" coords="312,136,492,177"/>
<area shape="poly" title=" " alt="" coords="111,921,123,776,150,555,170,440,195,334,226,247,243,213,263,188,278,175,295,166,298,171,281,180,267,192,248,216,231,249,200,336,175,441,155,556,128,776,116,921"/>
<area shape="rect" href="../../d7/d46/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1average__network__fictitious__play_1_1_average_policy.html#abdc9aec6873a17c1cbd8e65670b77e23" title=" " alt="" coords="265,201,539,242"/>
<area shape="poly" title=" " alt="" coords="111,920,125,786,154,585,174,481,199,385,228,307,245,276,263,253,266,250,270,253,267,257,249,279,233,309,204,387,179,482,159,586,130,787,117,921"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#a5fbe9303efa1660b1b4738078819631d" title=" " alt="" coords="296,267,508,307"/>
<area shape="poly" title=" " alt="" coords="112,921,127,798,158,616,178,522,203,436,231,365,246,338,263,317,280,304,284,308,267,321,251,341,235,367,208,437,183,523,163,617,133,798,117,921"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#ad9f79105068bacdec3421dc6cd6bdff4" title=" " alt="" coords="288,331,516,387"/>
<area shape="poly" title=" " alt="" coords="109,921,111,827,117,761,128,687,147,610,174,533,212,461,236,428,263,397,273,388,276,392,267,401,240,431,217,463,179,535,152,611,133,688,122,762,116,828,114,921"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#ae72fa55445edd59df6e326a4902eb686" title=" " alt="" coords="296,411,508,467"/>
<area shape="poly" title=" " alt="" coords="110,921,118,841,126,785,140,724,159,660,186,597,220,537,263,484,281,469,284,473,267,488,224,540,190,599,164,662,145,726,132,786,123,842,116,921"/>
<area shape="rect" href="../../dd/d94/classopen__spiel_1_1python_1_1algorithms_1_1nfsp_1_1_n_f_s_p.html#ac89ac21f6e717c7f68dee6590e99e12a" title=" " alt="" coords="290,816,514,857"/>
<area shape="poly" title=" " alt="" coords="148,919,202,892,264,866,285,859,286,864,266,871,204,896,151,923"/>
<area shape="rect" href="../../d2/d62/classopen__spiel_1_1python_1_1bots_1_1bluechip__bridge_1_1_blue_chip_bridge_bot.html#acaaa9d432ff433c3672a24c8a7bc0a23" title=" " alt="" coords="594,636,827,677"/>
<area shape="poly" title=" " alt="" coords="110,921,116,845,124,793,137,737,156,680,183,625,218,576,263,536,299,514,333,501,365,495,396,495,462,510,540,535,580,552,618,575,679,623,675,627,615,579,578,557,538,540,460,515,396,501,365,500,334,506,302,519,266,540,222,579,188,628,161,682,142,739,129,794,121,845,115,921"/>
<area shape="rect" href="../../da/d4a/classopen__spiel_1_1python_1_1bots_1_1bluechip__bridge__uncontested__bidding_1_1_blue_chip_bridge_bot.html#a6b74e3d54f11b8147bd0806a1641e2b1" title=" " alt="" coords="587,700,833,756"/>
<area shape="poly" title=" " alt="" coords="111,921,120,851,129,805,143,756,163,705,189,657,222,613,263,578,300,556,335,540,369,531,402,527,435,531,468,540,503,556,541,578,554,590,562,603,568,631,572,660,578,673,589,686,592,689,588,693,585,690,573,676,567,661,562,632,557,605,550,593,537,582,501,561,466,545,434,536,402,533,370,536,337,545,303,561,266,582,226,617,193,660,168,707,148,757,134,807,125,852,116,921"/>
<area shape="rect" href="../../d1/d07/classopen__spiel_1_1python_1_1bots_1_1policy_1_1_policy_bot.html#ae1967e66d77d550419acdce692703543" title=" " alt="" coords="612,780,808,821"/>
<area shape="poly" title=" " alt="" coords="217,954,306,963,400,967,482,963,514,956,538,946,550,934,558,922,562,893,566,862,573,846,585,832,597,823,601,827,589,836,577,849,571,863,567,894,563,923,555,938,540,951,516,961,483,968,400,973,306,968,217,959"/>
<area shape="rect" href="../../d5/dc0/classopen__spiel_1_1python_1_1bots_1_1uniform__random_1_1_uniform_random_bot.html#ac93a0f081d67fda75f84f09b1e6e2b0b" title=" " alt="" coords="587,845,833,886"/>
<area shape="poly" title=" " alt="" coords="163,960,212,977,265,990,342,1003,404,1011,464,1009,538,990,579,972,617,947,678,895,681,899,620,952,582,976,540,995,465,1014,403,1017,342,1009,264,995,210,982,161,965"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a307beec7698e9be87df5fbbe671f4552" title=" " alt="" coords="288,880,516,936"/>
<area shape="poly" title=" " alt="" coords="217,927,272,920,273,926,217,932"/>
<area shape="rect" href="../../da/dba/classopen__spiel_1_1python_1_1jax_1_1nfsp_1_1_n_f_s_p.html#a3b6060febf490d9bc7bbc3907cb70be6" title=" " alt="" coords="312,592,492,633"/>
<area shape="poly" title=" " alt="" coords="114,920,129,864,158,789,177,749,201,710,230,673,263,642,296,624,298,629,266,646,234,677,206,713,182,751,162,791,134,866,119,922"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#a21bbaf4ed7613d6231bb7a825bbddea8" title=" " alt="" coords="309,656,494,712"/>
<area shape="poly" title=" " alt="" coords="119,920,139,878,170,825,212,770,236,744,263,722,293,705,296,710,266,727,240,748,216,773,175,828,144,881,124,922"/>
<area shape="rect" href="../../d7/d46/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1average__network__fictitious__play_1_1_average_policy.html#a8d89870745eb75408d6d66d42a608b4e" title=" " alt="" coords="269,1062,535,1118"/>
<area shape="poly" title=" " alt="" coords="141,960,197,1000,266,1041,295,1053,292,1058,263,1045,194,1005,138,965"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#aa03ef306d33bfebbdb6c7478a965c26f" title=" " alt="" coords="296,736,508,792"/>
<area shape="poly" title=" " alt="" coords="128,919,184,861,222,829,263,802,281,793,283,798,266,807,225,834,188,865,132,923"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a2f382dfe307bcbd3b5e218296176c103" title=" " alt="" coords="278,1141,526,1182"/>
<area shape="poly" title=" " alt="" coords="125,961,147,998,178,1043,218,1089,266,1127,274,1132,271,1137,263,1132,215,1093,174,1046,142,1000,121,964"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#a3ab0b1c45101cb6b9a00bda3d3b1ef7c" title=" " alt="" coords="309,1206,494,1262"/>
<area shape="poly" title=" " alt="" coords="122,962,140,1009,170,1071,212,1136,238,1166,266,1192,296,1209,293,1213,263,1196,234,1170,208,1139,165,1074,135,1011,117,963"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#a6cc5d6bb8de010a9f67e71cc09e3ff5c" title=" " alt="" coords="278,1285,526,1326"/>
<area shape="poly" title=" " alt="" coords="118,962,131,1024,158,1108,177,1153,202,1196,231,1237,266,1272,270,1275,267,1279,263,1276,227,1240,197,1199,173,1155,153,1110,126,1025,113,963"/>
<area shape="rect" href="../../d2/d7c/classopen__spiel_1_1python_1_1algorithms_1_1dqn_1_1_d_q_n.html#ae9c1ce35d124abd475038179182072de" title=" " alt="" coords="292,1416,512,1457"/>
<area shape="poly" title=" " alt="" coords="115,962,121,1044,129,1100,142,1163,161,1227,187,1291,222,1350,266,1401,280,1411,277,1416,263,1405,218,1353,182,1293,156,1229,136,1164,123,1101,116,1045,110,963"/>
<area shape="rect" href="../../dd/d94/classopen__spiel_1_1python_1_1algorithms_1_1nfsp_1_1_n_f_s_p.html#a5f7b746e25b9e1853fb03765d8a11218" title=" " alt="" coords="290,1481,514,1522"/>
<area shape="poly" title=" " alt="" coords="114,962,116,1054,122,1119,134,1190,152,1265,179,1338,217,1407,240,1438,266,1466,278,1476,275,1480,263,1470,236,1441,213,1410,175,1341,147,1266,128,1191,117,1119,111,1055,109,963"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#aed4ffb841749a60bdbe259e38d4670e5" title=" " alt="" coords="288,1546,516,1602"/>
<area shape="poly" title=" " alt="" coords="118,962,134,1079,166,1251,187,1340,211,1421,237,1487,252,1513,267,1532,276,1541,273,1545,263,1535,247,1516,233,1490,206,1422,182,1341,161,1252,129,1080,112,963"/>
<area shape="rect" href="../../da/dba/classopen__spiel_1_1python_1_1jax_1_1nfsp_1_1_n_f_s_p.html#a9f10685976bfd0bfd22d3981a145759e" title=" " alt="" coords="306,1625,498,1666"/>
<area shape="poly" title=" " alt="" coords="117,962,131,1094,160,1290,180,1392,205,1485,234,1561,250,1590,266,1612,292,1630,289,1634,263,1616,245,1593,229,1563,200,1487,175,1393,154,1291,126,1095,111,963"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#ae7f03499d3fe8e965b17197a14b50fd5" title=" " alt="" coords="296,1690,508,1746"/>
<area shape="poly" title=" " alt="" coords="116,962,129,1104,157,1319,177,1431,202,1534,232,1619,249,1651,267,1676,284,1691,281,1695,263,1679,244,1654,227,1621,197,1536,172,1433,152,1320,124,1105,111,963"/>
<area shape="rect" href="../../dd/d1d/classopen__spiel_1_1python_1_1algorithms_1_1policy__gradient_1_1_policy_gradient.html#a0b144035d8261d817cfbcada93204812" title=" " alt="" coords="287,1769,517,1810"/>
<area shape="poly" title=" " alt="" coords="116,962,126,1119,151,1358,171,1484,196,1599,228,1693,246,1729,267,1756,276,1764,272,1768,263,1759,242,1732,223,1695,191,1600,165,1485,146,1359,120,1119,111,963"/>
<area shape="rect" href="../../dd/dae/classopen__spiel_1_1python_1_1jax_1_1policy__gradient_1_1_policy_gradient.html#a7d2d196a16afb7b1c93a05263bbaef4c" title=" " alt="" coords="309,1834,494,1890"/>
<area shape="poly" title=" " alt="" coords="116,962,125,1129,134,1252,149,1387,168,1523,194,1647,227,1750,246,1790,267,1820,296,1842,293,1846,263,1824,241,1793,222,1752,189,1649,163,1523,143,1388,129,1252,119,1129,110,963"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#a1df0f6d210f6335c45c04572758e5dab" title=" " alt="" coords="287,1351,517,1391"/>
<area shape="poly" title=" " alt="" coords="116,962,126,1034,150,1135,169,1190,195,1243,227,1293,266,1336,275,1342,272,1347,263,1340,223,1296,190,1246,164,1192,145,1137,121,1035,111,963"/>
<area shape="poly" title=" " alt="" coords="513,818,537,802,549,789,556,775,561,746,565,716,572,701,585,686,589,683,592,687,589,690,577,704,570,718,566,747,561,777,554,792,541,806,515,822"/>
<area shape="poly" title=" " alt="" coords="510,813,538,802,562,785,586,766,598,760,600,765,588,771,565,789,540,807,512,818"/>
<area shape="poly" title=" " alt="" coords="514,821,597,811,597,816,514,826"/>
<area shape="poly" title=" " alt="" coords="514,844,572,850,572,855,514,850"/>
<area shape="poly" title=" " alt="" coords="514,884,537,866,553,845,560,823,560,778,560,732,568,709,585,687,588,684,591,688,589,690,573,712,566,733,565,778,565,824,558,847,541,870,518,888"/>
<area shape="poly" title=" " alt="" coords="515,881,537,866,548,855,555,843,561,818,567,792,574,779,585,766,589,763,593,767,589,770,578,782,572,794,566,819,560,845,552,858,541,870,518,886"/>
<area shape="poly" title=" " alt="" coords="511,877,538,866,561,849,586,831,603,824,605,829,588,836,565,853,540,871,513,882"/>
<area shape="poly" title=" " alt="" coords="516,890,571,882,572,887,517,895"/>
<area shape="poly" title=" " alt="" coords="493,623,579,635,578,640,492,628"/>
<area shape="poly" title=" " alt="" coords="493,624,540,642,556,653,565,664,574,675,588,686,598,691,595,696,586,691,571,679,561,668,552,657,538,647,492,629"/>
<area shape="poly" title=" " alt="" coords="493,618,518,628,541,642,554,658,562,674,566,706,570,737,576,752,589,766,600,775,597,779,585,770,572,755,565,739,561,706,557,675,550,661,537,646,516,632,491,623"/>
<area shape="poly" title=" " alt="" coords="493,616,519,626,541,642,559,666,567,690,568,714,566,738,564,762,565,785,572,808,589,831,593,834,589,838,585,834,568,810,560,786,559,762,561,738,563,714,561,691,554,668,537,646,516,631,491,621"/>
<area shape="poly" title=" " alt="" coords="495,673,578,666,579,671,495,679"/>
<area shape="poly" title=" " alt="" coords="495,695,572,706,571,711,494,700"/>
<area shape="poly" title=" " alt="" coords="496,703,540,722,555,733,565,745,574,756,588,766,599,771,597,776,586,771,571,760,561,748,552,737,538,727,494,708"/>
<area shape="poly" title=" " alt="" coords="496,697,520,708,541,722,553,736,560,750,565,778,571,805,577,818,589,830,595,835,591,839,585,834,573,821,566,807,560,779,555,752,549,739,537,726,517,712,494,702"/>
<area shape="poly" title=" " alt="" coords="507,735,538,722,561,704,586,686,599,680,601,685,588,691,565,708,540,727,509,740"/>
<area shape="poly" title=" " alt="" coords="508,749,572,742,572,747,508,755"/>
<area shape="poly" title=" " alt="" coords="508,774,597,785,597,790,508,779"/>
<area shape="poly" title=" " alt="" coords="509,790,540,802,564,816,588,830,608,838,606,843,586,835,562,821,538,807,507,795"/>
<area shape="rect" href="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient.html#accd3df94affd3092ece7c5110a1de359" title=" " alt="" coords="600,1310,820,1366"/>
<area shape="poly" title=" " alt="" coords="527,1316,585,1322,585,1327,526,1321"/>
<area shape="poly" title=" " alt="" coords="517,1356,585,1348,586,1354,518,1361"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="../../da/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af6b7739338748eab5d5000c55d046fe8_icgraph.png" border="0" usemap="#ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af6b7739338748eab5d5000c55d046fe8_icgraph" alt=""/></div>
<map name="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af6b7739338748eab5d5000c55d046fe8_icgraph" id="ada/de9/classopen__spiel_1_1python_1_1pytorch_1_1policy__gradient_1_1_policy_gradient_af6b7739338748eab5d5000c55d046fe8_icgraph">
<area shape="rect" title=" " alt="" coords="884,216,1096,256"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#a14d11483beff07f087b51f3a2dd71135" title=" " alt="" coords="606,5,792,61"/>
<area shape="poly" title=" " alt="" coords="964,205,910,139,874,105,835,75,791,55,793,51,838,71,878,101,914,135,968,201"/>
<area shape="rect" href="../../d9/dd5/classopen__spiel_1_1python_1_1jax_1_1cfr_1_1jax__cfr_1_1_jax_c_f_r.html#adb88039a6a02b4d0090a0abc5c3c5424" title=" " alt="" coords="606,85,792,126"/>
<area shape="poly" title=" " alt="" coords="948,208,896,173,835,141,791,126,793,121,837,136,899,168,951,204"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a7a91195b9b42b8536e06098e836b02e4" title=" " alt="" coords="573,150,824,191"/>
<area shape="poly" title=" " alt="" coords="881,214,792,194,793,189,882,209"/>
<area shape="rect" href="../../d2/dfd/classnash__evolutionary__search_1_1_nash_c_m_a_e_s.html#a42b13c1091631c52988a6391fe34038a" title=" " alt="" coords="610,216,787,256"/>
<area shape="poly" title=" " alt="" coords="869,238,787,238,787,233,869,233"/>
<area shape="rect" href="../../d5/dd9/classnash__random__search_1_1_nash_random_search.html#a9b9967669c24ceba55dc8ce00565a71a" title=" " alt="" coords="584,281,813,322"/>
<area shape="poly" title=" " alt="" coords="882,263,793,283,792,278,881,257"/>
<area shape="rect" href="../../d1/d50/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1bandit__regret_1_1_polynomial_weight_algorithm.html#a3b7ceacfd8a03895a691242d227c1ddd" title=" " alt="" coords="561,346,836,387"/>
<area shape="poly" title=" " alt="" coords="951,268,899,303,837,336,803,348,801,343,835,331,896,299,948,264"/>
<area shape="rect" href="../../d5/d11/classregret__minimizer_1_1_regret_minimizer.html#aa371edb5793c6a6cfbf51dc8597905dc" title=" " alt="" coords="566,411,831,437"/>
<area shape="poly" title=" " alt="" coords="969,271,915,338,879,372,838,401,809,413,807,408,835,396,876,368,911,334,965,267"/>
<area shape="rect" href="../../d7/d68/classopen__spiel_1_1python_1_1algorithms_1_1double__oracle_1_1_double_oracle_solver.html#a44f0c375b5ef20bb1267524788ab16da" title=" " alt="" coords="281,150,513,191"/>
<area shape="poly" title=" " alt="" coords="557,173,514,173,514,168,557,168"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#ad1331eddb66a419f7336bc267b47d75e" title=" " alt="" coords="5,117,233,158"/>
<area shape="poly" title=" " alt="" coords="265,157,233,153,233,148,265,152"/>
<area shape="rect" href="../../d0/d7e/classopen__spiel_1_1python_1_1algorithms_1_1mcts_1_1_m_c_t_s_bot.html#a14e053b461dc025b01a41453bc278c7d" title=" " alt="" coords="5,182,233,223"/>
<area shape="poly" title=" " alt="" coords="265,188,233,192,233,187,265,183"/>
</map>
</div>

</div>
</div>
<h2 class="groupheader">Member Data Documentation</h2>
<a id="ae314355e379c41fab18e0f210e206dbe" name="ae314355e379c41fab18e0f210e206dbe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae314355e379c41fab18e0f210e206dbe">&#9670;&#160;</a></span>_baseline_layer</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._baseline_layer</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00218">218</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00405">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>, and <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00502">open_spiel.python.algorithms.policy_gradient.PolicyGradient.copy_with_noise()</a>.</p>

</div>
</div>
<a id="a514747846f0aba63885ceee9e7999ad5" name="a514747846f0aba63885ceee9e7999ad5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a514747846f0aba63885ceee9e7999ad5">&#9670;&#160;</a></span>_batch_size</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._batch_size</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00178">178</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00061">open_spiel.python.algorithms.dqn.DQN.__init__()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00062">open_spiel.python.algorithms.nfsp.NFSP.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d4/d52/iterated__matrix__game_8py_source.html#l00042">open_spiel.python.environments.iterated_matrix_game.IteratedMatrixGame.__init__()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00060">open_spiel.python.jax.dqn.DQN.__init__()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00063">open_spiel.python.jax.nfsp.NFSP.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00630">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.__init__()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00070">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy.__init__()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00087">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.__init__()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00133">open_spiel.python.pytorch.dqn.DQN.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00987">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._construct_episode_batches()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00244">open_spiel.python.algorithms.nfsp.NFSP._learn()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00266">open_spiel.python.jax.nfsp.NFSP._learn()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00933">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._should_update()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00305">open_spiel.python.algorithms.dqn.DQN.learn()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00310">open_spiel.python.jax.dqn.DQN.learn()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00221">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy.learn()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00348">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.learn()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00301">open_spiel.python.pytorch.dqn.DQN.learn()</a>, <a class="el" href="../../d4/d52/iterated__matrix__game_8py_source.html#l00144">open_spiel.python.environments.iterated_matrix_game.IteratedMatrixGame.reset()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d4/d52/iterated__matrix__game_8py_source.html#l00089">open_spiel.python.environments.iterated_matrix_game.IteratedMatrixGame.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="ae4711f268372a27b01725b41fa9e0075" name="ae4711f268372a27b01725b41fa9e0075"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4711f268372a27b01725b41fa9e0075">&#9670;&#160;</a></span>_critic_network</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_network</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00220">220</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00630">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00887">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._store_time_step()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00813">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.step()</a>, and <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00743">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.update_params()</a>.</p>

</div>
</div>
<a id="a7802b6a9f19aa8a16739cdb0d9689764" name="a7802b6a9f19aa8a16739cdb0d9689764"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7802b6a9f19aa8a16739cdb0d9689764">&#9670;&#160;</a></span>_critic_optimizer</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_optimizer</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00211">211</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00405">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_update()</a>, and <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>.</p>

</div>
</div>
<a id="a4f16488b9f0f92e073d7e8e969d8793b" name="a4f16488b9f0f92e073d7e8e969d8793b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f16488b9f0f92e073d7e8e969d8793b">&#9670;&#160;</a></span>_dataset</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._dataset</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00184">184</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00384">open_spiel.python.algorithms.policy_gradient.PolicyGradient._add_episode_data_to_dataset()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00362">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_episode_data_to_dataset()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00427">open_spiel.python.algorithms.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00405">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="a095ea25772e0dc60db1e0b69ff4d52cc" name="a095ea25772e0dc60db1e0b69ff4d52cc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a095ea25772e0dc60db1e0b69ff4d52cc">&#9670;&#160;</a></span>_episode_counter</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._episode_counter</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00190">190</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00630">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00933">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._should_update()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00887">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._store_time_step()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="a7ad49e1f466991ddab26852eeec613cb" name="a7ad49e1f466991ddab26852eeec613cb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7ad49e1f466991ddab26852eeec613cb">&#9670;&#160;</a></span>_episode_data</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._episode_data</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00183">183</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00384">open_spiel.python.algorithms.policy_gradient.PolicyGradient._add_episode_data_to_dataset()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00362">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_episode_data_to_dataset()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00404">open_spiel.python.algorithms.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00398">open_spiel.python.jax.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00382">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00422">open_spiel.python.jax.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00444">open_spiel.python.jax.policy_gradient.PolicyGradient._pi_update()</a>, and <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="a0db88eaecdaca8cb92f2a457b28f658e" name="a0db88eaecdaca8cb92f2a457b28f658e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0db88eaecdaca8cb92f2a457b28f658e">&#9670;&#160;</a></span>_extra_discount</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._extra_discount</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00179">179</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00384">open_spiel.python.algorithms.policy_gradient.PolicyGradient._add_episode_data_to_dataset()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00362">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_episode_data_to_dataset()</a>.</p>

</div>
</div>
<a id="a8008d74c54fdd7a8346c662c18f0513f" name="a8008d74c54fdd7a8346c662c18f0513f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8008d74c54fdd7a8346c662c18f0513f">&#9670;&#160;</a></span>_kwargs</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._kwargs</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00171">171</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00061">open_spiel.python.algorithms.dqn.DQN.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d9/d94/abstract__meta__trainer_8py_source.html#l00110">open_spiel.python.algorithms.psro_v2.abstract_meta_trainer.AbstractMetaTrainer.__init__()</a>, <a class="el" href="../../dc/d28/optimization__oracle_8py_source.html#l00053">open_spiel.python.algorithms.psro_v2.optimization_oracle.AbstractOracle.__init__()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00060">open_spiel.python.jax.dqn.DQN.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00133">open_spiel.python.pytorch.dqn.DQN.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00432">open_spiel.python.algorithms.dqn.DQN.copy_with_noise()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00502">open_spiel.python.algorithms.policy_gradient.PolicyGradient.copy_with_noise()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00378">open_spiel.python.pytorch.dqn.DQN.copy_with_noise()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00476">open_spiel.python.pytorch.policy_gradient.PolicyGradient.copy_with_noise()</a>, <a class="el" href="../../d2/d31/rl__oracle_8py_source.html#l00213">open_spiel.python.algorithms.psro_v2.rl_oracle.RLOracle.generate_new_policies()</a>, and <a class="el" href="../../d9/d94/abstract__meta__trainer_8py_source.html#l00239">open_spiel.python.algorithms.psro_v2.abstract_meta_trainer.AbstractMetaTrainer.get_policies()</a>.</p>

</div>
</div>
<a id="a0176c53410292f41d18248aa42f4b93f" name="a0176c53410292f41d18248aa42f4b93f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0176c53410292f41d18248aa42f4b93f">&#9670;&#160;</a></span>_last_critic_loss_value</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._last_critic_loss_value</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00360">360</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00427">open_spiel.python.algorithms.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00422">open_spiel.python.jax.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00405">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="ac2279bd25f2714729ebe52265829bcec" name="ac2279bd25f2714729ebe52265829bcec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac2279bd25f2714729ebe52265829bcec">&#9670;&#160;</a></span>_last_loss_value</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._last_loss_value</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00194">194</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00061">open_spiel.python.algorithms.dqn.DQN.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00043">open_spiel.python.algorithms.tabular_qlearner.QLearner.__init__()</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00069">open_spiel.python.algorithms.wolf_phc.WoLFPHC.__init__()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00060">open_spiel.python.jax.dqn.DQN.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00070">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy.__init__()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00087">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.__init__()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00133">open_spiel.python.pytorch.dqn.DQN.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00310">open_spiel.python.jax.dqn.DQN.learn()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00221">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy.learn()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00301">open_spiel.python.pytorch.dqn.DQN.learn()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00159">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy.loss()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00371">open_spiel.python.algorithms.dqn.DQN.restore()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00175">open_spiel.python.algorithms.dqn.DQN.step()</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00095">open_spiel.python.algorithms.tabular_qlearner.QLearner.step()</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00155">open_spiel.python.algorithms.wolf_phc.WoLFPHC.step()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00157">open_spiel.python.jax.dqn.DQN.step()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00188">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.step()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00191">open_spiel.python.pytorch.dqn.DQN.step()</a>, and <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00429">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.update_prev_q_network()</a>.</p>

</div>
</div>
<a id="a0e58499db2a1f760318def503964d092" name="a0e58499db2a1f760318def503964d092"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0e58499db2a1f760318def503964d092">&#9670;&#160;</a></span>_last_pi_loss_value</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._last_pi_loss_value</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00360">360</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00444">open_spiel.python.jax.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="a62bf8321cd431e13713e9970c7ac50c3" name="a62bf8321cd431e13713e9970c7ac50c3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a62bf8321cd431e13713e9970c7ac50c3">&#9670;&#160;</a></span>_layer_sizes</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._layer_sizes</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00177">177</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00061">open_spiel.python.algorithms.dqn.DQN.__init__()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00062">open_spiel.python.algorithms.nfsp.NFSP.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00060">open_spiel.python.jax.dqn.DQN.__init__()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00063">open_spiel.python.jax.nfsp.NFSP.__init__()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00133">open_spiel.python.pytorch.dqn.DQN.__init__()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>.</p>

</div>
</div>
<a id="af6fc20a88f31a3f20b4628ee182e3352" name="af6fc20a88f31a3f20b4628ee182e3352"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af6fc20a88f31a3f20b4628ee182e3352">&#9670;&#160;</a></span>_loss_class</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._loss_class</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00173">173</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00405">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>.</p>

</div>
</div>
<a id="a1898d1e97950c332e40d31db30b7f7de" name="a1898d1e97950c332e40d31db30b7f7de"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1898d1e97950c332e40d31db30b7f7de">&#9670;&#160;</a></span>_loss_str</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._loss_str</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00241">241</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00422">open_spiel.python.jax.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00444">open_spiel.python.jax.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="abd22d3c69beb48d983fd934193e03aaf" name="abd22d3c69beb48d983fd934193e03aaf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abd22d3c69beb48d983fd934193e03aaf">&#9670;&#160;</a></span>_max_global_gradient_norm</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._max_global_gradient_norm</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00181">181</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>.</p>

</div>
</div>
<a id="a769cd71526dec762bc6464d008e782bf" name="a769cd71526dec762bc6464d008e782bf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a769cd71526dec762bc6464d008e782bf">&#9670;&#160;</a></span>_net_torso</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._net_torso</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00198">198</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00405">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>, and <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00502">open_spiel.python.algorithms.policy_gradient.PolicyGradient.copy_with_noise()</a>.</p>

</div>
</div>
<a id="a224bf64bf629d63f4123b67f0f45bc7a" name="a224bf64bf629d63f4123b67f0f45bc7a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a224bf64bf629d63f4123b67f0f45bc7a">&#9670;&#160;</a></span>_num_actions</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._num_actions</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00176">176</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00040">open_spiel.python.jax.policy_gradient.NetA2C.__call__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00057">open_spiel.python.jax.policy_gradient.NetPG.__call__()</a>, <a class="el" href="../../d3/dc4/algorithms_2deep__cfr_8py_source.html#l00129">open_spiel.python.algorithms.deep_cfr.DeepCFRSolver.__init__()</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00285">open_spiel.python.algorithms.deep_cfr_tf2.DeepCFRSolver.__init__()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00061">open_spiel.python.algorithms.dqn.DQN.__init__()</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00106">open_spiel.python.algorithms.eva.EVAAgent.__init__()</a>, <a class="el" href="../../d9/d7e/mcts__agent_8py_source.html#l00029">open_spiel.python.algorithms.mcts_agent.MCTSAgent.__init__()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00062">open_spiel.python.algorithms.nfsp.NFSP.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d3/df2/random__agent_8py_source.html#l00024">open_spiel.python.algorithms.random_agent.RandomAgent.__init__()</a>, <a class="el" href="../../d8/d79/tabular__multiagent__qlearner_8py_source.html#l00173">open_spiel.python.algorithms.tabular_multiagent_qlearner.MultiagentQLearner.__init__()</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00043">open_spiel.python.algorithms.tabular_qlearner.QLearner.__init__()</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00069">open_spiel.python.algorithms.wolf_phc.WoLFPHC.__init__()</a>, <a class="el" href="../../d6/d15/bluechip__bridge_8py_source.html#l00196">open_spiel.python.bots.bluechip_bridge.BlueChipBridgeBot.__init__()</a>, <a class="el" href="../../d0/dd5/rl__response_8py_source.html#l00134">open_spiel.python.examples.rl_response.FirstActionAgent.__init__()</a>, <a class="el" href="../../da/db6/roshambo__population__example_8py_source.html#l00055">open_spiel.python.examples.roshambo_population_example.BotAgent.__init__()</a>, <a class="el" href="../../df/d6c/chat__game__base_8py_source.html#l00106">open_spiel.python.games.chat_games.chat_game_base.ChatGameState.__init__()</a>, <a class="el" href="../../d0/d69/jax_2deep__cfr_8py_source.html#l00138">open_spiel.python.jax.deep_cfr.DeepCFRSolver.__init__()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00060">open_spiel.python.jax.dqn.DQN.__init__()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00063">open_spiel.python.jax.nfsp.NFSP.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00630">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00070">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy.__init__()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00087">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.__init__()</a>, <a class="el" href="../../dd/d6d/normal__form__game_8py_source.html#l00141">open_spiel.python.mfg.games.normal_form_game.MFGNormalFormState.__init__()</a>, <a class="el" href="../../d7/d95/pytorch_2deep__cfr_8py_source.html#l00221">open_spiel.python.pytorch.deep_cfr.DeepCFRSolver.__init__()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00133">open_spiel.python.pytorch.dqn.DQN.__init__()</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00100">open_spiel.python.pytorch.eva.EVAAgent.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00145">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy._act()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00226">open_spiel.python.algorithms.nfsp.NFSP._add_transition()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00404">open_spiel.python.algorithms.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00233">open_spiel.python.jax.nfsp.NFSP._add_transition()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00398">open_spiel.python.jax.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../db/d67/average__network__fictitious__play_8py_source.html#l00197">open_spiel.python.mfg.algorithms.average_network_fictitious_play.AveragePolicy._add_transition()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00382">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00209">open_spiel.python.algorithms.eva.EVAAgent._add_transition_replay()</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00194">open_spiel.python.pytorch.eva.EVAAgent._add_transition_replay()</a>, <a class="el" href="../../dd/d6d/normal__form__game_8py_source.html#l00180">open_spiel.python.mfg.games.normal_form_game.MFGNormalFormState._apply_action()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00987">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._construct_episode_batches()</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00414">open_spiel.python.algorithms.deep_cfr_tf2.DeepCFRSolver._create_memories()</a>, <a class="el" href="../../d0/d69/jax_2deep__cfr_8py_source.html#l00315">open_spiel.python.jax.deep_cfr.DeepCFRSolver._create_memories()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00269">open_spiel.python.algorithms.dqn.DQN._epsilon_greedy()</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00368">open_spiel.python.algorithms.eva.EVAAgent._epsilon_greedy()</a>, <a class="el" href="../../d8/d79/tabular__multiagent__qlearner_8py_source.html#l00210">open_spiel.python.algorithms.tabular_multiagent_qlearner.MultiagentQLearner._epsilon_greedy()</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00056">open_spiel.python.algorithms.tabular_qlearner.QLearner._epsilon_greedy()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00233">open_spiel.python.jax.dqn.DQN._epsilon_greedy()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00266">open_spiel.python.pytorch.dqn.DQN._epsilon_greedy()</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00342">open_spiel.python.pytorch.eva.EVAAgent._epsilon_greedy()</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00130">open_spiel.python.algorithms.wolf_phc.WoLFPHC._get_action_probs()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00261">open_spiel.python.jax.dqn.DQN._get_epsilon()</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00600">open_spiel.python.algorithms.deep_cfr_tf2.DeepCFRSolver._get_matched_regrets()</a>, <a class="el" href="../../df/d6c/chat__game__base_8py_source.html#l00236">open_spiel.python.games.chat_games.chat_game_base.ChatGameState._legal_actions()</a>, <a class="el" href="../../dd/d6d/normal__form__game_8py_source.html#l00166">open_spiel.python.mfg.games.normal_form_game.MFGNormalFormState._legal_actions()</a>, <a class="el" href="../../df/d6c/chat__game__base_8py_source.html#l00830">open_spiel.python.games.chat_games.chat_game_base.BaseChatGame._load_chat_game()</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00391">open_spiel.python.algorithms.deep_cfr_tf2.DeepCFRSolver._reinitialize_advantage_network()</a>, <a class="el" href="../../d0/d69/jax_2deep__cfr_8py_source.html#l00294">open_spiel.python.jax.deep_cfr.DeepCFRSolver._reinitialize_advantage_network()</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00381">open_spiel.python.algorithms.deep_cfr_tf2.DeepCFRSolver._reinitialize_policy_network()</a>, <a class="el" href="../../d0/d69/jax_2deep__cfr_8py_source.html#l00286">open_spiel.python.jax.deep_cfr.DeepCFRSolver._reinitialize_policy_network()</a>, <a class="el" href="../../d3/dc4/algorithms_2deep__cfr_8py_source.html#l00336">open_spiel.python.algorithms.deep_cfr.DeepCFRSolver._sample_action_from_advantage()</a>, <a class="el" href="../../d7/d95/pytorch_2deep__cfr_8py_source.html#l00393">open_spiel.python.pytorch.deep_cfr.DeepCFRSolver._sample_action_from_advantage()</a>, <a class="el" href="../../dd/dc3/boltzmann__tabular__qlearner_8py_source.html#l00054">open_spiel.python.algorithms.boltzmann_tabular_qlearner.BoltzmannQLearner._softmax()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00342">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._to_one_hot()</a>, <a class="el" href="../../d3/dc4/algorithms_2deep__cfr_8py_source.html#l00282">open_spiel.python.algorithms.deep_cfr.DeepCFRSolver._traverse_game_tree()</a>, <a class="el" href="../../d9/d36/algorithms_2deep__cfr__tf2_8py_source.html#l00552">open_spiel.python.algorithms.deep_cfr_tf2.DeepCFRSolver._traverse_game_tree()</a>, <a class="el" href="../../d0/d69/jax_2deep__cfr_8py_source.html#l00416">open_spiel.python.jax.deep_cfr.DeepCFRSolver._traverse_game_tree()</a>, <a class="el" href="../../d7/d95/pytorch_2deep__cfr_8py_source.html#l00338">open_spiel.python.pytorch.deep_cfr.DeepCFRSolver._traverse_game_tree()</a>, <a class="el" href="../../df/d6c/chat__game__base_8py_source.html#l00153">open_spiel.python.games.chat_games.chat_game_base.ChatGameState._unravel_flat_action()</a>, <a class="el" href="../../d6/d15/bluechip__bridge_8py_source.html#l00255">open_spiel.python.bots.bluechip_bridge.BlueChipBridgeBot._update_for_state()</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00405">open_spiel.python.algorithms.eva.EVAAgent.action_probabilities()</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00378">open_spiel.python.pytorch.eva.EVAAgent.action_probabilities()</a>, <a class="el" href="../../dc/d9b/catch_8py_source.html#l00167">open_spiel.python.environments.catch.Environment.action_spec()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00223">open_spiel.python.algorithms.dqn.DQN.add_transition()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00208">open_spiel.python.jax.dqn.DQN.add_transition()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00241">open_spiel.python.pytorch.dqn.DQN.add_transition()</a>, <a class="el" href="../../dd/d6d/normal__form__game_8py_source.html#l00204">open_spiel.python.mfg.games.normal_form_game.MFGNormalFormState.distribution_support()</a>, <a class="el" href="../../df/d6c/chat__game__base_8py_source.html#l00537">open_spiel.python.games.chat_games.chat_game_base.ChatGameState.names()</a>, <a class="el" href="../../dc/d9b/catch_8py_source.html#l00153">open_spiel.python.environments.catch.Environment.observation_spec()</a>, <a class="el" href="../../d6/d15/bluechip__bridge_8py_source.html#l00225">open_spiel.python.bots.bluechip_bridge.BlueChipBridgeBot.restart()</a>, <a class="el" href="../../d9/d7e/mcts__agent_8py_source.html#l00035">open_spiel.python.algorithms.mcts_agent.MCTSAgent.step()</a>, <a class="el" href="../../d3/df2/random__agent_8py_source.html#l00029">open_spiel.python.algorithms.random_agent.RandomAgent.step()</a>, <a class="el" href="../../d6/d15/bluechip__bridge_8py_source.html#l00323">open_spiel.python.bots.bluechip_bridge.BlueChipBridgeBot.step()</a>, <a class="el" href="../../d0/dd5/rl__response_8py_source.html#l00139">open_spiel.python.examples.rl_response.FirstActionAgent.step()</a>, <a class="el" href="../../da/db6/roshambo__population__example_8py_source.html#l00063">open_spiel.python.examples.roshambo_population_example.BotAgent.step()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00813">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00138">open_spiel.python.algorithms.nfsp.NFSP.temp_mode_as()</a>, and <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00148">open_spiel.python.jax.nfsp.NFSP.temp_mode_as()</a>.</p>

</div>
</div>
<a id="aeb9c290f2c483ad80487aee65d4f9399" name="aeb9c290f2c483ad80487aee65d4f9399"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeb9c290f2c483ad80487aee65d4f9399">&#9670;&#160;</a></span>_num_critic_before_pi</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._num_critic_before_pi</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00180">180</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="aeacb6abaae61dbc27cb957842dae67aa" name="aeacb6abaae61dbc27cb957842dae67aa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aeacb6abaae61dbc27cb957842dae67aa">&#9670;&#160;</a></span>_num_learn_steps</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._num_learn_steps</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00191">191</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00630">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00933">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._should_update()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00945">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._update_agent()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="af488b26c17dc6464176a853eb8906cc3" name="af488b26c17dc6464176a853eb8906cc3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af488b26c17dc6464176a853eb8906cc3">&#9670;&#160;</a></span>_pi_network</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_network</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00233">233</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00630">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00768">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.get_policy()</a>, and <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00813">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.step()</a>.</p>

</div>
</div>
<a id="a20560f66e392c7a7a9c91f7552e903f8" name="a20560f66e392c7a7a9c91f7552e903f8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a20560f66e392c7a7a9c91f7552e903f8">&#9670;&#160;</a></span>_pi_optimizer</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_optimizer</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00235">235</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>.</p>

</div>
</div>
<a id="a1b0ccdfb7cf04ba5dd04306bbd8b3c65" name="a1b0ccdfb7cf04ba5dd04306bbd8b3c65"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1b0ccdfb7cf04ba5dd04306bbd8b3c65">&#9670;&#160;</a></span>_policy_logits</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._policy_logits</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00267">267</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>.</p>

</div>
</div>
<a id="afe5f81efc6a4d006adbc43523aa807b5" name="afe5f81efc6a4d006adbc43523aa807b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe5f81efc6a4d006adbc43523aa807b5">&#9670;&#160;</a></span>_policy_logits_layer</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._policy_logits_layer</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00200">200</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>, and <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00502">open_spiel.python.algorithms.policy_gradient.PolicyGradient.copy_with_noise()</a>.</p>

</div>
</div>
<a id="a5850c75570c66a26bd5a843401f8c655" name="a5850c75570c66a26bd5a843401f8c655"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5850c75570c66a26bd5a843401f8c655">&#9670;&#160;</a></span>_prev_action</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._prev_action</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00186">186</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00061">open_spiel.python.algorithms.dqn.DQN.__init__()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00062">open_spiel.python.algorithms.nfsp.NFSP.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00060">open_spiel.python.jax.dqn.DQN.__init__()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00063">open_spiel.python.jax.nfsp.NFSP.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00630">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00087">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.__init__()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00133">open_spiel.python.pytorch.dqn.DQN.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00404">open_spiel.python.algorithms.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00398">open_spiel.python.jax.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00382">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00887">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._store_time_step()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00310">open_spiel.python.jax.dqn.DQN.learn()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00301">open_spiel.python.pytorch.dqn.DQN.learn()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00371">open_spiel.python.algorithms.dqn.DQN.restore()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00175">open_spiel.python.algorithms.dqn.DQN.step()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00176">open_spiel.python.algorithms.nfsp.NFSP.step()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d8/d92/tabular__qlearner_8py_source.html#l00095">open_spiel.python.algorithms.tabular_qlearner.QLearner.step()</a>, <a class="el" href="../../d4/d63/wolf__phc_8py_source.html#l00155">open_spiel.python.algorithms.wolf_phc.WoLFPHC.step()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00157">open_spiel.python.jax.dqn.DQN.step()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00184">open_spiel.python.jax.nfsp.NFSP.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00188">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.step()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00191">open_spiel.python.pytorch.dqn.DQN.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="a5d0742495265e2db0c0f8f5853920573" name="a5d0742495265e2db0c0f8f5853920573"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5d0742495265e2db0c0f8f5853920573">&#9670;&#160;</a></span>_prev_time_step</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._prev_time_step</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00185">185</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00630">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00087">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00404">open_spiel.python.algorithms.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00398">open_spiel.python.jax.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00382">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00987">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._construct_episode_batches()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00887">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._store_time_step()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00188">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="a178999560faff22b784da9efd675eae2" name="a178999560faff22b784da9efd675eae2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a178999560faff22b784da9efd675eae2">&#9670;&#160;</a></span>_q_values_layer</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._q_values_layer</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00223">223</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00405">open_spiel.python.pytorch.policy_gradient.PolicyGradient._critic_update()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>, and <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00502">open_spiel.python.algorithms.policy_gradient.PolicyGradient.copy_with_noise()</a>.</p>

</div>
</div>
<a id="a5a1adfc0f559d59b75f9c30c5991c757" name="a5a1adfc0f559d59b75f9c30c5991c757"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5a1adfc0f559d59b75f9c30c5991c757">&#9670;&#160;</a></span>_savers</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._savers</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00207">207</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00061">open_spiel.python.algorithms.dqn.DQN.__init__()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00062">open_spiel.python.algorithms.nfsp.NFSP.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00063">open_spiel.python.jax.nfsp.NFSP.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00444">open_spiel.python.algorithms.policy_gradient.PolicyGradient._pi_update()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00371">open_spiel.python.algorithms.dqn.DQN.restore()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00304">open_spiel.python.algorithms.nfsp.NFSP.restore()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00346">open_spiel.python.algorithms.dqn.DQN.save()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00279">open_spiel.python.algorithms.nfsp.NFSP.save()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00295">open_spiel.python.jax.nfsp.NFSP.save()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>.</p>

</div>
</div>
<a id="a129b3a4ac314411afa90406590743a8d" name="a129b3a4ac314411afa90406590743a8d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a129b3a4ac314411afa90406590743a8d">&#9670;&#160;</a></span>_step_counter</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient._step_counter</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">protected</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00189">189</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00061">open_spiel.python.algorithms.dqn.DQN.__init__()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00062">open_spiel.python.algorithms.nfsp.NFSP.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00060">open_spiel.python.jax.dqn.DQN.__init__()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00063">open_spiel.python.jax.nfsp.NFSP.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00630">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00087">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.__init__()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00133">open_spiel.python.pytorch.dqn.DQN.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00295">open_spiel.python.algorithms.dqn.DQN._get_epsilon()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00261">open_spiel.python.jax.dqn.DQN._get_epsilon()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00404">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN._get_epsilon()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00291">open_spiel.python.pytorch.dqn.DQN._get_epsilon()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00933">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._should_update()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00887">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._store_time_step()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00310">open_spiel.python.jax.dqn.DQN.learn()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00301">open_spiel.python.pytorch.dqn.DQN.learn()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00371">open_spiel.python.algorithms.dqn.DQN.restore()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00175">open_spiel.python.algorithms.dqn.DQN.step()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00176">open_spiel.python.algorithms.nfsp.NFSP.step()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00157">open_spiel.python.jax.dqn.DQN.step()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00184">open_spiel.python.jax.nfsp.NFSP.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00188">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.step()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00191">open_spiel.python.pytorch.dqn.DQN.step()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00138">open_spiel.python.algorithms.nfsp.NFSP.temp_mode_as()</a>.</p>

</div>
</div>
<a id="a3f6b907fbc00f3a27c4777852bc5c108" name="a3f6b907fbc00f3a27c4777852bc5c108"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3f6b907fbc00f3a27c4777852bc5c108">&#9670;&#160;</a></span>pg_class</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.pg_class</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00232">232</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00436">open_spiel.python.pytorch.policy_gradient.PolicyGradient._pi_update()</a>.</p>

</div>
</div>
<a id="af3f98efa3a15dc3f807f10ee8d757171" name="af3f98efa3a15dc3f807f10ee8d757171"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af3f98efa3a15dc3f807f10ee8d757171">&#9670;&#160;</a></span>player_id</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.player_id</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00175">175</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00061">open_spiel.python.algorithms.dqn.DQN.__init__()</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00106">open_spiel.python.algorithms.eva.EVAAgent.__init__()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00062">open_spiel.python.algorithms.nfsp.NFSP.__init__()</a>, <a class="el" href="../../d6/d97/noisy__policy_8py_source.html#l00039">open_spiel.python.algorithms.noisy_policy.NoisyPolicy.__init__()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00060">open_spiel.python.jax.dqn.DQN.__init__()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00063">open_spiel.python.jax.nfsp.NFSP.__init__()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00630">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.__init__()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00203">open_spiel.python.jax.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00087">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.__init__()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00133">open_spiel.python.pytorch.dqn.DQN.__init__()</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00100">open_spiel.python.pytorch.eva.EVAAgent.__init__()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00226">open_spiel.python.algorithms.nfsp.NFSP._add_transition()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00404">open_spiel.python.algorithms.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00233">open_spiel.python.jax.nfsp.NFSP._add_transition()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00398">open_spiel.python.jax.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00382">open_spiel.python.pytorch.policy_gradient.PolicyGradient._add_transition()</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00209">open_spiel.python.algorithms.eva.EVAAgent._add_transition_replay()</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00194">open_spiel.python.pytorch.eva.EVAAgent._add_transition_replay()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00987">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent._construct_episode_batches()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00244">open_spiel.python.algorithms.nfsp.NFSP._learn()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00266">open_spiel.python.jax.nfsp.NFSP._learn()</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00405">open_spiel.python.algorithms.eva.EVAAgent.action_probabilities()</a>, <a class="el" href="../../d6/d97/noisy__policy_8py_source.html#l00112">open_spiel.python.algorithms.noisy_policy.NoisyPolicy.action_probabilities()</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00378">open_spiel.python.pytorch.eva.EVAAgent.action_probabilities()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00223">open_spiel.python.algorithms.dqn.DQN.add_transition()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00208">open_spiel.python.jax.dqn.DQN.add_transition()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00247">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.add_transition()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00241">open_spiel.python.pytorch.dqn.DQN.add_transition()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00768">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.get_policy()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00305">open_spiel.python.algorithms.dqn.DQN.learn()</a>, <a class="el" href="../../d4/ddf/algorithms_2dqn_8py_source.html#l00175">open_spiel.python.algorithms.dqn.DQN.step()</a>, <a class="el" href="../../dc/de1/algorithms_2eva_8py_source.html#l00236">open_spiel.python.algorithms.eva.EVAAgent.step()</a>, <a class="el" href="../../d3/d8e/algorithms_2nfsp_8py_source.html#l00176">open_spiel.python.algorithms.nfsp.NFSP.step()</a>, <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00297">open_spiel.python.algorithms.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d1/d9b/bluechip__bridge__uncontested__bidding_8py_source.html#l00219">open_spiel.python.bots.bluechip_bridge_uncontested_bidding.BlueChipBridgeBot.step()</a>, <a class="el" href="../../d4/dc6/jax_2dqn_8py_source.html#l00157">open_spiel.python.jax.dqn.DQN.step()</a>, <a class="el" href="../../d0/dfd/jax_2nfsp_8py_source.html#l00184">open_spiel.python.jax.nfsp.NFSP.step()</a>, <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00813">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.step()</a>, <a class="el" href="../../d8/ddd/jax_2policy__gradient_8py_source.html#l00342">open_spiel.python.jax.policy_gradient.PolicyGradient.step()</a>, <a class="el" href="../../d6/de5/munchausen__deep__mirror__descent_8py_source.html#l00188">open_spiel.python.mfg.algorithms.munchausen_deep_mirror_descent.MunchausenDQN.step()</a>, <a class="el" href="../../d0/d8f/pytorch_2dqn_8py_source.html#l00191">open_spiel.python.pytorch.dqn.DQN.step()</a>, <a class="el" href="../../de/d05/pytorch_2eva_8py_source.html#l00220">open_spiel.python.pytorch.eva.EVAAgent.step()</a>, <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00280">open_spiel.python.pytorch.policy_gradient.PolicyGradient.step()</a>, and <a class="el" href="../../dd/d07/opponent__shaping_8py_source.html#l00743">open_spiel.python.jax.opponent_shaping.OpponentShapingAgent.update_params()</a>.</p>

</div>
</div>
<a id="a1ea857b4ebb691043d7510d4a15825e5" name="a1ea857b4ebb691043d7510d4a15825e5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1ea857b4ebb691043d7510d4a15825e5">&#9670;&#160;</a></span>policy_logits_network</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.pytorch.policy_gradient.PolicyGradient.policy_logits_network</td>
        </tr>
      </table>
</div><div class="memdoc">

<p class="definition">Definition at line <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00204">204</a> of file <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a>.</p>

<p class="reference">Referenced by <a class="el" href="../../de/d2e/algorithms_2policy__gradient_8py_source.html#l00113">open_spiel.python.algorithms.policy_gradient.PolicyGradient.__init__()</a>, and <a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html#l00138">open_spiel.python.pytorch.policy_gradient.PolicyGradient.__init__()</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>open_spiel/python/pytorch/<a class="el" href="../../db/d99/pytorch_2policy__gradient_8py_source.html">policy_gradient.py</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.11.0
</small></address>
</div><!-- doc-content -->
</body>
</html>

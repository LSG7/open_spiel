<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.11.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>open spiel: open_spiel.python.mfg.algorithms.pytorch.mfg_proximal_policy_optimization Namespace Reference</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<script type="text/javascript" src="../../clipboard.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../cookie.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/searchdata.js"></script>
<script type="text/javascript" src="../../search/search.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">open spiel
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.11.0 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search/",'.html');
/* @license-end */
</script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() { codefold.init(1); });
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,false,'search.php','Search',false);
  $(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function(){ initResizable(false); });
/* @license-end */
</script>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="../../df/dc9/namespaceopen__spiel.html">open_spiel</a></li><li class="navelem"><a class="el" href="../../d9/d47/namespaceopen__spiel_1_1python.html">python</a></li><li class="navelem"><b>mfg</b></li><li class="navelem"><b>algorithms</b></li><li class="navelem"><b>pytorch</b></li><li class="navelem"><a class="el" href="../../de/db2/namespaceopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1pytorch_1_1mfg__proximal__policy__optimization.html">mfg_proximal_policy_optimization</a></li>  </ul>
</div>
</div><!-- top -->
<div id="doc-content">
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle"><div class="title">open_spiel.python.mfg.algorithms.pytorch.mfg_proximal_policy_optimization Namespace Reference</div></div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d1/d97/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1pytorch_1_1mfg__proximal__policy__optimization_1_1_agent.html">Agent</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d2/dc6/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1pytorch_1_1mfg__proximal__policy__optimization_1_1_nash_c.html">NashC</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="../../d1/d9f/classopen__spiel_1_1python_1_1mfg_1_1algorithms_1_1pytorch_1_1mfg__proximal__policy__optimization_1_1_policy.html">Policy</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a2e0c2d949420ed06c9abb2fcea4b269f" id="r_a2e0c2d949420ed06c9abb2fcea4b269f"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a2e0c2d949420ed06c9abb2fcea4b269f">rollout</a> (env, iter_agent, eps_agent, num_epsiodes, steps, device)</td></tr>
<tr class="separator:a2e0c2d949420ed06c9abb2fcea4b269f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae91a651e2630155159efe4a1dd4902af" id="r_ae91a651e2630155159efe4a1dd4902af"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae91a651e2630155159efe4a1dd4902af">calculate_advantage</a> (gamma, norm, rewards, values, dones, device)</td></tr>
<tr class="separator:ae91a651e2630155159efe4a1dd4902af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8e72ba16279f22ead2ddf89db68463e2" id="r_a8e72ba16279f22ead2ddf89db68463e2"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8e72ba16279f22ead2ddf89db68463e2">learn</a> (history, optimizer_actor, optimize_critic, agent, num_minibatches=5, update_epochs=5, itr_eps=0.05, eps_eps=0.2, alpha=0.5, ent_coef=0.01, max_grad_norm=5)</td></tr>
<tr class="separator:a8e72ba16279f22ead2ddf89db68463e2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1dd41c66b93d7019c4aa293c92c38c60" id="r_a1dd41c66b93d7019c4aa293c92c38c60"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1dd41c66b93d7019c4aa293c92c38c60">calculate_explotability</a> (game, distrib, policy)</td></tr>
<tr class="separator:a1dd41c66b93d7019c4aa293c92c38c60"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">Mean field proximal policy optimaztion algorithm.

Reference:

    Algumaei, Talal, et al. "Regularization of the policy updates for
    stabilizing
    Mean Field Games." Pacific-Asia Conference on Knowledge Discovery and Data
    Mining. Cham: Springer Nature Switzerland, 2023. Available at:
    https://link.springer.com/chapter/10.1007/978-3-031-33377-4_28
</pre> </div><h2 class="groupheader">Function Documentation</h2>
<a id="ae91a651e2630155159efe4a1dd4902af" name="ae91a651e2630155159efe4a1dd4902af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae91a651e2630155159efe4a1dd4902af">&#9670;&#160;</a></span>calculate_advantage()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.mfg.algorithms.pytorch.mfg_proximal_policy_optimization.calculate_advantage </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>gamma</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>norm</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>rewards</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>values</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>dones</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>device</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Function used to calculate the Generalized Advantage estimate.</pre> 
<p class="definition">Definition at line <a class="el" href="../../d8/d11/mfg__proximal__policy__optimization_8py_source.html#l00178">178</a> of file <a class="el" href="../../d8/d11/mfg__proximal__policy__optimization_8py_source.html">mfg_proximal_policy_optimization.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  178</span><span class="keyword">def </span>calculate_advantage(gamma, norm, rewards, values, dones, device):</div>
<div class="line"><span class="lineno">  179</span>  <span class="stringliteral">&quot;&quot;&quot;Function used to calculate the Generalized Advantage estimate.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  180</span>  <span class="keyword">with</span> torch.no_grad():</div>
<div class="line"><span class="lineno">  181</span>    next_done = dones[-1]</div>
<div class="line"><span class="lineno">  182</span>    next_value = values[-1]</div>
<div class="line"><span class="lineno">  183</span>    steps = len(values)</div>
<div class="line"><span class="lineno">  184</span>    returns = torch.zeros_like(rewards).to(device)</div>
<div class="line"><span class="lineno">  185</span>    <span class="keywordflow">for</span> t <span class="keywordflow">in</span> reversed(range(steps)):</div>
<div class="line"><span class="lineno">  186</span>      <span class="keywordflow">if</span> t == steps - 1:</div>
<div class="line"><span class="lineno">  187</span>        nextnonterminal = 1.0 - next_done</div>
<div class="line"><span class="lineno">  188</span>        next_return = next_value</div>
<div class="line"><span class="lineno">  189</span>      <span class="keywordflow">else</span>:</div>
<div class="line"><span class="lineno">  190</span>        nextnonterminal = 1.0 - dones[t + 1]</div>
<div class="line"><span class="lineno">  191</span>        next_return = returns[t + 1]</div>
<div class="line"><span class="lineno">  192</span>      returns[t] = rewards[t] + gamma * nextnonterminal * next_return</div>
<div class="line"><span class="lineno">  193</span> </div>
<div class="line"><span class="lineno">  194</span>    advantages = returns - values</div>
<div class="line"><span class="lineno">  195</span> </div>
<div class="line"><span class="lineno">  196</span>  <span class="keywordflow">if</span> norm:</div>
<div class="line"><span class="lineno">  197</span>    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)</div>
<div class="line"><span class="lineno">  198</span> </div>
<div class="line"><span class="lineno">  199</span>  <span class="keywordflow">return</span> advantages, returns</div>
<div class="line"><span class="lineno">  200</span> </div>
<div class="line"><span class="lineno">  201</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a1dd41c66b93d7019c4aa293c92c38c60" name="a1dd41c66b93d7019c4aa293c92c38c60"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1dd41c66b93d7019c4aa293c92c38c60">&#9670;&#160;</a></span>calculate_explotability()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.mfg.algorithms.pytorch.mfg_proximal_policy_optimization.calculate_explotability </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>game</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>distrib</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>policy</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">This function is used to log the results to tensor board.</pre> 
<p class="definition">Definition at line <a class="el" href="../../d8/d11/mfg__proximal__policy__optimization_8py_source.html#l00281">281</a> of file <a class="el" href="../../d8/d11/mfg__proximal__policy__optimization_8py_source.html">mfg_proximal_policy_optimization.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  281</span><span class="keyword">def </span>calculate_explotability(game, distrib, policy):</div>
<div class="line"><span class="lineno">  282</span>  <span class="stringliteral">&quot;&quot;&quot;This function is used to log the results to tensor board.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  283</span>  initial_states = game.new_initial_states()</div>
<div class="line"><span class="lineno">  284</span>  pi_value = policy_value.PolicyValue(</div>
<div class="line"><span class="lineno">  285</span>      game, distrib, policy, value.TabularValueFunction(game)</div>
<div class="line"><span class="lineno">  286</span>  )</div>
<div class="line"><span class="lineno">  287</span>  m = {</div>
<div class="line"><span class="lineno">  288</span>      f<span class="stringliteral">&quot;ppo_br/{state}&quot;</span>: pi_value.eval_state(state) <span class="keywordflow">for</span> state <span class="keywordflow">in</span> initial_states</div>
<div class="line"><span class="lineno">  289</span>  }</div>
<div class="line"><span class="lineno">  290</span>  nashc = NashC(game, distrib, pi_value).nash_conv()</div>
<div class="line"><span class="lineno">  291</span>  m[<span class="stringliteral">&quot;nash_conv_ppo&quot;</span>] = nashc</div>
<div class="line"><span class="lineno">  292</span> </div>
<div class="line"><span class="lineno">  293</span>  <span class="keywordflow">return</span> m</div>
</div><!-- fragment -->
</div>
</div>
<a id="a8e72ba16279f22ead2ddf89db68463e2" name="a8e72ba16279f22ead2ddf89db68463e2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8e72ba16279f22ead2ddf89db68463e2">&#9670;&#160;</a></span>learn()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.mfg.algorithms.pytorch.mfg_proximal_policy_optimization.learn </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>history</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>optimizer_actor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>optimize_critic</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>agent</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>num_minibatches</em></span><span class="paramdefsep"> = </span><span class="paramdefval">5</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>update_epochs</em></span><span class="paramdefsep"> = </span><span class="paramdefval">5</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>itr_eps</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0.05</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>eps_eps</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0.2</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>alpha</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0.5</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>ent_coef</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0.01</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>max_grad_norm</em></span><span class="paramdefsep"> = </span><span class="paramdefval">5</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Update the agent network (actor and critic).</pre> 
<p class="definition">Definition at line <a class="el" href="../../d8/d11/mfg__proximal__policy__optimization_8py_source.html#l00202">202</a> of file <a class="el" href="../../d8/d11/mfg__proximal__policy__optimization_8py_source.html">mfg_proximal_policy_optimization.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  214</span>):</div>
<div class="line"><span class="lineno">  215</span>  <span class="stringliteral">&quot;&quot;&quot;Update the agent network (actor and critic).&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  216</span>  v_loss = <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  217</span>  batch_size = history[<span class="stringliteral">&quot;actions&quot;</span>].shape[0]</div>
<div class="line"><span class="lineno">  218</span>  b_inds = np.arange(batch_size)</div>
<div class="line"><span class="lineno">  219</span>  mini_batch_size = batch_size // num_minibatches</div>
<div class="line"><span class="lineno">  220</span>  <span class="comment"># get batch indices</span></div>
<div class="line"><span class="lineno">  221</span>  np.random.shuffle(b_inds)</div>
<div class="line"><span class="lineno">  222</span>  <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(update_epochs):</div>
<div class="line"><span class="lineno">  223</span>    <span class="keywordflow">for</span> start <span class="keywordflow">in</span> range(0, batch_size, mini_batch_size):</div>
<div class="line"><span class="lineno">  224</span>      end = start + mini_batch_size</div>
<div class="line"><span class="lineno">  225</span>      mb_inds = b_inds[start:end]</div>
<div class="line"><span class="lineno">  226</span>      <span class="comment"># for each update epoch shuffle the batch indices</span></div>
<div class="line"><span class="lineno">  227</span>      <span class="comment"># generate the new logprobs, entropy and value then calculate the ratio</span></div>
<div class="line"><span class="lineno">  228</span>      b_obs = history[<span class="stringliteral">&quot;info_state&quot;</span>][mb_inds]</div>
<div class="line"><span class="lineno">  229</span>      b_advantages = history[<span class="stringliteral">&quot;advantages&quot;</span>][mb_inds]</div>
<div class="line"><span class="lineno">  230</span> </div>
<div class="line"><span class="lineno">  231</span>      <span class="comment"># Get the data under the episode policy (representative agent current</span></div>
<div class="line"><span class="lineno">  232</span>      <span class="comment"># policy)</span></div>
<div class="line"><span class="lineno">  233</span>      _, newlogprob, entropy, new_value = agent.get_action_and_value(</div>
<div class="line"><span class="lineno">  234</span>          b_obs, history[<span class="stringliteral">&quot;actions&quot;</span>][mb_inds]</div>
<div class="line"><span class="lineno">  235</span>      )</div>
<div class="line"><span class="lineno">  236</span>      logratio = newlogprob - history[<span class="stringliteral">&quot;logprobs&quot;</span>][mb_inds]</div>
<div class="line"><span class="lineno">  237</span>      ratio = torch.exp(logratio)</div>
<div class="line"><span class="lineno">  238</span> </div>
<div class="line"><span class="lineno">  239</span>      <span class="comment"># Get the data under the iteration policy (the population policy)</span></div>
<div class="line"><span class="lineno">  240</span>      _, t_newlogprob, _, _ = agent.get_action_and_value(</div>
<div class="line"><span class="lineno">  241</span>          b_obs, history[<span class="stringliteral">&quot;t_actions&quot;</span>][mb_inds]</div>
<div class="line"><span class="lineno">  242</span>      )</div>
<div class="line"><span class="lineno">  243</span>      t_logratio = t_newlogprob - history[<span class="stringliteral">&quot;t_logprobs&quot;</span>][mb_inds]</div>
<div class="line"><span class="lineno">  244</span>      t_ratio = torch.exp(t_logratio)</div>
<div class="line"><span class="lineno">  245</span> </div>
<div class="line"><span class="lineno">  246</span>      <span class="comment"># iteration update PPO</span></div>
<div class="line"><span class="lineno">  247</span>      t_pg_loss1 = b_advantages * t_ratio</div>
<div class="line"><span class="lineno">  248</span>      t_pg_loss2 = b_advantages * torch.clamp(t_ratio, 1 - itr_eps, 1 + itr_eps)</div>
<div class="line"><span class="lineno">  249</span> </div>
<div class="line"><span class="lineno">  250</span>      <span class="comment"># episodic update PPO</span></div>
<div class="line"><span class="lineno">  251</span>      pg_loss1 = b_advantages * ratio</div>
<div class="line"><span class="lineno">  252</span>      pg_loss2 = b_advantages * torch.clamp(ratio, 1 - eps_eps, 1 + eps_eps)</div>
<div class="line"><span class="lineno">  253</span> </div>
<div class="line"><span class="lineno">  254</span>      <span class="comment"># Calculate the loss using our loss function</span></div>
<div class="line"><span class="lineno">  255</span>      pg_loss = (</div>
<div class="line"><span class="lineno">  256</span>          -alpha * torch.min(pg_loss1, pg_loss2).mean()</div>
<div class="line"><span class="lineno">  257</span>          - (1 - alpha) * torch.min(t_pg_loss1, t_pg_loss2).mean()</div>
<div class="line"><span class="lineno">  258</span>      )</div>
<div class="line"><span class="lineno">  259</span>      v_loss = F.smooth_l1_loss(</div>
<div class="line"><span class="lineno">  260</span>          new_value.reshape(-1), history[<span class="stringliteral">&quot;returns&quot;</span>][mb_inds]</div>
<div class="line"><span class="lineno">  261</span>      ).mean()</div>
<div class="line"><span class="lineno">  262</span>      entropy_loss = entropy.mean()</div>
<div class="line"><span class="lineno">  263</span>      loss = pg_loss - ent_coef * entropy_loss</div>
<div class="line"><span class="lineno">  264</span> </div>
<div class="line"><span class="lineno">  265</span>      <span class="comment"># Actor update</span></div>
<div class="line"><span class="lineno">  266</span>      optimizer_actor.zero_grad()</div>
<div class="line"><span class="lineno">  267</span>      loss.backward()</div>
<div class="line"><span class="lineno">  268</span>      nn.utils.clip_grad_norm_(agent.actor.parameters(), max_grad_norm)</div>
<div class="line"><span class="lineno">  269</span>      optimizer_actor.step()</div>
<div class="line"><span class="lineno">  270</span> </div>
<div class="line"><span class="lineno">  271</span>      <span class="comment"># Critic update</span></div>
<div class="line"><span class="lineno">  272</span>      optimize_critic.zero_grad()</div>
<div class="line"><span class="lineno">  273</span>      v_loss.backward()</div>
<div class="line"><span class="lineno">  274</span>      nn.utils.clip_grad_norm_(agent.critic.parameters(), max_grad_norm)</div>
<div class="line"><span class="lineno">  275</span>      optimize_critic.step()</div>
<div class="line"><span class="lineno">  276</span> </div>
<div class="line"><span class="lineno">  277</span>  <span class="keyword">assert</span> v_loss <span class="keywordflow">is</span> <span class="keywordflow">not</span> <span class="keywordtype">None</span></div>
<div class="line"><span class="lineno">  278</span>  <span class="keywordflow">return</span> v_loss</div>
<div class="line"><span class="lineno">  279</span> </div>
<div class="line"><span class="lineno">  280</span> </div>
</div><!-- fragment -->
</div>
</div>
<a id="a2e0c2d949420ed06c9abb2fcea4b269f" name="a2e0c2d949420ed06c9abb2fcea4b269f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2e0c2d949420ed06c9abb2fcea4b269f">&#9670;&#160;</a></span>rollout()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">open_spiel.python.mfg.algorithms.pytorch.mfg_proximal_policy_optimization.rollout </td>
          <td>(</td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>env</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>iter_agent</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>eps_agent</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>num_epsiodes</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>steps</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"></td>          <td class="paramname"><span class="paramname"><em>device</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Generates num_epsiodes rollouts.</pre> 
<p class="definition">Definition at line <a class="el" href="../../d8/d11/mfg__proximal__policy__optimization_8py_source.html#l00126">126</a> of file <a class="el" href="../../d8/d11/mfg__proximal__policy__optimization_8py_source.html">mfg_proximal_policy_optimization.py</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  126</span><span class="keyword">def </span>rollout(env, iter_agent, eps_agent, num_epsiodes, steps, device):</div>
<div class="line"><span class="lineno">  127</span>  <span class="stringliteral">&quot;&quot;&quot;Generates num_epsiodes rollouts.&quot;&quot;&quot;</span></div>
<div class="line"><span class="lineno">  128</span>  info_state = torch.zeros((steps, iter_agent.info_state_size), device=device)</div>
<div class="line"><span class="lineno">  129</span>  actions = torch.zeros((steps,), device=device)</div>
<div class="line"><span class="lineno">  130</span>  logprobs = torch.zeros((steps,), device=device)</div>
<div class="line"><span class="lineno">  131</span>  rewards = torch.zeros((steps,), device=device)</div>
<div class="line"><span class="lineno">  132</span>  dones = torch.zeros((steps,), device=device)</div>
<div class="line"><span class="lineno">  133</span>  values = torch.zeros((steps,), device=device)</div>
<div class="line"><span class="lineno">  134</span>  entropies = torch.zeros((steps,), device=device)</div>
<div class="line"><span class="lineno">  135</span>  t_actions = torch.zeros((steps,), device=device)</div>
<div class="line"><span class="lineno">  136</span>  t_logprobs = torch.zeros((steps,), device=device)</div>
<div class="line"><span class="lineno">  137</span> </div>
<div class="line"><span class="lineno">  138</span>  step = 0</div>
<div class="line"><span class="lineno">  139</span>  <span class="keywordflow">for</span> _ <span class="keywordflow">in</span> range(num_epsiodes):</div>
<div class="line"><span class="lineno">  140</span>    time_step = env.reset()</div>
<div class="line"><span class="lineno">  141</span>    <span class="keywordflow">while</span> <span class="keywordflow">not</span> time_step.last():</div>
<div class="line"><span class="lineno">  142</span>      obs = time_step.observations[<span class="stringliteral">&quot;info_state&quot;</span>][0]</div>
<div class="line"><span class="lineno">  143</span>      obs = torch.Tensor(obs).to(device)</div>
<div class="line"><span class="lineno">  144</span>      info_state[step] = obs</div>
<div class="line"><span class="lineno">  145</span>      <span class="keyword">with</span> torch.no_grad():</div>
<div class="line"><span class="lineno">  146</span>        t_action, t_logprob, _, _ = iter_agent.get_action_and_value(obs)</div>
<div class="line"><span class="lineno">  147</span>        action, logprob, entropy, ivalue = eps_agent.get_action_and_value(obs)</div>
<div class="line"><span class="lineno">  148</span> </div>
<div class="line"><span class="lineno">  149</span>      time_step = env.step([action.item()])</div>
<div class="line"><span class="lineno">  150</span> </div>
<div class="line"><span class="lineno">  151</span>      <span class="comment"># iteration policy data</span></div>
<div class="line"><span class="lineno">  152</span>      t_logprobs[step] = t_logprob</div>
<div class="line"><span class="lineno">  153</span>      t_actions[step] = t_action</div>
<div class="line"><span class="lineno">  154</span> </div>
<div class="line"><span class="lineno">  155</span>      <span class="comment"># episode policy data</span></div>
<div class="line"><span class="lineno">  156</span>      logprobs[step] = logprob</div>
<div class="line"><span class="lineno">  157</span>      dones[step] = time_step.last()</div>
<div class="line"><span class="lineno">  158</span>      entropies[step] = entropy</div>
<div class="line"><span class="lineno">  159</span>      values[step] = ivalue</div>
<div class="line"><span class="lineno">  160</span>      actions[step] = action</div>
<div class="line"><span class="lineno">  161</span>      rewards[step] = torch.Tensor(time_step.rewards).to(device)</div>
<div class="line"><span class="lineno">  162</span>      step += 1</div>
<div class="line"><span class="lineno">  163</span> </div>
<div class="line"><span class="lineno">  164</span>  history = {</div>
<div class="line"><span class="lineno">  165</span>      <span class="stringliteral">&quot;info_state&quot;</span>: info_state,</div>
<div class="line"><span class="lineno">  166</span>      <span class="stringliteral">&quot;actions&quot;</span>: actions,</div>
<div class="line"><span class="lineno">  167</span>      <span class="stringliteral">&quot;logprobs&quot;</span>: logprobs,</div>
<div class="line"><span class="lineno">  168</span>      <span class="stringliteral">&quot;rewards&quot;</span>: rewards,</div>
<div class="line"><span class="lineno">  169</span>      <span class="stringliteral">&quot;dones&quot;</span>: dones,</div>
<div class="line"><span class="lineno">  170</span>      <span class="stringliteral">&quot;values&quot;</span>: values,</div>
<div class="line"><span class="lineno">  171</span>      <span class="stringliteral">&quot;entropies&quot;</span>: entropies,</div>
<div class="line"><span class="lineno">  172</span>      <span class="stringliteral">&quot;t_actions&quot;</span>: t_actions,</div>
<div class="line"><span class="lineno">  173</span>      <span class="stringliteral">&quot;t_logprobs&quot;</span>: t_logprobs,</div>
<div class="line"><span class="lineno">  174</span>  }</div>
<div class="line"><span class="lineno">  175</span>  <span class="keywordflow">return</span> history</div>
<div class="line"><span class="lineno">  176</span> </div>
<div class="line"><span class="lineno">  177</span> </div>
</div><!-- fragment -->
</div>
</div>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.11.0
</small></address>
</div><!-- doc-content -->
</body>
</html>
